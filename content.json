[{"title":"利用softEther VPN远程访问内部网络","date":"2019-11-02T07:12:46.000Z","path":"2019/11/02/softEther/","text":"利用 softEther VPN 进行远程访问作者: whr 使用场景和前提条件 内部网络受到保护，无法直接在内部网络中的主机中直接部署VPN server（搭建完无法连接到该server） 用户需要从外部网络远程访问内部网络中的资源，如主机或打印机等等 对内部网络中的某台主机拥有管理权限 有一台暴露在互联网中的主机 内部网络中的主机可以直接访问互联网 比如 学生于校外访问校园网资源 远程办公 管理家庭局域网设备 举个栗子这里通过一个例子，描述如何通过一步步的操作，利用softEther VPN 套件实现远程访问。 一个安全的网络（192.168.1.0/24），它受到防火墙和NAT的保护，无法从Internet访问，但是可以通过防火墙或NAT代理访问Internet上的网站。该网络中， IP地址为 192.168.1.111 的一台打印机，IP地址为 192.186.1.222 的一台主机H。一台暴露在Internet的主机S，IP地址为 125.111.111.111。 目标 通过构建主机S和主机H所在内部网络的级联网络，用户可以通过连接主机S所创建的VPN，实现对内部网络（192.168.1.0/24）中的资源的访问。 开始你的表演总体上整个任务的关键位置所运行的SoftEther VPN组件如下图所示 1、在主机S上安装搭建VPN server连接到 主机S ，将SoftEther VPN Server 组件下载到本地。组件选择地址根据实际运行环境，选择适当的版本。这里我选择的是Linux 系统，CPU选择的是Intel x64 / AMD64 (64bit)。 拿到下载地址后，使用wget命令进行下载，： 123456789# 下载softether-vpnserver到本地wget https://github.com/SoftEtherVPN/SoftEtherVPN_Stable/releases/download/v4.30-9696-beta/softether-vpnserver-v4.30-9696-beta-2019.07.08-linux-x64-64bit.tar.gz#解压tar zxvf softether-*server*.tar.gzcd vpnserver/# 这里面有一个隐藏的文件.install.sh，运行它。[vpnserver]# ./.install.sh# 一路Yes，Agree默认即可 查看下载的文件进入对应文件夹运行安装脚本进行默认配置 安装完成后进入 123456789101112131415161718192021222324252627282930# 启动vpnserver[vpnserver]# ./vpnserver start# 进行vpn的初始配置[vpnserver]# ./ vpncmdBy using vpncmd program, the following can be achieved.1. Management of VPN Server or VPN Bridge2. Management of VPN Client3. Use of VPN Tools (certificate creation and Network Traffic Speed Test Tool)Select 1, 2 or 3:# 选择1 回车Hostname of IP Address of Destination:# 回车If connecting to the server by Virtual Hub Admin Mode, please input the Virtual Hub name.If connecting by server admin mode, please press Enter without inputting anything.Specify Virtual Hub Name:# 回车Password:# 回车VPN Server&gt;ServerPasswordSet# 输入 ServerPasswordSetServerPasswordSet command - Set VPN Server Administrator PasswordPlease enter the password. To cancel press the Ctrl+D key.# 设置你的服务器管理密码Password: ******#这里输入管理密码Confirm input: ******#确认密码 至此，主机S上的vpnserver的安装和初步的配置就完成了，后面将介绍使用SoftEther VPN Server Manager 对其进行进一步的配置。 2、在主机H上安装搭建VPN Bridge连接到 主机H ，将SoftEther VPN Bridge 组件下载到本地。这里就不贴图了，具体和下载vpnserver一样，换成vpnbridge。下载地址 根据实际运行环境，选择适当的版本。这里我选择的是Linux 系统，CPU选择的是Intel x64 / AMD64 (64bit)。使用wget 命令进行下载，安装，初步配置也都相近： 12345678910111213141516171819202122232425262728293031323334353637383940# 下载softether-vpnbridge到本地wget https://github.com/SoftEtherVPN/SoftEtherVPN_Stable/releases/download/v4.30-9696-beta/softether-vpnbridge-v4.30-9696-beta-2019.07.08-linux-x64-64bit.tar.gz#解压tar zxvf softether-*bridge*.tar.gzcd vpnserver/# 这里面有一个隐藏的文件.install.sh，运行它。[vpnbridge]# ./.install.sh# 一路Yes，Agree默认即可[vpnbridge]# ./vpnbridge start[vpnbridge]# ./vpncmd...By using vpncmd program, the following can be achieved.1. Management of VPN Server or VPN Bridge2. Management of VPN Client3. Use of VPN Tools (certificate creation and Network Traffic Speed Test Tool)Select 1, 2 or 3: 1# 输入1Specify the host name or IP address of the computer that the destination VPN Server or VPN Bridge is operating on.By specifying according to the format 'host name:port number', you can also specify the port number.(When the port number is unspecified, 443 is used.)If nothing is input and the Enter key is pressed, the connection will be made to the port number 8888 of localhost (this computer).Hostname of IP Address of Destination:#回车If connecting to the server by Virtual Hub Admin Mode, please input the Virtual Hub name.If connecting by server admin mode, please press Enter without inputting anything.Specify Virtual Hub Name:#回车Connection has been established with VPN Server \"localhost\" (port 443).You have administrator privileges for the entire VPN Server.VPN Server&gt;ServerPasswordSetServerPasswordSet command - Set VPN Server Administrator PasswordPlease enter the password. To cancel press the Ctrl+D key.Password: ******#这里输入管理密码Confirm input: ******#确认密码The command completed successfully. 3、配置主机S上的vpnserver这里需要找了一台windows的机子，因为SoftEther提供了一款SoftEther VPN Server Manager的图形管理器，进行蛇者比较方便。要求就是最好在内网中，方便连接主机H，同时也能连接主机S。将SoftEther VPN Server Manager for Windows 图形组件下载到本地。下载地址 运行SoftEther VPN Server Manager，点击设置 填入设置名（这个随意），主机名填入主机S的IP地址，端口采用默认的443，代理类型选择直接TCP/IP连接（无代理），选中服务端管理模式并填入前面设置的vpnserver管理密码，点击确定。如果你在前面没有设置管理密码，在连接的时候将也提示你设置密码。 勾选远程访问VPN Server (R)，点击下一步后提示确认初始化，选择 是。 为你的vpnserver设置一个名字，这里输入VPN，点击确定。 动态DNS功能，不用管，直接无视选择退出。 IPsec/L2TP 设置，勾选启用L2TP服务器功能，并设置IPsec预共享秘钥。这一步是为了后面我们可以用手机或者PC自带的VPN工具进行连接。 VPN Azure 云，勾选禁用，点击确定。 创建一个用户来接受VPN连接，点击创建用户。 填入相关信息，验证类型选择密码验证，并在密码验证设置中填入密码。 我们这里需要创建两个账号，分别为user1和user2，一个用于主机H上的VPN bridge，一个用于用户在外网的状态下登录VPN。 点击关闭进入下一步。 点击管理HUB。 点击虚拟NAT和虚拟DHCP服务器。 点击启用SecureNAT，这一步很关键。 确定启用SecureNAT。 点击关闭。 至此，我们对于主机S上的VPN server的配置就完成了，接下来连接到主机H上的vpn bridge进行配置。 4、配置主机H上的vpnbridge同样是回到SoftEther VPN Server Manager主界面，点击新设置，填入VPN bridge的IP地址，这里是 192.168.1.222，如果前面在初步配置的时候选择默认的话，端口选择5555，如果前面在初步配置的时候选择默认的话。并填入管理密码。（参考3-1,3-2） 勾选站到站 VPN Server 或 VPN Bridge，选择下一步。 设置本地网桥。这里如果你有多张网卡的话，要选择你想级联出去网段所在的网卡。这里我想级联192.168.1.0/24网段，我选择配置为该网段地址的网卡，eth0。不清楚对应网卡的可以在控制台运行ifconfig命令查看。 回到管理器面板，点击管理虚拟HUB，点击虚拟NAT和虚拟DHCP服务器，启用 SecureNAT。 回到管理器面板，点击管理虚拟HUB，选择管理级联连接。 填写连接设置名(自由设置)，填写vpnserver的地址，即主机S的IP地址，端口号选择443。只要你的地址和端口填写正确，并且前面配置无误，这里虚拟HUB名的下拉列表就能找到我们之前创建的虚拟HUB “VPN”。勾选无代理，选择认证类型为标准密码验证，并填写用户名密码。这里使用创建的用户user1。点击确定。 进入到级联管理界面，选中我们刚刚创建的连接，点击在线。 发现该装填已由离线变成在线。 至此，我们在对主机H的vpn bridge的配置也大功告成。此时主机S与主机H逻辑上已经是同属一个网络，主机S可以直接访问内网192.168.1.0/24网络。所以下一步，我们只要连接到主机S的VPN，我们也就可以和主机S一样，直接访问内网192.168.1.0/24网络的资源了。 5. 用户配置L2TP/IPsec VPN IOS端设置。 Android端设置。 ————————————————连接时填入用户名密码即可。 Windows端设置。 连接有问题的时候请检查一下主机S的防火墙和安全策略设置。请开启L2TP必要的端口：UDP 500、4500、1701。 完结撒花"},{"title":"论文解读（1）BLA——基于区块链的认证","date":"2019-10-26T13:38:17.000Z","path":"2019/10/26/paperBLA/","text":"本篇博文分享来自期刊《IEEE INTERNET OF THINGS JOURNAL》中的一篇论文《BLA: Blockchain-Assisted Lightweight Anonymous Authentication for Distributed Vehicular Fog Services》 针对分布式车辆雾服务的区块链辅助的轻量级匿名认证一.背景1. 概念车载自治网络（VANET）是移动自治网络（MABET）的一部分，包括移动车辆和路边单元（RSUs）。每辆车都配置了一个车载单元（OBU）和一组传感器。 2.问题及可采取方式由于车辆的移动性，所以对于车辆雾服务（VFSs）来说需要跨分布式的数据中心，这样跨数据中心的认证也是在这个过程中不可避免的问题。 VAENTs依赖于云计算服务来进行通信，计算以及存储。而联网的车辆逐渐增多且不断增长的移动性要求服务的低延时和不可中断。这给当前云计算带来很大挑战。因此，车辆雾计算（VFC）被提出来提高通信效率和计算能力以适应最新的车辆应用。 3. 现状VFC被认为是对延迟敏感的应用来说是非常有益的技术之一，是对于高速移动车辆的一种理想的技术。 VFS基本安全和性能要求： 1）车辆身份认证与隐私 每辆车访问VFS必需经过认证，是后面授权决策的基础。同时必须保证在认证过程车辆的身份不会被暴露，确保车辆用户的隐私。 2）实时限制 另一方面，为了适应车辆的快速移动，要求认证是轻量级的。 现有的认证机制及缺点： 应用技术： 对称加密、PKI、基于身份的签名（IBS）、无证书签名、群签名； 缺点： 依赖于管理中心来提前创建与车辆间的信任关系，当车辆移动到新数据中心的时候，信任关系将会失效。 解决存在缺点的方式： 提出跨数据中心、跨地区、跨域的认证机制，存在以下问题： 要求在OBUs、RSUs和信任机构之间多次交互，造成高通信延时 数据库由单个管理员管理，无法抵抗篡改攻击 二. 解决方案（论文贡献） 实现灵活的跨数据中心认证。这里的灵活指的是车辆在移动到一个新的数据中心时，自身可以决定是否重新认证或者只是直接发送一个VFS请求。 为了保护车辆隐私实现匿名。车辆可以自主决定更换自己伪名的时间和频率。 提出的认证机制BLA是轻量级的。将密码和区块链技术结合起来，以消除车辆和服务管理器(SMS)之间的交互性。在访问VFS之前，驾驶着的车辆只需要发送一个消息，该消息可以是认证消息或VFS请求消息。这可以显著缩短认证的时间。此外，应用区块链技术还消除了在用户认证过程中SMs之间的通信。因为所有SMs的记录被同步地更新。 由于公共账本是由所有的SMs所维护，所以BLA可以有效抵抗数据库篡改攻击。 三. 方案实现3.1 系统模型 全称 缩写 意义 Audit Department AD 审计机构 service manager SM 服务管理 on-board unit OBU 车子啊单元 roadside unit RSU 路边单元 vehicular fog computing VFC 车辆雾计算 vehicular fog services VFS 车辆雾服务 vehicular fog datacenter VFD 车辆雾数据中心 Witness Peer WP 见证节点 AD (Audit Department):作为一个完全可信的机构，负责OBUs（车载单元）和SMs（服务管理）的注册，并追溯违法车辆 SM：一个区域的服务管理者需要在搭建系统之前就在AD处进行注册，SM主要负责管理所有的VFDs并对其管理区域的OBUs进行认证。每个SM维护一个包含所有车辆访问记录的公共账本。公共账本智能由AD、SMs和WPs所访问。 WP(Witness Peer): WP负责通过共识算法把认证结果写入公共账本的节点，所有的WPs和SMs共同组成了联盟区块链 RSU： 是VFD的管理者并为合法的OBUs提供VFS服务。只属于由一个SM所管理的地区。 OBU： OBU是VFS的用户，配置有计算和通信功能，包括内嵌的计算机、无线网络接口、GPS接收器、导航系统、数字地图等等。在访问VFS之前需要先在AD处注册。 联盟区块链网络（CBN）：由所有地区的SMs和WPs组成。 3.2 目标 保密性： 确保传输的数据无法被敌手解密 完整性： 确保传输的数据无法被敌手篡改 匿名性： 允许所有车辆使用自己定义的伪名并且在访问VFS的过程中，车辆可以通过重新认证自己来改变自己的伪名。使得敌手无法追踪或者计算车辆。 非交互性： 车辆只需要在访问VFS之前发出一个认证或者访问VFS的信息即可，无需其它信息。 可追踪性： 保证AD可以追踪非法车辆并拒绝它们对VFS的访问。 无法抵赖性： 当一辆违法车辆被报告是，则该车辆无法抵赖其错误行为。 轻量性：确保计算与通信开销较低。 3.3 具体实现步骤3.3.1 初始化设置系统参数，包括决定系统安全的大素数、哈希算法、AD的公私钥对。最后保留AD私钥。 3.3.2 注册注册阶段包括SM和OBU的注册 SM注册 随机选择一个整数sk1作为私钥的第一部分，根据这部分私钥计算出公钥pk1。然后把pk1和自己身份id用AD公钥加密发送给AD AD将从SM收到的加密信息用自身私钥解密，在身份检查过后，随机选择一个整数d，并根据这个整数计算出一对公私钥对pk2和sk2，然后通过安全通道发送给SM SM收到AD发来的pk2和sk2，将sk2提取出来与sk1组成完整的私钥，将pk2提取出与pk1组成完整的公钥，同时SM能够通过计算获取sk2是否可靠。 OBU注册：与SM注册过程类似，在此不再赘述 3.3.3 认证 这个阶段只要通过SMs来认证OBUs。在认证之后，SMs将认证结果广播出去，认证结果会在共识阶段由WP利用共识机制写入公共账本（区块链）中，当一个行驶着的OBU首次访问VFS时，需要执行以下步骤： 计算s： 计算hi R C 计算xi 和 k个系数 计算Yi和Vi OBUa将密文发送给离它最近的RSU，假设为RSUm RSUm接收到密文然后转发个区域管理者，假设为SMn 在接收到密文之后SMn进行以下操作： 根据自己身份计算以下数值： 计算R’并恢复原始数据和签名 从恢复出来的数据中获取OBUa的身份，如果对应公钥没在撤销列表，则进行以下计算： 验证以下等式是否成立： 3.3.4 共识 通过x=(heightmodk)+1来决定消息发送者(speaker)，其中height代表当前区块高度。由于选择是消息发送者不会影响共识结果，所以允许同一个消息发送者主持几轮共识过程来节约选择消息发送者的时间。 任何SM可以广播经过签名的认证结果给所有的WPs。 所有的WPs着上一步发送出来的认证结果数据并存在各自的内存中。 经过结块周期t时间之后，已经广播的认证结果组成一个新的区块，由消息发送者发送给其它WPs，要求WPs进行投票并签名。 接收到消息发送者发出的提案请求之后，WPs进行签名并回复。 任何WP在接收到至少(k−f)节点的签名区块时，都会达到共识并发布完整的块。如果签名的区块的数目达不到(k−f)，则将执行下一轮共识。这里，f=(k−1)/3表示系统中允许的最大错误WP数，例如，WP有网络故障。 任何WP在接收到完整的区块之后，从自身内存中删除包含在该区块中的认证结果并开始下一轮的共识。 3.3.5 服务交付在这一个阶段，当一个OBU移动到一个新的RSU的VFD时，可以选择不进行重新认证，过程如下： 当OBU驶入另一个RSU的服务范围时，会提交它的访问请求给RSU，请求包括伪名和时间戳的签名，伪名，时间戳。 同样，RSU会将访问请求转发给它的区域管理者SM SM首先查找自身的本地数据库看是否存在OBU的公钥，如果不存在，则到公共账本中去寻找对应信息。如果OBU的公钥没有在撤销列表当中的话，SM会验证OBU请求中的签名信息，如果认证通过且时间戳有效，SM会直接通知RSU响应OBU的服务请求。否则，SM会拒绝提供服务。 在这整个过程中如果非法车辆被AD所记录，AD会到公共账本中寻找该车辆的身份并通知所有SMs该非法车辆的公钥是无效的并将其添加到撤销列表中。 四. 模拟实验结果4.1 实验环境 4.2 时间开销 认证阶段 共识阶段4.3 在4,7,10个SM的基础下，认证一个请求所需平均时间：RSU逐渐增加和车辆到达时间间隔逐渐增加"},{"title":"为通道添加新的组织（续）","date":"2019-10-24T05:12:54.000Z","path":"2019/10/24/addorg2/","text":"本篇博文为上篇博文“为通道添加新的组织”的可选部分。 更新通道配置包含Org3锚节点因为Org1和Org2已经在通道配置中定义了锚节点，所以Org3的peer节点可以与Org1和Org2的peer节点建立gossip连接。同样，新添加的组织如Org3也应该在通道配置中定义自己的锚节点，让其它组织的新peer可以直接发现一个Org3的peer。 从Org3-CLI继续，为了定义一个Org3锚节点对通道配置进行更新，该过程与上次的配置更新相似。 1.获取最新配置区块：1peer channel fetch config config_block.pb -o orderer.example.com:7050 -c $CHANNEL_NAME --tls --cafile $ORDERER_CA 结果如下：12345root@e6a67979d990:/opt/gopath/src/github.com/hyperledger/fabric/peer# peer channel fetch config config_block.pb -o orderer.example.com:7050 -c $CHANNEL_NAME --tls --cafile $ORDERER_CA2019-10-24 02:55:14.866 UTC [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2019-10-24 02:55:14.883 UTC [cli.common] readBlock -&gt; INFO 002 Received block: 72019-10-24 02:55:14.891 UTC [cli.common] readBlock -&gt; INFO 003 Received block: 52019-10-24 02:55:14.892 UTC [channelCmd] fetch -&gt; INFO 004 Retrieving last config block: 5 2. 文件转换与配置添加configtxlator将.pb文件转化为.json文件，同时jq工具去掉头部，元数据和签名。1configtxlator proto_decode --input config_block.pb --type common.Block | jq .data.data[0].payload.data.config &gt; config.json 123root@e6a67979d990:/opt/gopath/src/github.com/hyperledger/fabric/peer# configtxlator proto_decode --input config_block.pb --type common.Block | jq .data.data[0].payload.data.config &gt; config.jsonroot@e6a67979d990:/opt/gopath/src/github.com/hyperledger/fabric/peer# lsconfig.json config_block.pb crypto mychannel.block scripts 现在的config.json代表着将要被更新的最新的通道配置，再次使用jq工具更新配置JSON文件，添加Org3锚节点。1jq &apos;.channel_group.groups.Application.groups.Org3MSP.values += &#123;&quot;AnchorPeers&quot;:&#123;&quot;mod_policy&quot;: &quot;Admins&quot;,&quot;value&quot;:&#123;&quot;anchor_peers&quot;: [&#123;&quot;host&quot;: &quot;peer0.org3.example.com&quot;,&quot;port&quot;: 11051&#125;]&#125;,&quot;version&quot;: &quot;0&quot;&#125;&#125;&apos; config.json &gt; modified_anchor_config.json 123root@e6a67979d990:/opt/gopath/src/github.com/hyperledger/fabric/peer# jq &apos;.channel_group.groups.Application.groups.Org3MSP.values += &#123;&quot;AnchorPeers&quot;:&#123;&quot;mod_policy&quot;: &quot;Admins&quot;,&quot;value&quot;:&#123;&quot;anchor_peers&quot;: [&#123;&quot;host&quot;: &quot;peer0.org3.example.com&quot;,&quot;port&quot;: 11051&#125;]&#125;,&quot;version&quot;: &quot;0&quot;&#125;&#125;&apos; config.json &gt; modified_anchor_config.jsonroot@e6a67979d990:/opt/gopath/src/github.com/hyperledger/fabric/peer# lsconfig.json config_block.pb crypto modified_anchor_config.json mychannel.block scripts 将.json文件转换为 .pb文件，并计算增量：123configtxlator proto_encode --input config.json --type common.Config --output config.pbconfigtxlator proto_encode --input modified_anchor_config.json --type common.Config --output modified_anchor_config.pbconfigtxlator compute_update --channel_id $CHANNEL_NAME --original config.pb --updated modified_anchor_config.pb --output anchor_update.pb 12345root@e6a67979d990:/opt/gopath/src/github.com/hyperledger/fabric/peer# configtxlator proto_encode --input config.json --type common.Config --output config.pbroot@e6a67979d990:/opt/gopath/src/github.com/hyperledger/fabric/peer# configtxlator proto_encode --input modified_anchor_config.json --type common.Config --output modified_anchor_config.pbroot@e6a67979d990:/opt/gopath/src/github.com/hyperledger/fabric/peer# configtxlator compute_update --channel_id $CHANNEL_NAME --original config.pb --updated modified_anchor_config.pb --output anchor_update.pbroot@e6a67979d990:/opt/gopath/src/github.com/hyperledger/fabric/peer# lsanchor_update.pb config.json config.pb config_block.pb crypto modified_anchor_config.json modified_anchor_config.pb mychannel.block scripts 将anchor_update.pb转化为anchor_update.json:1configtxlator proto_decode --input anchor_update.pb --type common.ConfigUpdate | jq . &gt; anchor_update.json 将更新封装在信封信息（envelope message）中，重新添加之前丢弃的头部,输出anchor_update_in_envelope.json文件：1echo &apos;&#123;&quot;payload&quot;:&#123;&quot;header&quot;:&#123;&quot;channel_header&quot;:&#123;&quot;channel_id&quot;:&quot;mychannel&quot;, &quot;type&quot;:2&#125;&#125;,&quot;data&quot;:&#123;&quot;config_update&quot;:&apos;$(cat anchor_update.json)&apos;&#125;&#125;&#125;&apos; | jq . &gt; anchor_update_in_envelope.json 将anchor_update_in_envelope.json转化为anchor_update_in_envelope.pb1configtxlator proto_encode --input anchor_update_in_envelope.json --type common.Envelope --output anchor_update_in_envelope.pb 结果：123root@e6a67979d990:/opt/gopath/src/github.com/hyperledger/fabric/peer# lsanchor_update.json anchor_update_in_envelope.json config.json config_block.pb modified_anchor_config.json mychannel.blockanchor_update.pb anchor_update_in_envelope.pb config.pb crypto modified_anchor_config.pb scripts 最后进行签名并提交更新，因为这只是对Org3的更新，所以只需要Org3在更新签名即可。由于当前环境身份为Org3身份，因此不需要切换身份。1peer channel update -f anchor_update_in_envelope.pb -c $CHANNEL_NAME -o orderer.example.com:7050 --tls --cafile $ORDERER_CA 123root@e6a67979d990:/opt/gopath/src/github.com/hyperledger/fabric/peer# peer channel update -f anchor_update_in_envelope.pb -c $CHANNEL_NAME -o orderer.example.com:7050 --tls --cafile $ORDERER_CA2019-10-24 03:24:29.270 UTC [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2019-10-24 03:24:29.324 UTC [channelCmd] update -&gt; INFO 002 Successfully submitted channel update orderer接收得到配置更新请求，添加一个配置更新区块。当所有peer接收到该区块，则会处理配置更新。 查看其中一个容器日志，当处理一个新区块中的配置交易时，可以看到gossip重新建立连接，代表配置更新已经成功应用了1docker logs -f peer0.org1.example.com 12345678mit=4ms) commitHash=[742a4724235b86378598f9f77115dee0bac62859d79062a43de1a151b43cef81]2019-10-24 03:24:29.329 UTC [gossip.privdata] StoreBlock -&gt; INFO 2e1 [mychannel] Received block [8] from buffer2019-10-24 03:24:29.370 UTC [gossip.gossip] JoinChan -&gt; INFO 2e2 Joining gossip network of channel mychannel with 3 organizations2019-10-24 03:24:29.370 UTC [gossip.gossip] learnAnchorPeers -&gt; INFO 2e3 Learning about the configured anchor peers of Org2MSP for channel mychannel : [&#123;peer0.org2.example.com 9051&#125;]2019-10-24 03:24:29.370 UTC [gossip.gossip] learnAnchorPeers -&gt; INFO 2e4 Learning about the configured anchor peers of Org3MSP for channel mychannel : [&#123;peer0.org3.example.com 11051&#125;]2019-10-24 03:24:29.370 UTC [gossip.gossip] learnAnchorPeers -&gt; INFO 2e5 Learning about the configured anchor peers of Org1MSP for channel mychannel : [&#123;peer0.org1.example.com 7051&#125;]2019-10-24 03:24:29.370 UTC [gossip.gossip] learnAnchorPeers -&gt; INFO 2e6 Anchor peer with same endpoint, skipping connecting to myself2019-10-24 03:24:29.413 UTC [committer.txvalidator] Validate -&gt; INFO 2e7 [mychannel] Validated block [8] in 83ms 到目前为止，已经成功提交两个配置更新操作，包括添加Org3到通道中和为Org3定义锚节点。"},{"title":"为通道添加新的组织","date":"2019-10-23T03:07:23.000Z","path":"2019/10/23/addorg1/","text":"1. 切换路径并关闭已存在网络1cd /opt/gopath/src/github.com/hyperledger/fabric-samples/first-network/ 执行通道配置更新并不是必需要关闭已有的网络。本次教程只是为了从初始状态开始才将原有网络关闭。1./byfn.sh down 2.生成新的网络12./byfn.sh generate./byfn.sh up 3.添加新组织Org33.1 利用脚本添加新组织Org31./eyfn.sh up 如果顺利运行，你可以看到以下内容：12345678========= All GOOD, EYFN test execution completed =========== _____ _ _ ____ | ____| | \\ | | | _ \\ | _| | \\| | | | | | | |___ | |\\ | | |_| | |_____| |_| \\_| |____/ 3.2 手动添加新组织Org3因为上面步骤已经使用了eyfn.sh脚本，因此需要关闭网络，删除所有容器，并撤销添加Org3的操作。1./eyfn.sh down 网络关闭之后，再次将其恢复12./byfn.sh generate./byfn.sh up 此时网络恢复到执行eyfn.sh脚本之前的状态 3.2.1 生成Org3的加密材料进入org3-artifacts目录1cd org3-artifacts/ 123[root@localhost first-network]# cd org3-artifacts/[root@localhost org3-artifacts]# lsconfigtx.yaml org3-crypto.yaml 生成加密材料1cryptogen generate --config=./org3-crypto.yaml 12[root@localhost org3-artifacts]# cryptogen generate --config=./org3-crypto.yamlorg3.example.com 该命令读取加密材料生成所需要的yaml文件，并利用cryptogen工具为Org3的一个CA和两个与之绑定的peer节点生成密钥和证书。生成的材料放在当前目录的crypto-config文件夹中. 利用configtxgen来以JSON的格式打印Org3指定配置材料，配置让configtxgen在当前目录寻找configtx.yaml文件1export FABRIC_CFG_PATH=$PWD &amp;&amp; configtxgen -printOrg Org3MSP &gt; ../channel-artifacts/org3.json 该命令生成一个org3.json文件，存放在first-network目录下的channel-artifacts文件夹中。该文件包含Org3的策略定义和三个base64格式的证书：管理员用户证书，CA根证书和TLS根证书。该json文件会在后面的步骤中加入到通道配置中。123[root@localhost first-network]# cd channel-artifacts/[root@localhost channel-artifacts]# lschannel.tx genesis.block Org1MSPanchors.tx Org2MSPanchors.tx org3.json 最后将orderer的MSP材料复制到Org3的crypto-config目录下。orderer的TLS根证书允许Org3和网络排序节点的安全通信。1cd ../ &amp;&amp; cp -r crypto-config/ordererOrganizations org3-artifacts/crypto-config/ cp -r 代表拷贝文件夹 123[root@localhost first-network]# cd org3-artifacts/crypto-config/[root@localhost crypto-config]# lsordererOrganizations peerOrganizations 可以看到已经将orderer的MSP材料复制到对应位置。 3.2.2 CLI环境准备更新过程利用配置转换工具：configtxlator。该工具提供独立于SDK的无状态REST API。同时提供了CLI来简化Fabric网路中的配置工作。该工具作用是在不同等效数据表示形式/格式之间轻松转换（在本例子中，在protobufs和json格式之间转换）。另外，该工具可以基于两个通道配置之间的差异来计算配置更新事务。 进入容器并配置ORDERER_CA 和 CHANNEL_NAME的值12docker exec -it cli bashexport ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem &amp;&amp; export CHANNEL_NAME=mychannel 查看是否正确设置对应变量值1echo $ORDERER_CA &amp;&amp; echo $CHANNEL_NAME 123root@f7d186065b85:/opt/gopath/src/github.com/hyperledger/fabric/peer# echo $ORDERER_CA &amp;&amp; echo $CHANNEL_NAME/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pemmychannel 这样的变量设置方式是临时的，一旦退出cli容器，重新进入时就需要再次重新设置。 3.2.3 获取配置获取通道mychannel最新的配置区块。之所以要获取最新的配置区块是因为配置元素是版本化的。可以避免重复的配置更改，同时有助于确保并发性（当需要从通道删除一个组织的时候，例如在一个新组织被添加到通道中之后，版本控制有助于防止同时将两个组织都删除了，而是保证仅仅删除想要删除的组织）1peer channel fetch config config_block.pb -o orderer.example.com:7050 -c $CHANNEL_NAME --tls --cafile $ORDERER_CA 该命令保存二进制protobuf通道配置块到config_block.pb。注意此处的名称和文件后缀选择是随意的，但是建议遵循一个约定，该约定既能表示对象类型也能体现对象的编码（protobuf 或者 json）格式。12345root@f7d186065b85:/opt/gopath/src/github.com/hyperledger/fabric/peer# peer channel fetch config config_block.pb -o orderer.example.com:7050 -c $CHANNEL_NAME --tls --cafile $ORDERER_CA2019-10-22 11:17:44.424 UTC [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2019-10-22 11:17:44.436 UTC [cli.common] readBlock -&gt; INFO 002 Received block: 42019-10-22 11:17:44.438 UTC [cli.common] readBlock -&gt; INFO 003 Received block: 22019-10-22 11:17:44.438 UTC [channelCmd] fetch -&gt; INFO 004 Retrieving last config block: 2 从日志最后一行可以看出通道mychannel最近的配置块实际上是区块2，并不是创世区块。默认情况下该命令返回目标通道的最新区块，在本次示例中最新区块为第三个区块。因为脚本为两个组织在两个独立的通道更新交易中定义了锚节点。所以配置序列如下： 区块0：创世区块 区块1：Org1锚节点更新 区块2：Org2锚节点更新 3.2.3 配置文件格式转换与修改使用configtxlator工具将通道配置块解码为JSON格式（人类可读取和修改）。 同时必须将所有与我们要进行的更改无关的标题，元数据，创建者签名等剥离。 通过使用jq工具完成此任务：1configtxlator proto_decode --input config_block.pb --type common.Block | jq .data.data[0].payload.data.config &gt; config.json 执行完毕生成一个简洁的JSON对象config.json作为后续配置更新的基准文件。12root@f7d186065b85:/opt/gopath/src/github.com/hyperledger/fabric/peer# lschannel-artifacts config.json config_block.pb crypto log.txt mychannel.block scripts 3.2.4 添加Org3加密材料再次使用jq工具追加Org3的配置定义Org3.json到通道的应用组字段中并将输出命名为modified_config.json。1jq -s &apos;.[0] * &#123;&quot;channel_group&quot;:&#123;&quot;groups&quot;:&#123;&quot;Application&quot;:&#123;&quot;groups&quot;: &#123;&quot;Org3MSP&quot;:.[1]&#125;&#125;&#125;&#125;&#125;&apos; config.json ./channel-artifacts/org3.json &gt; modified_config.json 可以看到已经生成modified_config.json文件12root@f7d186065b85:/opt/gopath/src/github.com/hyperledger/fabric/peer# lschannel-artifacts config.json config_block.pb crypto log.txt modified_config.json mychannel.block scripts 此时。已经有两个JSON文件，分别是config.json和modified_config.json。初始文件只包含Org1和Org2的信息，而修改后的文件包含了三个组织的信息。此时，只需重新编码这两个JSON文件并计算增量即可。 将config.json转回protobuf格式，命名为config.pb1configtxlator proto_encode --input config.json --type common.Config --output config.pb 将modified_config.json转回protobuf格式，命名为modified_config.pb1configtxlator proto_encode --input modified_config.json --type common.Config --output modified_config.pb 查看对应文件是否生成12root@f7d186065b85:/opt/gopath/src/github.com/hyperledger/fabric/peer# lschannel-artifacts config.json config.pb config_block.pb crypto log.txt modified_config.json modified_config.pb mychannel.block scripts 利用configtxlator计算两个配置protobufs的增量，以下命令会输出一个新的protobuf名为org3_update.pb:1configtxlator compute_update --channel_id $CHANNEL_NAME --original config.pb --updated modified_config.pb --output org3_update.pb 可以看到所需要文件已经生成12root@f7d186065b85:/opt/gopath/src/github.com/hyperledger/fabric/peer# lschannel-artifacts config.json config.pb config_block.pb crypto log.txt modified_config.json modified_config.pb mychannel.block org3_update.pb scripts 新生成的org3_update.pb 包含Org3的定义和指向Org1和Org2的高级指针。 在提交通道更新之前，我们需要执行最后的几步。 首先将 org3_update.pb 解码为可编辑的JSON格式，命名为org3_update.json1configtxlator proto_decode --input org3_update.pb --type common.ConfigUpdate | jq . &gt; org3_update.json 12root@f7d186065b85:/opt/gopath/src/github.com/hyperledger/fabric/peer# lschannel-artifacts config.json config.pb config_block.pb crypto log.txt modified_config.json modified_config.pb mychannel.block org3_update.json org3_update.pb scripts 在有解码后的org3_update.json文件之后，需要将其封装在信封消息之中。这一步会将我们先前删除的头部数据添加回来，封装完的文件命名为org3_update_in_envelope.json1echo &apos;&#123;&quot;payload&quot;:&#123;&quot;header&quot;:&#123;&quot;channel_header&quot;:&#123;&quot;channel_id&quot;:&quot;mychannel&quot;, &quot;type&quot;:2&#125;&#125;,&quot;data&quot;:&#123;&quot;config_update&quot;:&apos;$(cat org3_update.json)&apos;&#125;&#125;&#125;&apos; | jq . &gt; org3_update_in_envelope.json 123root@f7d186065b85:/opt/gopath/src/github.com/hyperledger/fabric/peer# lschannel-artifacts config.pb crypto modified_config.json mychannel.block org3_update.pb scriptsconfig.json config_block.pb log.txt modified_config.pb org3_update.json org3_update_in_envelope.json 最后再次利用configtxlator工具将org3_update_in_envelope.json转化为Fabric所需要的完整protobuf格式，命名为org3_update_in_envelope.pb:1onfigtxlator proto_encode --input org3_update_in_envelope.json --type common.Envelope --output org3_update_in_envelope.pb 123root@f7d186065b85:/opt/gopath/src/github.com/hyperledger/fabric/peer# lschannel-artifacts config.pb crypto modified_config.json mychannel.block org3_update.pb org3_update_in_envelope.pbconfig.json config_block.pb log.txt modified_config.pb org3_update.json org3_update_in_envelope.json scripts 3.2.5 签名并提交配置更新现在在CLI容器中已经有了org3_update_in_envelope.pb。但是在配置写入账本之前，必需要有来自Admin用户的签名，在已有通道应用组中修改策略设置为默认“MAJORITY”，即需要大多数现有的组织管理员的签名。因为目前只有Org1和Org2两个组织，所以需要这两个组织的签名。如果没有这两个签名，排序服务交易未能满足策略而拒绝交易。 Org1 Admin签名：1peer channel signconfigtx -f org3_update_in_envelope.pb 12root@f7d186065b85:/opt/gopath/src/github.com/hyperledger/fabric/peer# peer channel signconfigtx -f org3_update_in_envelope.pb2019-10-22 14:03:32.763 UTC [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized 在组织之间切换以签署配置事务（或执行其他任何操作）并不能反映真实的Fabric操作。单个容器永远不会安装整个网络的加密材料。而是需要将配置更新安全地带外传递给Org2管理员进行检查和批准。 切换到Org2环境变量1234567export CORE_PEER_LOCALMSPID=&quot;Org2MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/users/Admin@org2.example.com/mspexport CORE_PEER_ADDRESS=peer0.org2.example.com:9051 发出更新命令，此时Org2 Admin的签名将会附加到此调用中。因此不需手动再次为protobuf签名。1peer channel update -f org3_update_in_envelope.pb -c $CHANNEL_NAME -o orderer.example.com:7050 --tls --cafile $ORDERER_CA 122019-10-22 14:06:55.118 UTC [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2019-10-22 14:06:55.164 UTC [channelCmd] update -&gt; INFO 002 Successfully submitted channel update 3.2.6 选择配置新加入的节点通过创世块进行引导，但是创世块中不包含通道配置更新中被新添加进去的组织。因此新节点无法利用gossip，因为在新节点获得添加组织到通道的配置交易前，无法验证其它节点从自己组织中转发过来的区块。新添加的节点必须进行以下配置（二选一）使得新的节点能够从排序服务中接收区块。 利用静态选举模式，将节点配置为组织领导 12 CORE_PEER_GOSSIP_USELEADERELECTION=falseCORE_PEER_GOSSIP_ORGLEADER=true 所有添加到通道中的新节点配置必须相同 利用动态领导选举模式，配置节点使用领导选举12CORE_PEER_GOSSIP_USELEADERELECTION=trueCORE_PEER_GOSSIP_ORGLEADER=false 由于新添加组织中的节点无法形成成员视图，因此该配置是与静态模式相似的。因为每个节点在一开始的时候都会宣称自己是领导者。但是一旦它们获得添加组织到通道的配置交易更新，则组织只会有一个领导节点。所以如果最后希望组织节点利用领导选举则建议使用这种模式。 以上两种模式配置都是在first-network目录中的base文件夹下的peer-base.yaml文件中进行。以下截取可以配置部分：12345678910111213141516171819peer-base: image: hyperledger/fabric-peer:$IMAGE_TAG environment: - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock # the following setting starts chaincode containers on the same # bridge network as the peers # https://docs.docker.com/compose/networking/ - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=$&#123;COMPOSE_PROJECT_NAME&#125;_byfn - FABRIC_LOGGING_SPEC=INFO #- FABRIC_LOGGING_SPEC=DEBUG - CORE_PEER_TLS_ENABLED=true - CORE_PEER_GOSSIP_USELEADERELECTION=true - CORE_PEER_GOSSIP_ORGLEADER=false - CORE_PEER_PROFILE_ENABLED=true - CORE_PEER_TLS_CERT_FILE=/etc/hyperledger/fabric/tls/server.crt - CORE_PEER_TLS_KEY_FILE=/etc/hyperledger/fabric/tls/server.key - CORE_PEER_TLS_ROOTCERT_FILE=/etc/hyperledger/fabric/tls/ca.crt working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: peer node start 3.2.7 将Org3加入通道以上步骤只是将Org3添加到Fabric网络中，但是此时Org3还没有进入任何通道 首先，启动Org3 的节点容器和一个Org3对应的CLI容器在first-network目录下：1docker-compose -f docker-compose-org3.yaml up -d 1234567[root@localhost first-network]# docker-compose -f docker-compose-org3.yaml up -dCreating volume &quot;net_peer0.org3.example.com&quot; with default driverCreating volume &quot;net_peer1.org3.example.com&quot; with default driverWARNING: Found orphan containers (cli, peer0.org2.example.com, orderer.example.com, peer1.org2.example.com, peer1.org1.example.com, peer0.org1.example.com) for this project. If you removed or renamed this service in your compose file, you can run this command with the --remove-orphans flag to clean it up.Creating peer1.org3.example.com ... doneCreating peer0.org3.example.com ... doneCreating Org3cli ... done compose文件已经配置了初始网络连接，所以两个peer节点和CLI容器能够与现有的peer和排序节点连接。进入Org3-CLI容器1docker exec -it Org3cli bash 设置两个关键环境变量ORDERER_CA 和 CHANNEL_NAME1export ORDERER_CA=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem &amp;&amp; export CHANNEL_NAME=mychannel 确认变量正确设置：1echo $ORDERER_CA &amp;&amp; echo $CHANNEL_NAME 发送一个调用给排序服务请求mychannel通道的创世区块。以为上述步骤中通道已经成功更新，因此排序服务可以验证调用中附带的Org3签名。如果Org3没有成功添加到通道配置，则该请求将会被排序服务拒绝。 使用peer channel fetch命令检索区块：1peer channel fetch 0 mychannel.block -o orderer.example.com:7050 -c $CHANNEL_NAME --tls --cafile $ORDERER_CA 将0作为参数表明希望得到的是通道账本中的第一个块（即创世块）。如果使用peer channel fetch config命令，返回的是第五个区块——Org3定义的配置更新，但新加入通道必需从创世区块0开始。122019-10-23 01:56:32.458 UTC [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2019-10-23 01:56:32.498 UTC [cli.common] readBlock -&gt; INFO 002 Received block: 0 利用创世块mychannel.block加入通道1peer channel join -b mychannel.block 123root@e6a67979d990:/opt/gopath/src/github.com/hyperledger/fabric/peer# peer channel join -b mychannel.block2019-10-23 01:59:59.244 UTC [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2019-10-23 01:59:59.307 UTC [channelCmd] executeJoin -&gt; INFO 002 Successfully submitted proposal to join channel 如果需要将Org3的第二个peer也加入通道，只需要设置TLS和ADDRESS的值后再次执行上述命令：123export CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org3.example.com/peers/peer1.org3.example.com/tls/ca.crt &amp;&amp; export CORE_PEER_ADDRESS=peer1.org3.example.com:12051peer channel join -b mychannel.block 3.2.8 升级并调用链码升级链码版本同时更新背书策略来包含Org3。在Org3-CLI容器执行1peer chaincode install -n mycc -v 2.0 -p github.com/chaincode/chaincode_example02/go/ 1234root@e6a67979d990:/opt/gopath/src/github.com/hyperledger/fabric/peer# peer chaincode install -n mycc -v 2.0 -p github.com/chaincode/chaincode_example02/go/2019-10-23 02:14:13.535 UTC [chaincodeCmd] checkChaincodeCmdParams -&gt; INFO 001 Using default escc2019-10-23 02:14:13.535 UTC [chaincodeCmd] checkChaincodeCmdParams -&gt; INFO 002 Using default vscc2019-10-23 02:14:13.918 UTC [chaincodeCmd] install -&gt; INFO 003 Installed remotely response:&lt;status:200 payload:&quot;OK&quot; &gt; 回到原本的CLI容器，在Org1和Org2的peer上安装新版本的链码，以为上次执行通道更新调用使用Org2 管理员身份，所以当前容器代表身份仍然是peer0.org21peer chaincode install -n mycc -v 2.0 -p github.com/chaincode/chaincode_example02/go/ 1234root@f7d186065b85:/opt/gopath/src/github.com/hyperledger/fabric/peer# peer chaincode install -n mycc -v 2.0 -p github.com/chaincode/chaincode_example02/go/2019-10-23 02:18:08.241 UTC [chaincodeCmd] checkChaincodeCmdParams -&gt; INFO 001 Using default escc2019-10-23 02:18:08.241 UTC [chaincodeCmd] checkChaincodeCmdParams -&gt; INFO 002 Using default vscc2019-10-23 02:18:08.548 UTC [chaincodeCmd] install -&gt; INFO 003 Installed remotely response:&lt;status:200 payload:&quot;OK&quot; &gt; 将容器环境切换为Org11234567export CORE_PEER_LOCALMSPID=&quot;Org1MSP&quot;export CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crtexport CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/mspexport CORE_PEER_ADDRESS=peer0.org1.example.com:7051 再次执行链码安装1peer chaincode install -n mycc -v 2.0 -p github.com/chaincode/chaincode_example02/go/ 1234root@f7d186065b85:/opt/gopath/src/github.com/hyperledger/fabric/peer# peer chaincode install -n mycc -v 2.0 -p github.com/chaincode/chaincode_example02/go/2019-10-23 02:19:40.763 UTC [chaincodeCmd] checkChaincodeCmdParams -&gt; INFO 001 Using default escc2019-10-23 02:19:40.763 UTC [chaincodeCmd] checkChaincodeCmdParams -&gt; INFO 002 Using default vscc2019-10-23 02:19:40.920 UTC [chaincodeCmd] install -&gt; INFO 003 Installed remotely response:&lt;status:200 payload:&quot;OK&quot; &gt; 直至目前，链码升级已经准备完毕，这次升级并没有修改底层源代码，只是为通道mychannel中的mycc链码简单添加Org3到背书策略中。 任何满足链码实例化策略的身份都可以发布更新调用。默认情况下，该身份是通道管理员。 1peer chaincode upgrade -o orderer.example.com:7050 --tls $CORE_PEER_TLS_ENABLED --cafile $ORDERER_CA -C $CHANNEL_NAME -n mycc -v 2.0 -c &apos;&#123;&quot;Args&quot;:[&quot;init&quot;,&quot;a&quot;,&quot;90&quot;,&quot;b&quot;,&quot;210&quot;]&#125;&apos; -P &quot;OR (&apos;Org1MSP.peer&apos;,&apos;Org2MSP.peer&apos;,&apos;Org3MSP.peer&apos;)&quot; -v标志指明新版本 -P可以看到已经将Org3添加到策略中去 与实例化调用一样，链码更新也需要调用init方法，如果链码中init需要参数，则更新时同样需要。 更新调用添加了一个新的区块——区块6.同时允许Org3 peer在背书阶段执行交易。123root@f7d186065b85:/opt/gopath/src/github.com/hyperledger/fabric/peer# peer chaincode upgrade -o orderer.example.com:7050 --tls $CORE_PEER_TLS_ENABLED --cafile $ORDERER_CA -C $CHANNEL_NAME -n mycc -v 2.0 -c &apos;&#123;&quot;Args&quot;:[&quot;init&quot;,&quot;a&quot;,&quot;90&quot;,&quot;b&quot;,&quot;210&quot;]&#125;&apos; -P &quot;OR (&apos;Org1MSP.peer&apos;,&apos;Org2MSP.peer&apos;,&apos;Org3MSP.peer&apos;)&quot;2019-10-23 02:25:18.999 UTC [chaincodeCmd] checkChaincodeCmdParams -&gt; INFO 001 Using default escc2019-10-23 02:25:18.999 UTC [chaincodeCmd] checkChaincodeCmdParams -&gt; INFO 002 Using default vscc 回到Org3-CLI容器并查询a的值，这个过程需要耗费一些时间，因为对应peer需要构建并启动链码镜像：1peer chaincode query -C $CHANNEL_NAME -n mycc -c &apos;&#123;&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]&#125;&apos; 结果12root@e6a67979d990:/opt/gopath/src/github.com/hyperledger/fabric/peer# peer chaincode query -C $CHANNEL_NAME -n mycc -c &apos;&#123;&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]&#125;&apos;90 调用链码：1peer chaincode invoke -o orderer.example.com:7050 --tls $CORE_PEER_TLS_ENABLED --cafile $ORDERER_CA -C $CHANNEL_NAME -n mycc -c &apos;&#123;&quot;Args&quot;:[&quot;invoke&quot;,&quot;a&quot;,&quot;b&quot;,&quot;10&quot;]&#125;&apos; 12root@e6a67979d990:/opt/gopath/src/github.com/hyperledger/fabric/peer# peer chaincode invoke -o orderer.example.com:7050 --tls $CORE_PEER_TLS_ENABLED --cafile $ORDERER_CA -C $CHANNEL_NAME -n mycc -c &apos;&#123;&quot;Args&quot;:[&quot;invoke&quot;,&quot;a&quot;,&quot;b&quot;,&quot;10&quot;]&#125;&apos;2019-10-23 02:45:08.595 UTC [chaincodeCmd] chaincodeInvokeOrQuery -&gt; INFO 001 Chaincode invoke successful. result: status:200 最后查询：1peer chaincode query -C $CHANNEL_NAME -n mycc -c &apos;&#123;&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]&#125;&apos; 12root@e6a67979d990:/opt/gopath/src/github.com/hyperledger/fabric/peer# peer chaincode query -C $CHANNEL_NAME -n mycc -c &apos;&#123;&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]&#125;&apos;80 3.2.9 结论通道配置更新过程确实涉及很多，但是各个步骤都有一个逻辑方法。 最终的结果是形成一个以protobuf二进制格式表示的增量交易对象，然后获取必要数量的管理员签名，以便通道配置更新交易满足通道的修改政策。主要涉及各种文件的转换与获取，如下流程图所示： 附：文件转化过程："},{"title":"couchdb","date":"2019-10-22T09:13:08.000Z","path":"2019/10/22/couchdb/","text":"Fabric默认使用LevelDB，在对链码数据建模为JSON之后，CouchDB具有针对状态数据库数据内容执行丰富和复杂查询的附加功能。 1. 关闭已经启动的fabric网络1./byfn.sh down 2. 生成启动first-network步骤生成网络启动所需要材料123456cryptogen generate --config=./crypto-config.yamlexport FABRIC_CFG_PATH=$PWDconfigtxgen -profile TwoOrgsOrdererGenesis -channelID byfn-sys-channel -outputBlock ./channel-artifacts/genesis.blockexport CHANNEL_NAME=mychannel &amp;&amp; configtxgen -profile TwoOrgsChannel -outputCreateChannelTx ./channel-artifacts/channel.tx -channelID $CHANNEL_NAMEconfigtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org1MSPanchors.tx -channelID $CHANNEL_NAME -asOrg Org1MSPconfigtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org2MSPanchors.tx -channelID $CHANNEL_NAME -asOrg Org2MSP 3.启动CouchDB1docker-compose -f docker-compose-cli.yaml -f docker-compose-couch.yaml up -d 123456789101112131415161718192021222324252627282930[root@localhost first-network]# docker-compose -f docker-compose-cli.yaml -f docker-compose-couch.yaml up -dCreating network &quot;net_byfn&quot; with the default driverCreating volume &quot;net_peer0.org2.example.com&quot; with default driverCreating volume &quot;net_peer1.org2.example.com&quot; with default driverCreating volume &quot;net_peer1.org1.example.com&quot; with default driverCreating volume &quot;net_peer0.org1.example.com&quot; with default driverCreating volume &quot;net_orderer.example.com&quot; with default driverCreating couchdb3 ... doneCreating orderer.example.com ... doneCreating couchdb1 ... doneCreating couchdb0 ... doneCreating couchdb2 ... doneCreating peer1.org2.example.com ... doneCreating peer0.org1.example.com ... doneCreating peer0.org2.example.com ... doneCreating peer1.org1.example.com ... doneCreating cli ... done[root@localhost first-network]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES0b819576bb29 hyperledger/fabric-tools:latest &quot;/bin/bash&quot; About a minute ago Up About a minute cli924a616c7885 hyperledger/fabric-peer:latest &quot;peer node start&quot; About a minute ago Up About a minute 0.0.0.0:8051-&gt;8051/tcp peer1.org1.example.come0d8ddd1cbdc hyperledger/fabric-peer:latest &quot;peer node start&quot; About a minute ago Up About a minute 0.0.0.0:9051-&gt;9051/tcp peer0.org2.example.com7d48491351e0 hyperledger/fabric-peer:latest &quot;peer node start&quot; About a minute ago Up About a minute 0.0.0.0:7051-&gt;7051/tcp peer0.org1.example.com14f48756e507 hyperledger/fabric-peer:latest &quot;peer node start&quot; About a minute ago Up About a minute 0.0.0.0:10051-&gt;10051/tcp peer1.org2.example.com9cce36571279 hyperledger/fabric-couchdb &quot;tini -- /docker-ent…&quot; About a minute ago Up About a minute 4369/tcp, 9100/tcp, 0.0.0.0:6984-&gt;5984/tcp couchdb142761a41bb38 hyperledger/fabric-couchdb &quot;tini -- /docker-ent…&quot; About a minute ago Up About a minute 4369/tcp, 9100/tcp, 0.0.0.0:7984-&gt;5984/tcp couchdb21d6db23645d0 hyperledger/fabric-couchdb &quot;tini -- /docker-ent…&quot; About a minute ago Up About a minute 4369/tcp, 9100/tcp, 0.0.0.0:5984-&gt;5984/tcp couchdb08b2facd544eb hyperledger/fabric-orderer:latest &quot;orderer&quot; About a minute ago Up About a minute 0.0.0.0:7050-&gt;7050/tcp orderer.example.coma2cdad7d30ab hyperledger/fabric-couchdb &quot;tini -- /docker-ent…&quot; About a minute ago Up About a minute 4369/tcp, 9100/tcp, 0.0.0.0:8984-&gt;5984/tcp couchdb3 注：因为不是在生产环境，所以对couchDB容器做了到主机端口的映射，使得开发环境中可以直接使用CouchDB的REST API，可通过CouchDB的WEB界面可视化数据库。生产环境需要避免端口映射，限制外部对CouchDB容器的访问。 4. 创建加入通道并更新锚节点12345docker exec -it cli bashexport CHANNEL_NAME=mychannelpeer channel create -o orderer.example.com:7050 -c $CHANNEL_NAME -f ./channel-artifacts/channel.tx --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pempeer channel join -b mychannel.blockpeer channel update -o orderer.example.com:7050 -c $CHANNEL_NAME -f ./channel-artifacts/Org1MSPanchors.tx --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem 123456CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/users/Admin@org2.example.com/mspCORE_PEER_ADDRESS=peer0.org2.example.com:9051CORE_PEER_LOCALMSPID=&quot;Org2MSP&quot;CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt peer channel join -b mychannel.blockpeer channel update -o orderer.example.com:7050 -c $CHANNEL_NAME -f ./channel-artifacts/Org2MSPanchors.tx --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem #### 5.链码安装与实例化12peer chaincode install -n marbles -v 1.0 -p github.com/chaincode/marbles02/gopeer chaincode instantiate -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n marbles -v 1.0 -c &apos;&#123;&quot;Args&quot;:[&quot;init&quot;]&#125;&apos; -P &quot;OR (&apos;Org1MSP.peer&apos;,&apos;Org2MSP.peer&apos;)&quot; 6.链码调用123456peer chaincode invoke -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n marbles -c &apos;&#123;&quot;Args&quot;:[&quot;initMarble&quot;,&quot;marble1&quot;,&quot;blue&quot;,&quot;35&quot;,&quot;tom&quot;]&#125;&apos;peer chaincode invoke -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n marbles -c &apos;&#123;&quot;Args&quot;:[&quot;initMarble&quot;,&quot;marble2&quot;,&quot;red&quot;,&quot;50&quot;,&quot;tom&quot;]&#125;&apos;peer chaincode invoke -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n marbles -c &apos;&#123;&quot;Args&quot;:[&quot;initMarble&quot;,&quot;marble3&quot;,&quot;blue&quot;,&quot;70&quot;,&quot;tom&quot;]&#125;&apos;peer chaincode invoke -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n marbles -c &apos;&#123;&quot;Args&quot;:[&quot;transferMarble&quot;,&quot;marble2&quot;,&quot;jerry&quot;]&#125;&apos;peer chaincode invoke -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n marbles -c &apos;&#123;&quot;Args&quot;:[&quot;transferMarblesBasedOnColor&quot;,&quot;blue&quot;,&quot;jerry&quot;]&#125;&apos;peer chaincode invoke -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n marbles -c &apos;&#123;&quot;Args&quot;:[&quot;delete&quot;,&quot;marble1&quot;]&#125;&apos; 1234562019-10-21 06:39:47.840 UTC [chaincodeCmd] chaincodeInvokeOrQuery -&gt; INFO 001 Chaincode invoke successful. result: status:200 2019-10-21 06:39:47.892 UTC [chaincodeCmd] chaincodeInvokeOrQuery -&gt; INFO 001 Chaincode invoke successful. result: status:2002019-10-21 06:39:47.945 UTC [chaincodeCmd] chaincodeInvokeOrQuery -&gt; INFO 001 Chaincode invoke successful. result: status:200 2019-10-21 06:39:48.002 UTC [chaincodeCmd] chaincodeInvokeOrQuery -&gt; INFO 001 Chaincode invoke successful. result: status:2002019-10-21 06:39:48.050 UTC [chaincodeCmd] chaincodeInvokeOrQuery -&gt; INFO 001 Chaincode invoke successful. result: status:200 payload:&quot;Transferred 0 blue marbles to jerry&quot;2019-10-21 06:41:05.065 UTC [chaincodeCmd] chaincodeInvokeOrQuery -&gt; INFO 001 Chaincode invoke successful. result: status:200 因为CouchDB容器与主机做了端口映射，所以可以通过CouchDB Web接口来可视化状态数据库通过访问 http://localhost:5984/_utils,可以看到下图界面： 7.链码查询1peer chaincode query -C $CHANNEL_NAME -n marbles -c &apos;&#123;&quot;Args&quot;:[&quot;readMarble&quot;,&quot;marble2&quot;]&#125;&apos; 1&#123;&quot;color&quot;:&quot;red&quot;,&quot;docType&quot;:&quot;marble&quot;,&quot;name&quot;:&quot;marble2&quot;,&quot;owner&quot;:&quot;jerry&quot;,&quot;size&quot;:50&#125; 历史查询1peer chaincode query -C $CHANNEL_NAME -n marbles -c &apos;&#123;&quot;Args&quot;:[&quot;getHistoryForMarble&quot;,&quot;marble1&quot;]&#125;&apos; 12[&#123;&quot;TxId&quot;:&quot;f94ca6cf8d184cb999c589eaa2c69ee8d73e76eba9c9e617f81076eec4c386d9&quot;, &quot;Value&quot;:&#123;&quot;docType&quot;:&quot;marble&quot;,&quot;name&quot;:&quot;marble1&quot;,&quot;color&quot;:&quot;blue&quot;,&quot;size&quot;:35,&quot;owner&quot;:&quot;tom&quot;&#125;, &quot;Timestamp&quot;:&quot;2019-10-21 06:39:47.834102301 +0000 UTC&quot;, &quot;IsDelete&quot;:&quot;false&quot;&#125;,&#123;&quot;TxId&quot;:&quot;0a8d6d9aaf3d2cb4088d92d6269572a8aca0134efc295c776f8be56b8bd1ef5f&quot;, &quot;Value&quot;:null, &quot;Timestamp&quot;:&quot;2019-10-21 06:41:05.059717786 +0000 UTC&quot;, &quot;IsDelete&quot;:&quot;true&quot;&#125;] 根据数据内容查询1peer chaincode query -C $CHANNEL_NAME -n marbles -c &apos;&#123;&quot;Args&quot;:[&quot;queryMarblesByOwner&quot;,&quot;jerry&quot;]&#125;&apos; 附1：为什么要使用CouchDBCouchDB是一种NoSQL解决方案。是一个面向文件的数据库，其中文件字段存储为键值映射。 字段可以是简单的键值对，列表或映射。 除了LevelDB支持的键/复合键/键范围查询外，CouchDB还支持丰富的全数据查询功能，例如针对整个区块链数据的非键查询，因为其数据内容以JSON格式存储，并且完全可查询。 因此，CouchDB在许多使用场景中可以满足LevelDB不支持的链码、审计和报告要求。 另外，CouchDB属于CAP定理的AP类型（可用性和分区容差）。 它使用具有最终一致性的主-主复制模型。 但是，在每个peer节点下，没有数据库副本，数据库的写入是一致且持久的（不是最终一致性）。 CouchDB是第一个用于Fabric的外部可插入状态数据库，并且可能并且应该有其他外部数据库选项。 例如，IBM为其区块链启用关系数据库。 并且可能还需要CP类型（一致性和分区容差）数据库，以便在不保证应用程序级别的情况下实现数据一致性。 附2：关于数据持久性如果要在peer容器或者CouchDB容器上保持数据持久性，可以选择将主机中目录挂在到容器的相关目录中。如：在 docker-compose-cli.yaml 文件的peer容器说明中添加：12volumes: - /var/hyperledger/peer0:/var/hyperledger/production 对于CouchDB容器，添加以下两行在CouchDB容器说明中：12volumes: - /var/hyperledger/couchdb0:/opt/couchdb/data"},{"title":"建立你的第一个fabric网络（byfn）——step by step","date":"2019-10-22T09:05:10.000Z","path":"2019/10/22/byfn2/","text":"byfn.sh 中执行了什么命令，如何使整个fabric网络启动。这就是这篇文章所要分析的内容。 一. 工具介绍1. cryptogen生成加密材料，包括x509证书和签名密钥。这些材料允许网络实体在通信和交易时进行验证和签名。利用crypto-config.yaml文件来生成为组织和组织中的组件生成证书和密钥集。每个组织都有一个唯一的根CA，与组织中的组件相绑定。crypto-config.yaml示例文件内容如下：1234567891011121314151617181920212223242526OrdererOrgs: - Name: Orderer Domain: example.com EnableNodeOUs: true Specs: - Hostname: orderer - Hostname: orderer2 - Hostname: orderer3 - Hostname: orderer4 - Hostname: orderer5PeerOrgs: - Name: Org1 Domain: org1.example.com EnableNodeOUs: true Template: Count: 2 Users: Count: 1 - Name: Org2 Domain: org2.example.com EnableNodeOUs: true Template: Count: 2 Users: Count: 1 “Specs”： 在配置中启动主机是显示定义，模板如下所示 Specs 是 Spec条目组。每个Spec条目包括两个内容： Hostname: (必需) 所需主机名，不需域名. CommonName: (可选) 指定CN模板或者显式覆写。默认模板如下： &quot;{{.Hostname}}.{{.Domain}}&quot; 包含 Spec.Hostname和 Org.Domain 例子如下：12345Specs: - Hostname: foo # 代表&quot;foo.org1.example.com&quot; CommonName: foo27.org5.example.com # 覆写上面设置的主机名 - Hostname: bar - Hostname: baz “Template”： 允许定义利用模板来顺序创建1个或多个主机默认情况下，从0到Count-1以”peer%d”的形式出现 .可以修改节点数量(Count), 开始的索引(Start)和用于构建名称的模板 (Hostname). 注意: Template 和 Specs 不是互斥的。两部分可以同时定义，将会创建聚合节点。只需要留意避免名称冲突 . 例子如下： 1234Template: Count: 2 Start: 5 Hostname: &#123;&#123;.Prefix&#125;&#125;&#123;&#123;.Index&#125;&#125; # 默认 12345# ---------------------------------------------------------------------------# &quot;Users&quot;# ---------------------------------------------------------------------------# Count: 除了管理员外的用户账户# --------------------------------------------------------------------------- 在cryptogen工具运行之后，生成的证书和密钥将会保存到crypto-config文件夹。在crypto-config.yaml文件中列出5个排序节点与排序组织相绑定，因此cryptogen会为这5个排序节点生成证书，但是除非使用了raft或者kafka排序服务，否则只有一个节点用于独立排序服务实现并用来创建系统通道和mychannel。 2. configtxgenconfigtxgen工具用来生成4个配置元素： 排序节点的创世块 genesis block 通道配置交易 configuration transaction 两个锚定节点交易 anchor peer transaction 排序节点块是排序服务中的创世块，通道配置交易会在通道创建的时候广播给排序节点。而锚定节点交易即指明通道上每个组织是锚定节点。（锚定节点即负责组织与外部以及其它组织通信的节点） 与cryptogen工具类似，configtxgen也需要利用一个配置文件configtx.yaml来生成对应材料。该配置文件包含示例网络的定义。 包含三个成员： 一个排序组织(OrdererOrg)和两个节点组织(Org1 &amp; Org2)每个组织管理和维护两个节点。 文件同时指定了一个联盟——SampleConsortium， 包含上述两个节点组织。特别注意文件最后Profiles部分，出现了几个唯一的配置： TwoOrgsOrdererGenesis ：为单节点排序服务生成创世区块 SampleMultiNodeEtcdRaft ：为Raft排序服务生成创世区块。-o 选项并指定 etcdraft 时有效 SampleDevModeKafka ：为Kafka排序服务生成创世区块。-o 选项并指定 kafka 时有效 TwoOrgsChannel ：为通道生成创世块 注意，SampleConsortium是在系统级配置文件中定义的，然后由通道级配置文件引用。 通道存在于联盟的权限范围内，所有联盟都必须在整个网络范围内定义。 该文件还包含两个值得注意的附加规范。首先，为每个对等组织指定锚点对等体（peer0.org1.example.com＆peer0.org2.example.com）。其次，指向每个成员的MSP目录的位置，从而允许将每个组织的根证书存储在排序节点创始块中。 二. 命令运行1. 生成证书及密钥1cryptogen generate --config=./crypto-config.yaml 因为安装二进制文件的时候已经把该执行文件路径放到环境变量中了，所以可以直接使用。123[root@localhost first-network]# cryptogen generate --config=./crypto-config.yaml org1.example.comorg2.example.com 可以看到该目录下多了一个crypto-config子目录12345[root@localhost first-network]# ls base ccp-template.yaml connection-org1.yaml connection-org3.yaml docker-compose-cli.yaml docker-compose-etcdraft2.yaml org3-artifactsbyfn.sh channel-artifacts connection-org2.json crypto-config docker-compose-couch-org3.yaml docker-compose-kafka.yaml README.mdccp-generate.sh configtx.yaml connection-org2.yaml crypto-config.yaml docker-compose-couch.yaml docker-compose-org3.yaml scriptsccp-template.json connection-org1.json connection-org3.json docker-compose-ca.yaml docker-compose-e2e-template.yaml eyfn.sh 2. 生成配置交易2.1 创建排序创世块首先需要配置configtx.yaml文件路径，使得工具configtxgen可以找到该文件1export FABRIC_CFG_PATH=$PWD 执行命令1configtxgen -profile TwoOrgsOrdererGenesis -channelID byfn-sys-channel -outputBlock ./channel-artifacts/genesis.block 使用配置TwoOrgsOrdererGenesis，通道ID（channelID代表系统通道的名称）设置为byfn-sys-channel，生成创世块为channel-artifacts目录下的genesis.block12345678[root@localhost first-network]# configtxgen -profile TwoOrgsOrdererGenesis -channelID byfn-sys-channel -outputBlock ./channel-artifacts/genesis.block2019-10-20 15:00:32.995 CST [common.tools.configtxgen] main -&gt; INFO 001 Loading configuration2019-10-20 15:00:33.048 CST [common.tools.configtxgen.localconfig] completeInitialization -&gt; INFO 002 orderer type: solo2019-10-20 15:00:33.048 CST [common.tools.configtxgen.localconfig] Load -&gt; INFO 003 Loaded configuration: /opt/gopath/src/github.com/hyperledger/fabric-samples/first-network/configtx.yaml2019-10-20 15:00:33.106 CST [common.tools.configtxgen.localconfig] completeInitialization -&gt; INFO 004 orderer type: solo2019-10-20 15:00:33.106 CST [common.tools.configtxgen.localconfig] LoadTopLevel -&gt; INFO 005 Loaded configuration: /opt/gopath/src/github.com/hyperledger/fabric-samples/first-network/configtx.yaml2019-10-20 15:00:33.108 CST [common.tools.configtxgen] doOutputBlock -&gt; INFO 006 Generating genesis block2019-10-20 15:00:33.109 CST [common.tools.configtxgen] doOutputBlock -&gt; INFO 007 Writing genesis block 如果需要使用Raft排序服务，则使用配置SampleMultiNodeEtcdRaft，命令如下1configtxgen -profile SampleMultiNodeEtcdRaft -channelID byfn-sys-channel -outputBlock ./channel-artifacts/genesis.block 如果需要使用Kafka排序服务，则使用配置SampleDevModeKafka，命令如下1configtxgen -profile SampleDevModeKafka -channelID byfn-sys-channel -outputBlock ./channel-artifacts/genesis.block 2.3 创建通道配置交易设置通道名称作为环境变量同时生成配置交易1export CHANNEL_NAME=mychannel &amp;&amp; configtxgen -profile TwoOrgsChannel -outputCreateChannelTx ./channel-artifacts/channel.tx -channelID $CHANNEL_NAME 使用配置TwoOrgsChannel，生成配置交易为channel-artifacts目录下的channel.tx1234567[root@localhost first-network]# export CHANNEL_NAME=mychannel &amp;&amp; configtxgen -profile TwoOrgsChannel -outputCreateChannelTx ./channel-artifacts/channel.tx -channelID $CHANNEL_NAME2019-10-20 15:33:00.766 CST [common.tools.configtxgen] main -&gt; INFO 001 Loading configuration2019-10-20 15:33:00.820 CST [common.tools.configtxgen.localconfig] Load -&gt; INFO 002 Loaded configuration: /opt/gopath/src/github.com/hyperledger/fabric-samples/first-network/configtx.yaml2019-10-20 15:33:00.872 CST [common.tools.configtxgen.localconfig] completeInitialization -&gt; INFO 003 orderer type: solo2019-10-20 15:33:00.872 CST [common.tools.configtxgen.localconfig] LoadTopLevel -&gt; INFO 004 Loaded configuration: /opt/gopath/src/github.com/hyperledger/fabric-samples/first-network/configtx.yaml2019-10-20 15:33:00.872 CST [common.tools.configtxgen] doOutputChannelCreateTx -&gt; INFO 005 Generating new channel configtx2019-10-20 15:33:00.874 CST [common.tools.configtxgen] doOutputChannelCreateTx -&gt; INFO 006 Writing new channel tx 可以注意到在该命令中并没有明确的指令指明使用的是那种排序服务（如：Kafka 或 Raft），因为TwoOrgsChannel会使用你创建创世块时所指定的排序服务配置。 2.4 创建两个锚定节点交易创建组织1（Org1）锚节点（anchor peer）1configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org1MSPanchors.tx -channelID $CHANNEL_NAME -asOrg Org1MSP 1234567[root@localhost first-network]# configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org1MSPanchors.tx -channelID $CHANNEL_NAME -asOrg Org1MSP2019-10-20 16:07:11.323 CST [common.tools.configtxgen] main -&gt; INFO 001 Loading configuration2019-10-20 16:07:11.376 CST [common.tools.configtxgen.localconfig] Load -&gt; INFO 002 Loaded configuration: /opt/gopath/src/github.com/hyperledger/fabric-samples/first-network/configtx.yaml2019-10-20 16:07:11.428 CST [common.tools.configtxgen.localconfig] completeInitialization -&gt; INFO 003 orderer type: solo2019-10-20 16:07:11.428 CST [common.tools.configtxgen.localconfig] LoadTopLevel -&gt; INFO 004 Loaded configuration: /opt/gopath/src/github.com/hyperledger/fabric-samples/first-network/configtx.yaml2019-10-20 16:07:11.428 CST [common.tools.configtxgen] doOutputAnchorPeersUpdate -&gt; INFO 005 Generating anchor peer update2019-10-20 16:07:11.428 CST [common.tools.configtxgen] doOutputAnchorPeersUpdate -&gt; INFO 006 Writing anchor peer update 创建同一通道上组织2（Org2）的锚节点（anchor peer）1configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org2MSPanchors.tx -channelID $CHANNEL_NAME -asOrg Org2MSP 1234567[root@localhost first-network]# configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org2MSPanchors.tx -channelID $CHANNEL_NAME -asOrg Org2MSP2019-10-20 16:07:50.112 CST [common.tools.configtxgen] main -&gt; INFO 001 Loading configuration2019-10-20 16:07:50.166 CST [common.tools.configtxgen.localconfig] Load -&gt; INFO 002 Loaded configuration: /opt/gopath/src/github.com/hyperledger/fabric-samples/first-network/configtx.yaml2019-10-20 16:07:50.218 CST [common.tools.configtxgen.localconfig] completeInitialization -&gt; INFO 003 orderer type: solo2019-10-20 16:07:50.218 CST [common.tools.configtxgen.localconfig] LoadTopLevel -&gt; INFO 004 Loaded configuration: /opt/gopath/src/github.com/hyperledger/fabric-samples/first-network/configtx.yaml2019-10-20 16:07:50.218 CST [common.tools.configtxgen] doOutputAnchorPeersUpdate -&gt; INFO 005 Generating anchor peer update2019-10-20 16:07:50.218 CST [common.tools.configtxgen] doOutputAnchorPeersUpdate -&gt; INFO 006 Writing anchor peer update 此时查看channel-artifacts文件夹，可以看到四个所需要配置文件均生成12[root@localhost channel-artifacts]# lschannel.tx genesis.block Org1MSPanchors.tx Org2MSPanchors.tx 3.启动网络利用docker-compose文件启动网络，使用上面步骤生成的 genesis.block 文件来启动排序服务1docker-compose -f docker-compose-cli.yaml up -d 123456789101112131415161718192021[root@localhost first-network]# docker-compose -f docker-compose-cli.yaml up -dCreating network &quot;net_byfn&quot; with the default driverCreating volume &quot;net_peer0.org2.example.com&quot; with default driverCreating volume &quot;net_peer1.org2.example.com&quot; with default driverCreating volume &quot;net_peer1.org1.example.com&quot; with default driverCreating volume &quot;net_peer0.org1.example.com&quot; with default driverCreating volume &quot;net_orderer.example.com&quot; with default driverCreating peer0.org2.example.com ... doneCreating orderer.example.com ... doneCreating peer1.org1.example.com ... doneCreating peer1.org2.example.com ... doneCreating peer0.org1.example.com ... doneCreating cli ... done[root@localhost first-network]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES3797ff79a60f hyperledger/fabric-tools:latest &quot;/bin/bash&quot; 47 seconds ago Up 46 seconds cli1cd801dfe6a9 hyperledger/fabric-peer:latest &quot;peer node start&quot; 49 seconds ago Up 46 seconds 0.0.0.0:9051-&gt;9051/tcp peer0.org2.example.com87bdc5b7f31e hyperledger/fabric-peer:latest &quot;peer node start&quot; 49 seconds ago Up 47 seconds 0.0.0.0:10051-&gt;10051/tcp peer1.org2.example.com35067e605249 hyperledger/fabric-peer:latest &quot;peer node start&quot; 49 seconds ago Up 46 seconds 0.0.0.0:8051-&gt;8051/tcp peer1.org1.example.com349a8be2cfa9 hyperledger/fabric-orderer:latest &quot;orderer&quot; 49 seconds ago Up 46 seconds 0.0.0.0:7050-&gt;7050/tcp orderer.example.com1c458fb55bd8 hyperledger/fabric-peer:latest &quot;peer node start&quot; 49 seconds ago Up 46 seconds 0.0.0.0:7051-&gt;7051/tcp peer0.org1.example.com 可以看到已经启动两个组织的4个节点，一个排序节点，和一个cli容器 4. 创建并加入通道上面已经创建通道配置交易，如果想要创建额外的通道，可以重复上述通道配置创建过程使用configtx.yaml中相同或者不同的配置。首先，进入cli容器1docker exec -it cli bash 进入cli容器结果：12[root@localhost first-network]# docker exec -it cli bashroot@3797ff79a60f:/opt/gopath/src/github.com/hyperledger/fabric/peer# 因为cli容器中的默认环境变量是 peer0.org1.example.com 对应的环境变量，因此调用 peer0.org1.example.com 时可以不做变量设置，直接调用即可。但是如果需要调用其它节点，则需要在调用命令执行之前设置对应节点的环境变量。peer0.org1的环境变量如下：123456# Environment variables for PEER0CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/mspCORE_PEER_ADDRESS=peer0.org1.example.com:7051CORE_PEER_LOCALMSPID=&quot;Org1MSP&quot;CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt peer0.org2的环境变量如下：1234CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/users/Admin@org2.example.com/msp CORE_PEER_ADDRESS=peer0.org2.example.com:7051 CORE_PEER_LOCALMSPID=&quot;Org2MSP&quot; CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt 4.1 创建通道将生成的通道配置交易channel.tx传给orderer，作为通道创建需求的一部分，注意通道名称不能出现大写字母。12export CHANNEL_NAME=mychannelpeer channel create -o orderer.example.com:7050 -c $CHANNEL_NAME -f ./channel-artifacts/channel.tx --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem 命令中的cafile是orderer根证书的本地路径，可以用来验证TLS握手。命令会返回一个创世区块 -&lt;CHANNEL_NAME.block&gt;，包含channel.tx中指定的配置信息。本次示例返回mychannel.block，在加入通道时需要使用到。123452019-10-20 09:21:41.951 UTC [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2019-10-20 09:21:41.998 UTC [cli.common] readBlock -&gt; INFO 002 Received block: 0root@3797ff79a60f:/opt/gopath/src/github.com/hyperledger/fabric/peer# lschannel-artifacts crypto mychannel.block scripts 4.2 加入通道将peer0.org1.example.com加入通道1peer channel join -b mychannel.block 122019-10-20 09:25:43.238 UTC [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2019-10-20 09:25:43.279 UTC [channelCmd] executeJoin -&gt; INFO 002 Successfully submitted proposal to join channel 将peer0.org2.example.com加入通道，需要先设置环境变量为peer0.org2.example.com对应的环境变量再执行命令12345CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/users/Admin@org2.example.com/mspCORE_PEER_ADDRESS=peer0.org2.example.com:9051CORE_PEER_LOCALMSPID=&quot;Org2MSP&quot;CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt peer channel join -b mychannel.block 122019-10-20 09:30:00.602 UTC [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2019-10-20 09:30:00.639 UTC [channelCmd] executeJoin -&gt; INFO 002 Successfully submitted proposal to join channel 4.3 更新锚节点更新锚节点会传播到通道的定义。从本质上来讲，是在通道的创世区块上添加配置信息。但这不是修改创世区块，而是添加锚节点的定义到链中。 更新通道定义将Org1的锚节点定义为 peer0.org1.example.com。将生成的锚节点交易Org1MSPanchors.tx传给orderer1peer channel update -o orderer.example.com:7050 -c $CHANNEL_NAME -f ./channel-artifacts/Org1MSPanchors.tx --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem 122019-10-20 11:28:10.858 UTC [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2019-10-20 11:28:10.877 UTC [channelCmd] update -&gt; INFO 002 Successfully submitted channel update 更新通道定义将Org2的锚节点定义为 peer0.org2.example.com：12345CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/users/Admin@org2.example.com/mspCORE_PEER_ADDRESS=peer0.org2.example.com:9051 CORE_PEER_LOCALMSPID=&quot;Org2MSP&quot;CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crtpeer channel update -o orderer.example.com:7050 -c $CHANNEL_NAME -f ./channel-artifacts/Org2MSPanchors.tx --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem 122019-10-20 11:29:46.293 UTC [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2019-10-20 11:29:46.320 UTC [channelCmd] update -&gt; INFO 002 Successfully submitted channel update 4.4 安装链码本示例中，使用简单已经存在的链码。应用通过链码与区块链账本进行交互。因此在每个需要执行和背书的节点上都需要安装链码，然后在对应通道中将链码实例化。 首先安装链码，该命令将链码放置到对应节点的文件系统中。每个链码名称和版本只能对应一个链码源代码。1peer chaincode install -n mycc -v 1.0 -p github.com/chaincode/chaincode_example02/go/ -n 链码名称 -v 链码版本 -p 链码路径 -l 链码语言（默认golang）1232019-10-20 11:52:41.045 UTC [chaincodeCmd] checkChaincodeCmdParams -&gt; INFO 001 Using default escc2019-10-20 11:52:41.045 UTC [chaincodeCmd] checkChaincodeCmdParams -&gt; INFO 002 Using default vscc2019-10-20 11:52:41.613 UTC [chaincodeCmd] install -&gt; INFO 003 Installed remotely response:&lt;status:200 payload:&quot;OK&quot; &gt; Node.js版本1peer chaincode install -n mycc -v 1.0 -l node -p /opt/gopath/src/github.com/chaincode/chaincode_example02/node/ Java版本1peer chaincode install -n mycc -v 1.0 -l java -p /opt/gopath/src/github.com/chaincode/chaincode_example02/java/ 将链码安装在Org2的peer0上,修改环境变量1234CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/users/Admin@org2.example.com/mspCORE_PEER_ADDRESS=peer0.org2.example.com:9051CORE_PEER_LOCALMSPID=&quot;Org2MSP&quot;CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt 安装链码：1peer chaincode install -n mycc -v 1.0 -p github.com/chaincode/chaincode_example02/go/ 1232019-10-20 11:57:55.352 UTC [chaincodeCmd] checkChaincodeCmdParams -&gt; INFO 001 Using default escc2019-10-20 11:57:55.352 UTC [chaincodeCmd] checkChaincodeCmdParams -&gt; INFO 002 Using default vscc2019-10-20 11:57:55.585 UTC [chaincodeCmd] install -&gt; INFO 003 Installed remotely response:&lt;status:200 payload:&quot;OK&quot; &gt; 4.5 实例化链码实例化链码即初始化通道上的链码并为链码设置背书策略，然后为目标节点启动链码容器。其中-P参数对应的是指定的背书策略，指定对应交易验证所需要的条件。 在示例中使用 -P &quot;AND (&#39;Org1MSP.peer&#39;,&#39;Org2MSP.peer&#39;)&quot;，表示需要来自Org1和Org2的背书交易才能验证通过，缺一不可。如果将其中的AND改成OR，则只需要两者之一即可。 实例化链码：1peer chaincode instantiate -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n mycc -v 1.0 -c &apos;&#123;&quot;Args&quot;:[&quot;init&quot;,&quot;a&quot;, &quot;100&quot;, &quot;b&quot;,&quot;200&quot;]&#125;&apos; -P &quot;AND (&apos;Org1MSP.peer&apos;,&apos;Org2MSP.peer&apos;)&quot; 122019-10-20 12:10:25.198 UTC [chaincodeCmd] checkChaincodeCmdParams -&gt; INFO 001 Using default escc2019-10-20 12:10:25.198 UTC [chaincodeCmd] checkChaincodeCmdParams -&gt; INFO 002 Using default vscc 如果需要其它节点参加到账本的交互中来的话，只需要将同样名称、版本和语言的链码源码安装到对应的节点上。当节点想要与特定链码交互的时候，对应的链码容器将会被启动。 实例化完成后可以看到启动了一个链码容器：123456789[root@localhost ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESfba2e8af5e59 dev-peer0.org2.example.com-mycc-1.0-15b571b3ce849066b7ec74497da3b27e54e0df1345daff3951b94245ce09c42b &quot;chaincode -peer.add…&quot; 2 minutes ago Up 2 minutes dev-peer0.org2.example.com-mycc-1.03797ff79a60f hyperledger/fabric-tools:latest &quot;/bin/bash&quot; 4 hours ago Up 4 hours cli1cd801dfe6a9 hyperledger/fabric-peer:latest &quot;peer node start&quot; 4 hours ago Up 4 hours 0.0.0.0:9051-&gt;9051/tcp peer0.org2.example.com87bdc5b7f31e hyperledger/fabric-peer:latest &quot;peer node start&quot; 4 hours ago Up 4 hours 0.0.0.0:10051-&gt;10051/tcp peer1.org2.example.com35067e605249 hyperledger/fabric-peer:latest &quot;peer node start&quot; 4 hours ago Up 4 hours 0.0.0.0:8051-&gt;8051/tcp peer1.org1.example.com349a8be2cfa9 hyperledger/fabric-orderer:latest &quot;orderer&quot; 4 hours ago Up 4 hours 0.0.0.0:7050-&gt;7050/tcp orderer.example.com1c458fb55bd8 hyperledger/fabric-peer:latest &quot;peer node start&quot; 4 hours ago Up 4 hours 0.0.0.0:7051-&gt;7051/tcp peer0.org1.example.com Node.js版本1peer chaincode instantiate -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n mycc -l node -v 1.0 -c &apos;&#123;&quot;Args&quot;:[&quot;init&quot;,&quot;a&quot;, &quot;100&quot;, &quot;b&quot;,&quot;200&quot;]&#125;&apos; -P &quot;AND (&apos;Org1MSP.peer&apos;,&apos;Org2MSP.peer&apos;)&quot; Java版本1peer chaincode instantiate -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n mycc -l java -v 1.0 -c &apos;&#123;&quot;Args&quot;:[&quot;init&quot;,&quot;a&quot;, &quot;100&quot;, &quot;b&quot;,&quot;200&quot;]&#125;&apos; -P &quot;AND (&apos;Org1MSP.peer&apos;,&apos;Org2MSP.peer&apos;)&quot; 4.6 链码查询1peer chaincode query -C $CHANNEL_NAME -n mycc -c &apos;&#123;&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]&#125;&apos; 12root@3797ff79a60f:/opt/gopath/src/github.com/hyperledger/fabric/peer# peer chaincode query -C $CHANNEL_NAME -n mycc -c &apos;&#123;&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]&#125;&apos;100 4.7 链码调用1peer chaincode invoke -o orderer.example.com:7050 --tls true --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n mycc --peerAddresses peer0.org1.example.com:7051 --tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt --peerAddresses peer0.org2.example.com:9051 --tlsRootCertFiles /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt -c &apos;&#123;&quot;Args&quot;:[&quot;invoke&quot;,&quot;a&quot;,&quot;b&quot;,&quot;10&quot;]&#125;&apos; 12019-10-20 12:29:16.689 UTC [chaincodeCmd] chaincodeInvokeOrQuery -&gt; INFO 001 Chaincode invoke successful. result: status:200 再次查询1peer chaincode query -C $CHANNEL_NAME -n mycc -c &apos;&#123;&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]&#125;&apos; 12root@3797ff79a60f:/opt/gopath/src/github.com/hyperledger/fabric/peer# peer chaincode query -C $CHANNEL_NAME -n mycc -c &apos;&#123;&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]&#125;&apos;90 此时可以看到存在两个链码镜像，因为链码调用的时候peer0.org1需要与账本交互，此前已经安装了对应链码，因此会自动启动对应的链码容器。12345678910[root@localhost ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES3a32eea0e068 dev-peer0.org1.example.com-mycc-1.0-384f11f484b9302df90b453200cfb25174305fce8f53f4e94d45ee3b6cab0ce9 &quot;chaincode -peer.add…&quot; 2 seconds ago Up 2 seconds dev-peer0.org1.example.com-mycc-1.0fba2e8af5e59 dev-peer0.org2.example.com-mycc-1.0-15b571b3ce849066b7ec74497da3b27e54e0df1345daff3951b94245ce09c42b &quot;chaincode -peer.add…&quot; 15 minutes ago Up 15 minutes dev-peer0.org2.example.com-mycc-1.03797ff79a60f hyperledger/fabric-tools:latest &quot;/bin/bash&quot; 4 hours ago Up 4 hours cli1cd801dfe6a9 hyperledger/fabric-peer:latest &quot;peer node start&quot; 4 hours ago Up 4 hours 0.0.0.0:9051-&gt;9051/tcp peer0.org2.example.com87bdc5b7f31e hyperledger/fabric-peer:latest &quot;peer node start&quot; 4 hours ago Up 4 hours 0.0.0.0:10051-&gt;10051/tcp peer1.org2.example.com35067e605249 hyperledger/fabric-peer:latest &quot;peer node start&quot; 4 hours ago Up 4 hours 0.0.0.0:8051-&gt;8051/tcp peer1.org1.example.com349a8be2cfa9 hyperledger/fabric-orderer:latest &quot;orderer&quot; 4 hours ago Up 4 hours 0.0.0.0:7050-&gt;7050/tcp orderer.example.com1c458fb55bd8 hyperledger/fabric-peer:latest &quot;peer node start&quot; 4 hours ago Up 4 hours 0.0.0.0:7051-&gt;7051/tcp peer0.org1.example.com 4.8 在第三个节点上安装链码本次将链码安装在Org2的peer1上。同样，首先修改环境变量：1234CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/users/Admin@org2.example.com/mspCORE_PEER_ADDRESS=peer1.org2.example.com:10051CORE_PEER_LOCALMSPID=&quot;Org2MSP&quot;CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer1.org2.example.com/tls/ca.crt 安装链码：1peer chaincode install -n mycc -v 1.0 -p github.com/chaincode/chaincode_example02/go/ 1232019-10-20 12:40:01.588 UTC [chaincodeCmd] checkChaincodeCmdParams -&gt; INFO 001 Using default escc2019-10-20 12:40:01.588 UTC [chaincodeCmd] checkChaincodeCmdParams -&gt; INFO 002 Using default vscc2019-10-20 12:40:01.809 UTC [chaincodeCmd] install -&gt; INFO 003 Installed remotely response:&lt;status:200 payload:&quot;OK&quot; &gt; 因为在上述链码中，变量a被初始化为100，接着在调用的时候被转走10，因此对a的查询最后应该返回90。为了确认我们可以在Org2的peer1上进行查询，首先应该先加入通道12345CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/users/Admin@org2.example.com/mspCORE_PEER_ADDRESS=peer1.org2.example.com:10051 CORE_PEER_LOCALMSPID=&quot;Org2MSP&quot;CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer1.org2.example.com/tls/ca.crt peer channel join -b mychannel.block 122019-10-20 12:45:00.417 UTC [channelCmd] InitCmdFactory -&gt; INFO 001 Endorser and orderer connections initialized2019-10-20 12:45:00.439 UTC [channelCmd] executeJoin -&gt; INFO 002 Successfully submitted proposal to join channel 加入通道后即可进行查询：1peer chaincode query -C $CHANNEL_NAME -n mycc -c &apos;&#123;&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]&#125;&apos; 12root@3797ff79a60f:/opt/gopath/src/github.com/hyperledger/fabric/peer# peer chaincode query -C $CHANNEL_NAME -n mycc -c &apos;&#123;&quot;Args&quot;:[&quot;query&quot;,&quot;a&quot;]&#125;&apos;90 返回结果无误，而且在查询过程中，需要等待一段时间才会有响应，是因为在Org2的peer1节点上也不存在着已经启动的链码容器，因为这是该节点第一次与账本交互，因此会启动对应的链码容器，花费一定时间。1234567891011[root@localhost ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESb25b1a4c1ea3 dev-peer1.org2.example.com-mycc-1.0-26c2ef32838554aac4f7ad6f100aca865e87959c9a126e86d764c8d01f8346ab &quot;chaincode -peer.add…&quot; 2 minutes ago Up 2 minutes dev-peer1.org2.example.com-mycc-1.03a32eea0e068 dev-peer0.org1.example.com-mycc-1.0-384f11f484b9302df90b453200cfb25174305fce8f53f4e94d45ee3b6cab0ce9 &quot;chaincode -peer.add…&quot; 23 minutes ago Up 23 minutes dev-peer0.org1.example.com-mycc-1.0fba2e8af5e59 dev-peer0.org2.example.com-mycc-1.0-15b571b3ce849066b7ec74497da3b27e54e0df1345daff3951b94245ce09c42b &quot;chaincode -peer.add…&quot; 38 minutes ago Up 38 minutes dev-peer0.org2.example.com-mycc-1.03797ff79a60f hyperledger/fabric-tools:latest &quot;/bin/bash&quot; 4 hours ago Up 4 hours cli1cd801dfe6a9 hyperledger/fabric-peer:latest &quot;peer node start&quot; 4 hours ago Up 4 hours 0.0.0.0:9051-&gt;9051/tcp peer0.org2.example.com87bdc5b7f31e hyperledger/fabric-peer:latest &quot;peer node start&quot; 4 hours ago Up 4 hours 0.0.0.0:10051-&gt;10051/tcp peer1.org2.example.com35067e605249 hyperledger/fabric-peer:latest &quot;peer node start&quot; 4 hours ago Up 4 hours 0.0.0.0:8051-&gt;8051/tcp peer1.org1.example.com349a8be2cfa9 hyperledger/fabric-orderer:latest &quot;orderer&quot; 4 hours ago Up 4 hours 0.0.0.0:7050-&gt;7050/tcp orderer.example.com1c458fb55bd8 hyperledger/fabric-peer:latest &quot;peer node start&quot; 4 hours ago Up 4 hours 0.0.0.0:7051-&gt;7051/tcp peer0.org1.example.com 注： 如果需要对账本成功执行读/写操作，必需要在对应节点上安装链码。链码容器会在初始化或者传统读写交易的触发下才会开始启动。 通道中的所有节点都会维护一个精确的账本副本，将不可篡改和顺序的区块数据组成区块链，来维护当前状态。这些节点也包括了没有安装链码但已经加入该通道的节点。 如果要访问链码，只需要在对应节点上安装上链码源码即可，因为链码已经被实例化过了。 4.9 查看交易1docker logs -f cli 4.10 查看链码日志123docker logs dev-peer0.org2.example.com-mycc-1.0docker logs dev-peer0.org1.example.com-mycc-1.0docker logs dev-peer1.org2.example.com-mycc-1.0 123456789101112131415161718192021222324252627[root@localhost ~]# docker logs dev-peer0.org2.example.com-mycc-1.0ex02 InitAval = 100, Bval = 200ex02 InvokeQuery Response:&#123;&quot;Name&quot;:&quot;a&quot;,&quot;Amount&quot;:&quot;100&quot;&#125;ex02 InvokeAval = 90, Bval = 210[root@localhost ~]# docker logs dev-peer0.org1.example.com-mycc-1.0ex02 InvokeQuery Response:&#123;&quot;Name&quot;:&quot;a&quot;,&quot;Amount&quot;:&quot;100&quot;&#125;ex02 InvokeAval = 90, Bval = 210ex02 InvokeQuery Response:&#123;&quot;Name&quot;:&quot;a&quot;,&quot;Amount&quot;:&quot;90&quot;&#125;ex02 InvokeQuery Response:&#123;&quot;Name&quot;:&quot;a&quot;,&quot;Amount&quot;:&quot;90&quot;&#125;ex02 InvokeQuery Response:&#123;&quot;Name&quot;:&quot;a&quot;,&quot;Amount&quot;:&quot;90&quot;&#125;ex02 InvokeQuery Response:&#123;&quot;Name&quot;:&quot;a&quot;,&quot;Amount&quot;:&quot;90&quot;&#125;[root@localhost ~]# docker logs dev-peer1.org2.example.com-mycc-1.0ex02 InvokeQuery Response:&#123;&quot;Name&quot;:&quot;a&quot;,&quot;Amount&quot;:&quot;90&quot;&#125;ex02 InvokeQuery Response:&#123;&quot;Name&quot;:&quot;a&quot;,&quot;Amount&quot;:&quot;90&quot;&#125;"},{"title":"建立你的第一个fabric网络（byfn）——脚本版","date":"2019-10-22T09:05:04.000Z","path":"2019/10/22/byfn1/","text":"在利用脚本建立第一个网络之前，需要先下载fabric-sample。如果安装环境是时候使用bootstrap.sh默认安装，则fabric-sample是已经下载的了。否则进入目录 /opt/opt/gopath/src/github.com/hyperledger/ 下克隆fabric-sample项目。以下教程默认已经安装fabric-sample 1. 进入first-network目录12cd /opt/opt/gopath/src/github.com/hyperledger/fabric-sample/first-networkls 可以看到目录下存在名为byfn.sh的脚本文件，下面将利用该脚本文件启动fabric网络12345[root@localhost first-network]# lsbase ccp-template.yaml connection-org1.yaml connection-org3.yaml docker-compose-couch-org3.yaml docker-compose-kafka.yaml README.mdbyfn.sh channel-artifacts connection-org2.json crypto-config.yaml docker-compose-couch.yaml docker-compose-org3.yaml scriptsccp-generate.sh configtx.yaml connection-org2.yaml docker-compose-ca.yaml docker-compose-e2e-template.yaml eyfn.shccp-template.json connection-org1.json connection-org3.json docker-compose-cli.yaml docker-compose-etcdraft2.yaml org3-artifacts 2. 创建实体证书和配置交易1./byfn.sh generate 执行结果如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071[root@localhost first-network]# ./byfn.sh generateGenerating certs and genesis block for channel &apos;mychannel&apos; with CLI timeout of &apos;10&apos; seconds and CLI delay of &apos;3&apos; secondsContinue? [Y/n] yproceeding .../opt/gopath/src/github.com/hyperledger/fabric/release/linux-amd64/bin/cryptogen############################################################### Generate certificates using cryptogen tool ###################################################################+ cryptogen generate --config=./crypto-config.yamlorg1.example.comorg2.example.com+ res=0+ set +xGenerate CCP files for Org1 and Org2/opt/gopath/src/github.com/hyperledger/fabric/release/linux-amd64/bin/configtxgen################################################################### Generating Orderer Genesis block ########################################################################CONSENSUS_TYPE=solo+ &apos;[&apos; solo == solo &apos;]&apos;+ configtxgen -profile TwoOrgsOrdererGenesis -channelID byfn-sys-channel -outputBlock ./channel-artifacts/genesis.block2019-10-19 11:01:15.267 CST [common.tools.configtxgen] main -&gt; INFO 001 Loading configuration2019-10-19 11:01:15.324 CST [common.tools.configtxgen.localconfig] completeInitialization -&gt; INFO 002 orderer type: solo2019-10-19 11:01:15.324 CST [common.tools.configtxgen.localconfig] Load -&gt; INFO 003 Loaded configuration: /opt/gopath/src/github.com/hyperledger/fabric-samples/first-network/configtx.yaml2019-10-19 11:01:15.376 CST [common.tools.configtxgen.localconfig] completeInitialization -&gt; INFO 004 orderer type: solo2019-10-19 11:01:15.376 CST [common.tools.configtxgen.localconfig] LoadTopLevel -&gt; INFO 005 Loaded configuration: /opt/gopath/src/github.com/hyperledger/fabric-samples/first-network/configtx.yaml2019-10-19 11:01:15.378 CST [common.tools.configtxgen] doOutputBlock -&gt; INFO 006 Generating genesis block2019-10-19 11:01:15.378 CST [common.tools.configtxgen] doOutputBlock -&gt; INFO 007 Writing genesis block+ res=0+ set +x#################################################################### Generating channel configuration transaction &apos;channel.tx&apos; ####################################################################+ configtxgen -profile TwoOrgsChannel -outputCreateChannelTx ./channel-artifacts/channel.tx -channelID mychannel2019-10-19 11:01:15.401 CST [common.tools.configtxgen] main -&gt; INFO 001 Loading configuration2019-10-19 11:01:15.454 CST [common.tools.configtxgen.localconfig] Load -&gt; INFO 002 Loaded configuration: /opt/gopath/src/github.com/hyperledger/fabric-samples/first-network/configtx.yaml2019-10-19 11:01:15.507 CST [common.tools.configtxgen.localconfig] completeInitialization -&gt; INFO 003 orderer type: solo2019-10-19 11:01:15.507 CST [common.tools.configtxgen.localconfig] LoadTopLevel -&gt; INFO 004 Loaded configuration: /opt/gopath/src/github.com/hyperledger/fabric-samples/first-network/configtx.yaml2019-10-19 11:01:15.507 CST [common.tools.configtxgen] doOutputChannelCreateTx -&gt; INFO 005 Generating new channel configtx2019-10-19 11:01:15.509 CST [common.tools.configtxgen] doOutputChannelCreateTx -&gt; INFO 006 Writing new channel tx+ res=0+ set +x######################################################################## Generating anchor peer update for Org1MSP ###########################################################################+ configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org1MSPanchors.tx -channelID mychannel -asOrg Org1MSP2019-10-19 11:01:15.554 CST [common.tools.configtxgen] main -&gt; INFO 001 Loading configuration2019-10-19 11:01:15.606 CST [common.tools.configtxgen.localconfig] Load -&gt; INFO 002 Loaded configuration: /opt/gopath/src/github.com/hyperledger/fabric-samples/first-network/configtx.yaml2019-10-19 11:01:15.658 CST [common.tools.configtxgen.localconfig] completeInitialization -&gt; INFO 003 orderer type: solo2019-10-19 11:01:15.658 CST [common.tools.configtxgen.localconfig] LoadTopLevel -&gt; INFO 004 Loaded configuration: /opt/gopath/src/github.com/hyperledger/fabric-samples/first-network/configtx.yaml2019-10-19 11:01:15.658 CST [common.tools.configtxgen] doOutputAnchorPeersUpdate -&gt; INFO 005 Generating anchor peer update2019-10-19 11:01:15.658 CST [common.tools.configtxgen] doOutputAnchorPeersUpdate -&gt; INFO 006 Writing anchor peer update+ res=0+ set +x######################################################################## Generating anchor peer update for Org2MSP ###########################################################################+ configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org2MSPanchors.tx -channelID mychannel -asOrg Org2MSP2019-10-19 11:01:15.678 CST [common.tools.configtxgen] main -&gt; INFO 001 Loading configuration2019-10-19 11:01:15.731 CST [common.tools.configtxgen.localconfig] Load -&gt; INFO 002 Loaded configuration: /opt/gopath/src/github.com/hyperledger/fabric-samples/first-network/configtx.yaml2019-10-19 11:01:15.783 CST [common.tools.configtxgen.localconfig] completeInitialization -&gt; INFO 003 orderer type: solo2019-10-19 11:01:15.783 CST [common.tools.configtxgen.localconfig] LoadTopLevel -&gt; INFO 004 Loaded configuration: /opt/gopath/src/github.com/hyperledger/fabric-samples/first-network/configtx.yaml2019-10-19 11:01:15.783 CST [common.tools.configtxgen] doOutputAnchorPeersUpdate -&gt; INFO 005 Generating anchor peer update2019-10-19 11:01:15.783 CST [common.tools.configtxgen] doOutputAnchorPeersUpdate -&gt; INFO 006 Writing anchor peer update+ res=0+ set +x 该步骤执行以下命令 为网络实体生成证书和密钥 生成启动排序服务的创世区块 生成配置通道所需要的配置交易集合 3. 启动网络1./byfn.sh up 该命令默认编译并启动golang链码镜像如果使用node.js或者java链码，可以使用以下命令：12./byfn.sh -l node //node.js链码启动命令./byfn.sh -l java //java链码启动命令 执行结果：123456789101112131415161718192021222324252627282930Creating network &quot;net_byfn&quot; with the default driverCreating volume &quot;net_peer0.org2.example.com&quot; with default driverCreating volume &quot;net_peer1.org2.example.com&quot; with default driverCreating volume &quot;net_peer1.org1.example.com&quot; with default driverCreating volume &quot;net_peer0.org1.example.com&quot; with default driverCreating volume &quot;net_orderer.example.com&quot; with default driverCreating peer0.org2.example.com ... doneCreating orderer.example.com ... doneCreating peer1.org2.example.com ... doneCreating peer1.org1.example.com ... doneCreating peer0.org1.example.com ... doneCreating cli ... doneCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES7bccf9fbbdfc hyperledger/fabric-tools:latest &quot;/bin/bash&quot; 1 second ago Up Less than a second cli5965f6980409 hyperledger/fabric-peer:latest &quot;peer node start&quot; 3 seconds ago Up Less than a second 0.0.0.0:7051-&gt;7051/tcp peer0.org1.example.comc0b4948a2120 hyperledger/fabric-peer:latest &quot;peer node start&quot; 3 seconds ago Up Less than a second 0.0.0.0:8051-&gt;8051/tcp peer1.org1.example.com36d1b4ee086a hyperledger/fabric-peer:latest &quot;peer node start&quot; 3 seconds ago Up Less than a second 0.0.0.0:10051-&gt;10051/tcp peer1.org2.example.com990eb2e086df hyperledger/fabric-orderer:latest &quot;orderer&quot; 3 seconds ago Up Less than a second 0.0.0.0:7050-&gt;7050/tcp orderer.example.com13dbf13c7a50 hyperledger/fabric-peer:latest &quot;peer node start&quot; 3 seconds ago Up 1 second 0.0.0.0:9051-&gt;9051/tcp peer0.org2.example.com ____ _____ _ ____ _____ / ___| |_ _| / \\ | _ \\ |_ _|\\___ \\ | | / _ \\ | |_) | | | ___) | | | / ___ \\ | _ &lt; | | |____/ |_| /_/ \\_\\ |_| \\_\\ |_| Build your first network (BYFN) end-to-end testChannel name : mychannelCreating channel... 12345678========= All GOOD, BYFN execution completed =========== _____ _ _ ____ | ____| | \\ | | | _ \\ | _| | \\| | | | | | | |___ | |\\ | | |_| | |_____| |_| \\_| |____/ 至此，我们的第一个fabric网络启动成功，查看正在运行的docker容器如下：1234567891011[root@localhost first-network]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES6fcfd0974e3b dev-peer1.org2.example.com-mycc-1.0-26c2ef32838554aac4f7ad6f100aca865e87959c9a126e86d764c8d01f8346ab &quot;chaincode -peer.add…&quot; 4 minutes ago Up 4 minutes dev-peer1.org2.example.com-mycc-1.00f84dd3b767d dev-peer0.org1.example.com-mycc-1.0-384f11f484b9302df90b453200cfb25174305fce8f53f4e94d45ee3b6cab0ce9 &quot;chaincode -peer.add…&quot; 4 minutes ago Up 4 minutes dev-peer0.org1.example.com-mycc-1.0d93f067ed43d dev-peer0.org2.example.com-mycc-1.0-15b571b3ce849066b7ec74497da3b27e54e0df1345daff3951b94245ce09c42b &quot;chaincode -peer.add…&quot; 4 minutes ago Up 4 minutes dev-peer0.org2.example.com-mycc-1.07bccf9fbbdfc hyperledger/fabric-tools:latest &quot;/bin/bash&quot; 5 minutes ago Up 5 minutes cli5965f6980409 hyperledger/fabric-peer:latest &quot;peer node start&quot; 5 minutes ago Up 5 minutes 0.0.0.0:7051-&gt;7051/tcp peer0.org1.example.comc0b4948a2120 hyperledger/fabric-peer:latest &quot;peer node start&quot; 5 minutes ago Up 5 minutes 0.0.0.0:8051-&gt;8051/tcp peer1.org1.example.com36d1b4ee086a hyperledger/fabric-peer:latest &quot;peer node start&quot; 5 minutes ago Up 5 minutes 0.0.0.0:10051-&gt;10051/tcp peer1.org2.example.com990eb2e086df hyperledger/fabric-orderer:latest &quot;orderer&quot; 5 minutes ago Up 5 minutes 0.0.0.0:7050-&gt;7050/tcp orderer.example.com13dbf13c7a50 hyperledger/fabric-peer:latest &quot;peer node start&quot; 5 minutes ago Up 5 minutes 0.0.0.0:9051-&gt;9051/tcp peer0.org2.example.com 可以看到已经启动4个peer节点和一个orderer排序节点。同时在三个peer节点上实例化了mycc链码。 4. 关闭网络1./byfn.sh down 该命令会停止上述已经运行的容器同时删除上述步骤所生成的所有材料，包括证书，密钥和配置交易。同时将生成的链码镜像同时删除。"},{"title":"fabric-bootstrap到底做了什么？","date":"2019-10-21T08:30:50.000Z","path":"2019/10/21/fabric-bootstrap/","text":"我们在fabric1.4的下载安装的时候，下载了bootstrap.sh,并利用它来拉取镜像和下载并二进制可执行文件。但是在这个过程bootstrap.sh做了啥？这就是下面要分析的内容 一. 命令分析执行bootstrap.sh 时使用了以下命令 1curl -sSL https://raw.githubusercontent.com/hyperledger/fabric/master/scripts/bootstrap.sh | bash -s -- 1.4.3 1.4.3 0.4.15 其中 -sSL 代表含义如下：123-s, --silent Silent mode-S, --show-error Show error even when -s is used-L, --location Follow redirects s :沉默模式 ，不输出请求过程的任何信息S ：当使用沉默模式的时候，如果出现错误事件需要显示出来L ：短连接进行重定向，原本命令为1curl -sSL http://bit.ly/2ysbOFE | bash -s -- 1.4.3 1.4.3 0.4.15 其中链接为短链接，短链接会重新定向到真正的目标地址。但是使用的时候短链接失效，所以使用了官方教程中提供的长链接。 命令中的竖线 “|” 表示管道，即上个命令输出的内容，交给下一个命令执行。这里表示将下载的bootstrap.sh下载后交给bash执行。 后面跟着的 1.4.3 1.4.3 0.4.15分别表示fabric 、fabric-ca 、第三方镜像（couchdb, kafka 和 zookeeper）版本 后面还可以跟着可选命令 -h -d -s -b 具体含义下面分析： 123456789101112printHelp() &#123; echo &quot;Usage: bootstrap.sh [version [ca_version [thirdparty_version]]] [options]&quot; echo echo &quot;options:&quot; echo &quot;-h : this help&quot; echo &quot;-d : bypass docker image download&quot; echo &quot;-s : bypass fabric-samples repo clone&quot; echo &quot;-b : bypass download of platform-specific binaries&quot; echo echo &quot;e.g. bootstrap.sh 1.4.3 -s&quot; echo &quot;would download docker images and binaries for version 1.4.3&quot;&#125; 从bootstrap.sh中提取出来的帮助函数可以看出 -h : 提示 -d ：跳过docker镜像下载 -s ：跳过fabric-sample的克隆 -b ：跳过指定平台二进制文件下载 具体执行过程如下，整个脚本主要做3件事 克隆fabric-sample 下载特定平台的fabric二进制可执行文件和配置文件 下载指定版本的fabric的docker镜像12345678910111213141516171819202122232425262728293031323334353637DOCKER=trueSAMPLES=trueBINARIES=true# then parse optswhile getopts &quot;h?dsb&quot; opt; do case &quot;$opt&quot; in h|\\?) printHelp exit 0 ;; d) DOCKER=false ;; s) SAMPLES=false ;; b) BINARIES=false ;; esacdoneif [ &quot;$SAMPLES&quot; == &quot;true&quot; ]; then echo echo &quot;Installing hyperledger/fabric-samples repo&quot; echo samplesInstallfiif [ &quot;$BINARIES&quot; == &quot;true&quot; ]; then echo echo &quot;Installing Hyperledger Fabric binaries&quot; echo binariesInstallfiif [ &quot;$DOCKER&quot; == &quot;true&quot; ]; then echo echo &quot;Installing Hyperledger Fabric docker images&quot; echo dockerInstallfi 其中 samplesInstall、 binariesInstall、 dockerInstall分别代表克隆fabric-sample、下载二进制可执行文件、下载docker镜像。 二. 功能具体如下分析：2.1 samplesInstall1234567891011121314151617samplesInstall() &#123; # clone (if needed) hyperledger/fabric-samples and checkout corresponding # version to the binaries and docker images to be downloaded if [ -d first-network ]; then # if we are in the fabric-samples repo, checkout corresponding version echo &quot;===&gt; Checking out v$&#123;VERSION&#125; of hyperledger/fabric-samples&quot; git checkout v$&#123;VERSION&#125; elif [ -d fabric-samples ]; then # if fabric-samples repo already cloned and in current directory, # cd fabric-samples and checkout corresponding version echo &quot;===&gt; Checking out v$&#123;VERSION&#125; of hyperledger/fabric-samples&quot; cd fabric-samples &amp;&amp; git checkout v$&#123;VERSION&#125; else echo &quot;===&gt; Cloning hyperledger/fabric-samples repo and checkout v$&#123;VERSION&#125;&quot; git clone -b master https://github.com/hyperledger/fabric-samples.git &amp;&amp; cd fabric-samples &amp;&amp; git checkout v$&#123;VERSION&#125; fi&#125; git clone -b master https://github.com/hyperledger/fabric-samples.git &amp;&amp; cd fabric-samples &amp;&amp; git checkout v${VERSION} 该命令即表示从github仓库克隆fabric-sample并进入该目录后检出指定版本。 2.2 binariesInstall1234567891011121314151617binariesInstall() &#123; echo &quot;===&gt; Downloading version $&#123;FABRIC_TAG&#125; platform specific fabric binaries&quot; binaryDownload &quot;$&#123;BINARY_FILE&#125;&quot; &quot;https://nexus.hyperledger.org/content/repositories/releases/org/hyperledger/fabric/hyperledger-fabric/$&#123;ARCH&#125;-$&#123;VERSION&#125;/$&#123;BINARY_FILE&#125;&quot; if [ $? -eq 22 ]; then echo echo &quot;------&gt; $&#123;FABRIC_TAG&#125; platform specific fabric binary is not available to download &lt;----&quot; echo fi echo &quot;===&gt; Downloading version $&#123;CA_TAG&#125; platform specific fabric-ca-client binary&quot; binaryDownload &quot;$&#123;CA_BINARY_FILE&#125;&quot; &quot;https://nexus.hyperledger.org/content/repositories/releases/org/hyperledger/fabric-ca/hyperledger-fabric-ca/$&#123;ARCH&#125;-$&#123;CA_VERSION&#125;/$&#123;CA_BINARY_FILE&#125;&quot; if [ $? -eq 22 ]; then echo echo &quot;------&gt; $&#123;CA_TAG&#125; fabric-ca-client binary is not available to download (Available from 1.1.0-rc1) &lt;----&quot; echo fi&#125; 该函数调用binaryDownload到指定地址下载二进制文件压缩包。 2.2.1 binaryDownload12345678910111213141516171819202122# This will attempt to download the .tar.gz all at once, but will trigger the# binaryIncrementalDownload() function upon a failure, allowing for resume# if there are network failures.binaryDownload() &#123; local BINARY_FILE=$1 local URL=$2 echo &quot;===&gt; Downloading: &quot; &quot;$&#123;URL&#125;&quot; # Check if a previous failure occurred and the file was partially downloaded if [ -e &quot;$&#123;BINARY_FILE&#125;&quot; ]; then echo &quot;==&gt; Partial binary file found. Resuming download...&quot; binaryIncrementalDownload &quot;$&#123;BINARY_FILE&#125;&quot; &quot;$&#123;URL&#125;&quot; else curl &quot;$&#123;URL&#125;&quot; | tar xz || rc=$? if [ -n &quot;$rc&quot; ]; then echo &quot;==&gt; There was an error downloading the binary file. Switching to incremental download.&quot; echo &quot;==&gt; Downloading file...&quot; binaryIncrementalDownload &quot;$&#123;BINARY_FILE&#125;&quot; &quot;$&#123;URL&#125;&quot; else echo &quot;==&gt; Done.&quot; fi fi&#125; curl &quot;${URL}&quot; | tar xz || rc=$? 使用curl命令下载tar包，并用tar命令解压。解压后的可执行文件出现在bin目录下，但由于下载过程网络原因，会花费较多时间或者下载失败。所以也可以通过编译fabric源码生成。通过编译生成二进制可执行文件的方式在上一篇fabric1.4下载安装中已经讲过。生成的可执行文件有configtxgen configtxlator cryptogen discover idemixgen orderer peer作用如下 文件 作用 configtxgen 负责生成配置的区块和配置交易 configtxlator 配置信息解读 cryptogen 负责生成组织和成员身份证明文件 discover fabric发现服务 idemixgen 身份混合机制 orderer 负责启动排序节点 peer 负责启动节点 2.3 dockerInstall12345678910111213141516171819dockerInstall() &#123; command -v docker &gt;&amp; /dev/null NODOCKER=$? if [ &quot;$&#123;NODOCKER&#125;&quot; == 0 ]; then echo &quot;===&gt; Pulling fabric Images&quot; dockerFabricPull &quot;$&#123;FABRIC_TAG&#125;&quot; echo &quot;===&gt; Pulling fabric ca Image&quot; dockerCaPull &quot;$&#123;CA_TAG&#125;&quot; echo &quot;===&gt; Pulling thirdparty docker images&quot; dockerThirdPartyImagesPull &quot;$&#123;THIRDPARTY_TAG&#125;&quot; echo echo &quot;===&gt; List out hyperledger docker images&quot; docker images | grep hyperledger else echo &quot;=========================================================&quot; echo &quot;Docker not installed, bypassing download of Fabric images&quot; echo &quot;=========================================================&quot; fi&#125; 关键下载语句如下所示： dockerFabricPull &quot;${FABRIC_TAG}&quot; dockerCaPull &quot;${CA_TAG}&quot; dockerThirdPartyImagesPull &quot;${THIRDPARTY_TAG}&quot; 拉取对应的docker镜像并打标签，最后执行==docker images | grep hyperledger==查看是否下载完成所有镜像。 2.3.1 dockerFabricPull123456789101112# dockerFabricPull() pulls docker images from fabric and chaincode repositories# note, if a docker image doesn&apos;t exist for a requested release, it will simply# be skipped, since this script doesn&apos;t terminate upon errors.dockerFabricPull() &#123; local FABRIC_TAG=$1 for IMAGES in peer orderer ccenv tools baseos nodeenv javaenv; do echo &quot;==&gt; FABRIC IMAGE: $IMAGES&quot; echo docker pull &quot;hyperledger/fabric-$IMAGES:$FABRIC_TAG&quot; docker tag &quot;hyperledger/fabric-$IMAGES:$FABRIC_TAG&quot; &quot;hyperledger/fabric-$IMAGES&quot; done&#125; 2.3.2 dockerCaPull1234567dockerCaPull() &#123; local CA_TAG=$1 echo &quot;==&gt; FABRIC CA IMAGE&quot; echo docker pull &quot;hyperledger/fabric-ca:$CA_TAG&quot; docker tag &quot;hyperledger/fabric-ca:$CA_TAG&quot; &quot;hyperledger/fabric-ca&quot;&#125; 2.3.3 dockerThirdPartyImagesPull123456789dockerThirdPartyImagesPull() &#123; local THIRDPARTY_TAG=$1 for IMAGES in couchdb kafka zookeeper; do echo &quot;==&gt; THIRDPARTY DOCKER IMAGE: $IMAGES&quot; echo docker pull &quot;hyperledger/fabric-$IMAGES:$THIRDPARTY_TAG&quot; docker tag &quot;hyperledger/fabric-$IMAGES:$THIRDPARTY_TAG&quot; &quot;hyperledger/fabric-$IMAGES&quot; done&#125; 镜像说明 名称 说明 是否必需 hyperledger/fabric-peer peer节点镜像文件 是 hyperledger/fabric-orderer orderer节点镜像文件 是 hyperledger/fabric-ccenv GOLANG链码基础镜像文件 是 hyperledger/fabric-tools 包含crytogen、configtxgen、configtxlator等工具的镜像文件 否 hyperledger/fabric-ca fabric-ca镜像文件 否 hyperledger/fabric-couchdb couchdb镜像文件 否 hyperledger/fabric-kafka kafka镜像文件 否 hyperledger/fabric-zookeeper zookeeper镜像文件 否 hyperledger/fabric-javaenv java链码的基础镜像文件 否 注: 非必需的镜像文件说明只有在需要使用的时候选择即可"},{"title":"fabric1.4下载安装","date":"2019-10-21T07:59:40.000Z","path":"2019/10/21/fabric1-4-download/","text":"一. 通过脚本安装1. 创建安装目录1mkdir -p /opt/gopath/src/github.com/hyperledger/ &amp;&amp; cd /opt/gopath/src/github.com/hyperledger 2. 克隆fabric-sample项目1git clone -b v1.4.3 https://github.com/hyperledger/fabric-samples.git &amp;&amp; cd fabric-samples 3. 执行bootstrap脚本1curl -sSL https://raw.githubusercontent.com/hyperledger/fabric/master/scripts/bootstrap.sh | bash -s -- 1.4.3 1.4.3 0.4.15 一般执行该命令会消耗较长时间，且可能出现下载失败，所以可以采取以下方式： 进入目录/opt/gopath/src/github.com/hyperledger，从github上拉取fabric源码 12345git clone https://gerrit.hyperledger.org/r/fabric.gitcd fabricgit checkout v1.4.3make releasecd release/linux-amd64/bin 若bin文件夹中出现以下文件说明编译成功 12[root@localhost bin]# lsconfigtxgen configtxlator cryptogen discover idemixgen orderer peer 将生成文件添加进环境变量 12vim /etc/profileexport PATH=$PATH:$GOPATH/src/github.com/hyperledger/fabric/release/linux-amd64/bin wq保存退出，并更新 1source /etc/profile 二、手动下载安装1. 定义变量12345678910111213VERSION=1.4.3CA_VERSION=1.4.3THIRDPARTY_IMAGE_VERSION=0.4.15CA_TAG=$CA_VERSIONFABRIC_TAG=$VERSIONTHIRDPARTY_TAG=$THIRDPARTY_IMAGE_VERSIONARCH=$(echo &quot;$(uname -s|tr &apos;[:upper:]&apos; &apos;[:lower:]&apos;|sed &apos;s/mingw64_nt.*/windows/&apos;)-$(uname -m | sed &apos;s/x86_64/amd64/g&apos;)&quot;)MARCH=$(uname -m)BINARY_FILE=hyperledger-fabric-$&#123;ARCH&#125;-$&#123;VERSION&#125;.tar.gzCA_BINARY_FILE=hyperledger-fabric-ca-$&#123;ARCH&#125;-$&#123;CA_VERSION&#125;.tar.gz 2. 创建项目目录1mkdir -p /opt/gopath/src/github.com/hyperledger/ &amp;&amp; cd /opt/gopath/src/github.com/hyperledger 3. 克隆fabric-sample，并切换到对应版本（可选）1git clone -b master https://github.com/hyperledger/fabric-samples.git &amp;&amp; cd fabric-samples &amp;&amp; git checkout v$&#123;VERSION&#125; 4. 下载二进制可执行文件压缩包并解压4.1 通过链接下载压缩包并解压（很慢，耗时过长，且容易出现下载失败）123curl https://nexus.hyperledger.org/content/repositories/releases/org/hyperledger/fabric/hyperledger-fabric/$&#123;ARCH&#125;-$&#123;VERSION&#125;/$&#123;BINARY_FILE&#125; | tar xzcurl https://nexus.hyperledger.org/content/repositories/releases/org/hyperledger/fabric-ca/hyperledger-fabric-ca/$&#123;ARCH&#125;-$&#123;CA_VERSION&#125;/$&#123;CA_BINARY_FILE&#125; | tar xz 4.2 通过源码编译生成（建议使用该方法）1234567git clone https://gerrit.hyperledger.org/r/fabric.gitcd fabricgit checkout release-1.4make releasecd release/linux-amd64/bin[root@localhost bin]# lsconfigtxgen configtxlator cryptogen discover idemixgen orderer peer 1234567git clone https://github.com/hyperledger/fabric-ca.gitcd fabric-cagit checkout v1.4.3make releasecd release/linux-amd64/bin[root@localhost bin]# lsfabric-ca-client 将生成文件移到同一个文件夹并添加进环境变量 123mv fabric-ca-client /opt/gopath/src/github.com/hyperledger/fabric/release/linux-amd64/bin/vim /etc/profileexport PATH=$PATH:$GOPATH/src/github.com/hyperledger/fabric/release/linux-amd64/bin wq保存退出，并更新 1source /etc/profile 5. 拉取镜像5.1 拉取fabric镜像1234567891011121314151617181920docker pull &quot;hyperledger/fabric-peer:$FABRIC_TAG&quot;docker tag &quot;hyperledger/fabric-peer:$FABRIC_TAG&quot; &quot;hyperledger/fabric-peer&quot;docker pull &quot;hyperledger/fabric-orderer:$FABRIC_TAG&quot;docker tag &quot;hyperledger/fabric-orderer:$FABRIC_TAG&quot; &quot;hyperledger/fabric-orderer&quot;docker pull &quot;hyperledger/fabric-ccenv:$FABRIC_TAG&quot;docker tag &quot;hyperledger/fabric-ccenv:$FABRIC_TAG&quot; &quot;hyperledger/fabric-ccenv&quot;docker pull &quot;hyperledger/fabric-tools:$FABRIC_TAG&quot;docker tag &quot;hyperledger/fabric-tools:$FABRIC_TAG&quot; &quot;hyperledger/fabric-tools&quot;docker pull &quot;hyperledger/fabric-baseos:$FABRIC_TAG&quot;docker tag &quot;hyperledger/fabric-baseos:$FABRIC_TAG&quot; &quot;hyperledger/fabric-baseos&quot;docker pull &quot;hyperledger/fabric-nodeenv:$FABRIC_TAG&quot;docker tag &quot;hyperledger/fabric-nodeenv:$FABRIC_TAG&quot; &quot;hyperledger/fabric-nodeenv&quot;docker pull &quot;hyperledger/fabric-javaenv:$FABRIC_TAG&quot;docker tag &quot;hyperledger/fabric-javaenv:$FABRIC_TAG&quot; &quot;hyperledger/fabric-javaenv&quot; 5.2 拉取第三方镜像12345678docker pull &quot;hyperledger/fabric-couchdb:$THIRDPARTY_TAG&quot;docker tag &quot;hyperledger/fabric-couchdb:$THIRDPARTY_TAG&quot; &quot;hyperledger/fabric-couchdb&quot;docker pull &quot;hyperledger/fabric-kafka:$THIRDPARTY_TAG&quot;docker tag &quot;hyperledger/fabric-kafka:$THIRDPARTY_TAG&quot; &quot;hyperledger/fabric-kafka&quot; docker pull &quot;hyperledger/fabric-zookeeper:$THIRDPARTY_TAG&quot;docker tag &quot;hyperledger/fabric-zookeeper:$THIRDPARTY_TAG&quot; &quot;hyperledger/fabric-zookeeper&quot; 5.3 拉取fabric-ca镜像12docker pull &quot;hyperledger/fabric-ca:$CA_TAG&quot;docker tag &quot;hyperledger/fabric-ca:$CA_TAG&quot; &quot;hyperledger/fabric-ca&quot; 拉取结果： 123456789101112131415161718[root@localhost ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEhyperledger/fabric-tools 1.4.3 18ed4db0cd57 7 weeks ago 1.55GBhyperledger/fabric-tools latest 18ed4db0cd57 7 weeks ago 1.55GBhyperledger/fabric-ca 1.4.3 c18a0d3cc958 7 weeks ago 253MBhyperledger/fabric-ca latest c18a0d3cc958 7 weeks ago 253MBhyperledger/fabric-ccenv 1.4.3 3d31661a812a 7 weeks ago 1.45GBhyperledger/fabric-ccenv latest 3d31661a812a 7 weeks ago 1.45GBhyperledger/fabric-orderer 1.4.3 b666a6ebbe09 7 weeks ago 173MBhyperledger/fabric-orderer latest b666a6ebbe09 7 weeks ago 173MBhyperledger/fabric-peer 1.4.3 fa87ccaed0ef 7 weeks ago 179MBhyperledger/fabric-peer latest fa87ccaed0ef 7 weeks ago 179MBhyperledger/fabric-zookeeper 0.4.15 20c6045930c8 7 months ago 1.43GBhyperledger/fabric-zookeeper latest 20c6045930c8 7 months ago 1.43GBhyperledger/fabric-kafka 0.4.15 b4ab82bbaf2f 7 months ago 1.44GBhyperledger/fabric-kafka latest b4ab82bbaf2f 7 months ago 1.44GBhyperledger/fabric-couchdb 0.4.15 8de128a55539 7 months ago 1.5GBhyperledger/fabric-couchdb latest 8de128a55539 7 months ago 1.5GB 三、启动第一个fabric网络12cd /opt/gopath/src/github.com/hyperledger/fabric-sample/first-network./byfn up 若最后输出以下内容，说明fabric网络启动成功 12345678910===================== Query successful on peer1.org2 on channel &apos;mychannel&apos; ===================== ========= All GOOD, BYFN execution completed =========== _____ _ _ ____ | ____| | \\ | | | _ \\ | _| | \\| | | | | | | |___ | |\\ | | |_| | |_____| |_| \\_| |____/ 关闭启动的fabric网络，同时删除链码镜像 1./byfn down"},{"title":"问题1 ：curl 不支持 https（Protocol https not supported or disabled in libcurl）","date":"2019-10-21T07:50:10.000Z","path":"2019/10/21/prob1/","text":"curl默认安装完后是只支持http协议而不支持https协议的。 1、可以先用curl -V查看当前curl支持哪些协议：12345[root@localhost ~]# curl -Vcurl 7.66.0 (x86_64-pc-linux-gnu) libcurl/7.66.0 OpenSSL/1.0.2k zlib/1.2.7Release-Date: 2019-09-11Protocols: dict file ftp ftps gopher http imap imaps pop3 pop3s rtsp smb smbs smtp smtps telnet tftp Features: AsynchDNS HTTPS-proxy IPv6 Largefile libz NTLM NTLM_WB SSL TLS-SRP UnixSockets 可以看到并不支持https协议。若用curl命令访问https时就会报错： Protocol https not supported or disabled in libcurl 若需要让curl支持https协议，需要安装openssl并在curl中使之生效： 2、下载并安装openssl包（若已经装了则不需要重新安装）：wget https://www.openssl.org/source/openssl-1.0.2k.tar.gz wget https://www.openssl.org/source/openssl-fips-2.0.14.tar.gz 安装openssl-fips：12tar xvf openssl-fips-2.0.14.tar.gzcd openssl-fips-2.0.14 &amp;&amp; ./config &amp;&amp; make &amp;&amp; make install 安装openssl： 12tar xvf openssl-1.0.2k.tar.gz./config shared --prefix=/usr/local/ssl &amp;&amp; make &amp;&amp; make install 3、更新ld12echo &quot;/usr/local/ssl/lib&quot; &gt;&gt; /etc/ld.so.confldconfig -v 4、配置openssl库1234567891011cp /usr/local/ssl/lib/libssl.so.1.0.0 /usr/lib64cp /usr/local/ssl/lib/libcrypto.so.1.0.0 /usr/lib64chmod 555 /usr/lib64/libssl.so.1.0.0chmod 555/usr/lib64/libcrypto.so.1.0.0ln -s /usr/lib64/libcrypto.so.1.0.0 /usr/lib64/libcrypto.so.10ln -s /usr/lib64/libssl.so.1.0.0 /usr/lib64/libssl.so.10ln -s /usr/local/ssl/bin/openssl /usr/bin/opensslln -s/usr/local/ssl/include/openssl /usr/include/openssl 5、 查看openssl版本123456789openssl version -aOpenSSL 1.0.2k-fips 26 Jan 2017built on: reproducible build, date unspecifiedplatform: linux-x86_64options: bn(64,64) md2(int) rc4(16x,int) des(idx,cisc,16,int) idea(int) blowfish(idx) compiler: gcc -I. -I.. -I../include -fPIC -DOPENSSL_PIC -DZLIB -DOPENSSL_THREADS -D_REENTRANT -DDSO_DLFCN -DHAVE_DLFCN_H -DKRB5_MIT -m64 -DL_ENDIAN -Wall -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -Wa,--noexecstack -DPURIFY -DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT -DOPENSSL_BN_ASM_MONT5 -DOPENSSL_BN_ASM_GF2m -DRC4_ASM -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DMD5_ASM -DAES_ASM -DVPAES_ASM -DBSAES_ASM -DWHIRLPOOL_ASM -DGHASH_ASM -DECP_NISTZ256_ASMOPENSSLDIR: &quot;/etc/pki/tls&quot;engines: rdrand dynamic 6、重新编译curl123./configure –with-ssl=/usr/local/sslmakemake install 7、查看curl是否已经支持https协议：123456curl -V[root@localhost ~]# curl -Vcurl 7.66.0 (x86_64-pc-linux-gnu) libcurl/7.66.0 OpenSSL/1.0.2k zlib/1.2.7Release-Date: 2019-09-11Protocols: dict file ftp ftps gopher http https imap imaps pop3 pop3s rtsp smb smbs smtp smtps telnet tftp Features: AsynchDNS HTTPS-proxy IPv6 Largefile libz NTLM NTLM_WB SSL TLS-SRP UnixSockets 可以看到已经支持https协议了。 内容参考PrefectSix"},{"title":"fabric1.4开发环境准备","date":"2019-10-21T07:36:45.000Z","path":"2019/10/21/fabric1-4-env/","text":"1.安装curl最新版本1234567wget https://curl.haxx.se/download/curl-7.66.0.tar.gztar -zxvf curl-7.66.0.tar.gzcd curl-7.66.0 yum install gcc gcc-c++ -y./configure make -j8 &amp;&amp; make install curl --version 2.安装docker更新yum包1yum update 安装所需要软件包 1yum install -y yum-utils device-mapper-persistent-data lvm2 设置yum源 1yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 查看仓库中的docker版本，安装特定版本 1yum list docker-ce --showduplicates | sort -r 安装docker，docker-ce-版本号 1yum install docker-ce-17.12.1.ce 启动docker 1systemctl start docker 加入开机启动 1systemctl enable docker 验证安装是否成功，若有client和server两部分说明安装启动成功 123456789101112131415161718[root@localhost ~]# docker version Client: Version: 17.12.1-ce API version: 1.35 Go version: go1.9.4 Git commit: 7390fc6 Built: Tue Feb 27 22:15:20 2018 OS/Arch: linux/amd64Server: Engine: Version: 17.12.1-ce API version: 1.35 (minimum version 1.12) Go version: go1.9.4 Git commit: 7390fc6 Built: Tue Feb 27 22:17:54 2018 OS/Arch: linux/amd64 Experimental: false 3.安装docker-compose安装python-pip123yum -y install epel-releasepip install --upgrade pipyum install -y python-pip 安装docker-compose12pip install docker-composedocker-compose --version 12345[root@localhost ~]# docker-compose versiondocker-compose version 1.24.1, build 4667896docker-py version: 3.7.3CPython version: 2.7.5OpenSSL version: OpenSSL 1.0.2k-fips 26 Jan 2017 4.安装golang12345678wget https://gomirrors.org/dl/go/go1.11.10.linux-amd64.tar.gztar -C /usr/local -xzf go1.11.10.linux-amd64.tar.gzvim /etc/profile export GOROOT=/usr/local/go export PATH=$PATH:$GOROOT/bin export GOPATH=/opt/gopath source /etc/profile go version"},{"title":"fabric分布式部署方案","date":"2019-03-31T09:23:01.000Z","path":"2019/03/31/fabric-distribute-config/","text":"一、环境操作系统：CentOS 7.6软件版本 软件名称 版本号 hyperledger/fabric-ca（镜像） 1.2.0 hyperledger/fabric-orderer（镜像） 1.2.0 hyperledger/fabric-peer（镜像） 1.2.0 hyperledger/fabric-zookeeper（镜像） 1.2.0 hyperledger/fabric-kafka（镜像） 1.2.0 hyperledger/fabric-tools（镜像） 1.2.0 hyperledger/fabric-ccenv（镜像） 1.2.0 docker 1.13.1 docker-compose 1.12.0 go 1.11.2 ip 部署角色 191.8.2.156 ca0 &nbsp; &nbsp; zookeeper0 &nbsp; &nbsp;kafka0 &nbsp; &nbsp; orderer0.example.com &nbsp; &nbsp; peer0.org1.example.com 191.8.2.158 zookeeper1 &nbsp; &nbsp; kafka1 &nbsp; &nbsp; orderer1.example.com 191.8.2.159 zookeeper2 &nbsp; &nbsp; kafka2 &nbsp; &nbsp; orderer2.example.com &nbsp; &nbsp; peer0.org2.example.com 191.8.2.147 kafka3 &nbsp; &nbsp; peer1.org2.example.com 191.8.2.148 ca1 &nbsp; &nbsp; peer1.org1.example.com 二、fabric网络结构本次分布式部署包括以下节点角色： 3个orderer 2个组织org1、org2 4个peer，每个组织包含2个peer，分别为peer0.org1、peer1.org1、peer0.org2、peer1.org2 2个CA，每个组织包含一个CA，分别是ca0、ca1 3个zookeeper实例，zookeeper0、zookeeper1、zookeeper2 4个kafka实例，kafka0、kafka1、kafka2、kafka3 三、部署过程1、生成创世区块、channel、锚节点和证书及密钥所需材料生成创世区块、channel、锚节点所需配置文件 configtx.yaml 生成证书及密钥文件所需材料 crypto-config.yaml 运行文件 generate.sh使用工具 configtxgen 和cryptogen来生成对应材料 1bash generate.sh 该命令执行完会生成两个文件目录config、cryto-config 将config文件和cryto-config文件压缩打包 12zip -r ./ config ./config.zipzip -r ./ crypto-config ./ crypto-config.zip 2、在每个宿主机上创建新路径用来存放fabric项目1mkdir /opt/gopath/src/github.com/hyperledger/ &amp;&amp; cd /opt/gopath/src/github.com/hyperledger/ 3、将步骤1的压缩文件分发到各个节点fabric项目目录目录下并解压1234567891011scp config.zip root@191.8.2.158 :/opt/gopath/src/github.com/hyperledger/scp crypto-config.zip root@191.8.2.158: /opt/gopath/src/github.com/hyperledger/scp config.zip root@191.8.2.159: /opt/gopath/src/github.com/hyperledger/scp crypto-config.zip root@191.8.2.159: /opt/gopath/src/github.com/hyperledger/scp config.zip root@191.8.2.148: /opt/gopath/src/github.com/hyperledger/scp crypto-config.zip root@191.8.2.148: /opt/gopath/src/github.com/hyperledger/scp config.zip root@191.8.2.148: /opt/gopath/src/github.com/hyperledger/scp crypto-config.zip root@191.8.2.148: /opt/gopath/src/github.com/hyperledger/ 解压 123cd /opt/gopath/src/github.com/hyperledger/unzip config.zipunzip crypto-config.zip 4、编写各节点角色容器启动文件4.1 在每个宿主机路径/opt/gopath/src/github.com/hyperledger/下创建hosts文件，该host是文件主要是作为挂载在容器的hosts文件 1234567mkdir cluster-config &amp;&amp; cd cluster-configvi hosts 191.8.2.156 ca0 zookeeper0 kafka0 orderer0.example.com peer0.org1.example.com 191.8.2.158 zookeeper1 kafka1 orderer1.example.com peer1.org1.example.com 191.8.2.159 zookeeper2 kafka2 orderer2.example.com peer0.org2.example.com 191.8.2.147 kafka3 peer1.org2.example.com 191.8.2.148 ca1 peer1.org1.example.com 创建docker-compose-base.yml文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899vi docker-compose-base.ymlversion: &apos;2&apos;services: zookeeper: image: hyperledger/fabric-zookeeper ports: - 2181 - 2888 - 3888 volumes: - ./hosts:/etc/hosts kafka: image: hyperledger/fabric-kafka environment: - KAFKA_LOG_RETENTION_MS=-1 - KAFKA_MESSAGE_MAX_BYTES=103809024 - KAFKA_REPLICA_FETCH_MAX_BYTES=103809024 - KAFKA_UNCLEAN_LEADER_ELECTION_ENABLE=false - KAFKA_DEFAULT_REPLICATION_FACTOR=$&#123;KAFKA_DEFAULT_REPLICATION_FACTOR&#125; - KAFKA_MIN_INSYNC_REPLICAS=2 volumes: - ./hosts:/etc/hosts ports: - 9092 orderer: image: hyperledger/fabric-orderer environment: - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=host - ORDERER_HOME=/var/hyperledger/orderer - ORDERER_GENERAL_LOGLEVEL=debug - ORDERER_GENERAL_LOCALMSPDIR=/var/hyperledger/msp - ORDERER_GENERAL_LOCALMSPID=OrdererMSP - ORDERER_GENERAL_LISTENADDRESS=0.0.0.0 - ORDERER_GENERAL_LISTENPORT=7050 - ORDERER_GENERAL_LEDGERTYPE=ram - ORDERER_GENERAL_GENESISMETHOD=file - ORDERER_GENERAL_GENESISFILE=/var/hyperledger/configs/orderer.block - CONFIGTX_ORDERER_ORDERERTYPE=solo - CONFIGTX_ORDERER_BATCHSIZE_MAXMESSAGECOUNT=$&#123;CONFIGTX_ORDERER_BATCHSIZE_MAXMESSAGECOUNT&#125; - CONFIGTX_ORDERER_BATCHTIMEOUT=$&#123;CONFIGTX_ORDERER_BATCHTIMEOUT&#125; - CONFIGTX_ORDERER_ADDRESSES=[127.0.0.1:7050] # TLS settings - ORDERER_GENERAL_TLS_ENABLED=$&#123;ORDERER_GENERAL_TLS_ENABLED&#125; - ORDERER_GENERAL_TLS_PRIVATEKEY=$&#123;ORDERER_GENERAL_TLS_PRIVATEKEY&#125; - ORDERER_GENERAL_TLS_CERTIFICATE=$&#123;ORDERER_GENERAL_TLS_CERTIFICATE&#125; - ORDERER_GENERAL_TLS_ROOTCAS=[/var/hyperledger/tls/ca.crt] - ORDERER_TLS_CLIENTAUTHREQUIRED=$&#123;ORDERER_TLS_CLIENTAUTHREQUIRED&#125; - ORDERER_TLS_CLIENTROOTCAS_FILES=/var/hyperledger/users/Admin@example.com/tls/ca.crt - ORDERER_TLS_CLIENTCERT_FILE=/var/hyperledger/users/Admin@example.com/tls/client.crt - ORDERER_TLS_CLIENTKEY_FILE=/var/hyperledger/users/Admin@example.com/tls/client.key volumes: - ../config/:/var/hyperledger/configs - ../crypto-config/ordererOrganizations/example.com/users:/var/hyperledger/users - ./hosts:/etc/hosts working_dir: /opt/gopath/src/github.com/hyperledger/fabric/orderer command: orderer ports: - &apos;7050&apos; couchdb: image: hyperledger/fabric-couchdb volumes: - ./hosts:/etc/hosts peer: image: hyperledger/fabric-peer environment: - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_PEER_NETWORKID=$&#123;CORE_PEER_NETWORKID&#125; - CORE_VM_DOCKER_HOSTCONFIG_NETWORKMODE=$&#123;CORE_PEER_NETWORKID&#125;_behave - CORE_PEER_ADDRESSAUTODETECT=true - CORE_PEER_GOSSIP_ORGLEADER=false - CORE_PEER_GOSSIP_USELEADERELECTION=true - CORE_PEER_PROFILE_ENABLED=true - CORE_PEER_MSPCONFIGPATH=/var/hyperledger/msp #- CORE_LEDGER_STATE_STATEDATABASE=LevelDB - CORE_LOGGING_LEVEL=DEBUG - CORE_LOGGING_GOSSIP=$&#123;CORE_LOGGING_GOSSIP&#125; - CORE_LOGGING_MSP=DEBUG # TLS settings - CORE_PEER_TLS_ENABLED=$&#123;CORE_PEER_TLS_ENABLED&#125; - CORE_PEER_TLS_CLIENTAUTHREQUIRED=$&#123;CORE_PEER_TLS_CLIENTAUTHREQUIRED&#125; - CORE_PEER_TLS_CERT_FILE=$&#123;CORE_PEER_TLS_CERT_FILE&#125; - CORE_PEER_TLS_KEY_FILE=$&#123;CORE_PEER_TLS_KEY_FILE&#125; - CORE_PEER_TLS_ROOTCERT_FILE=/var/hyperledger/tls/ca.crt volumes: - /var/run/:/host/var/run/ - $GOPATH/src/github.com/hyperledger/fabric/:/opt/gopath/src/github.com/hyperledger/fabric/ - ../crypto-config/:/var/hyperledger/configs - ../config/:/var/hyperledger/configs command: peer node start ports: - &apos;7051&apos; - &apos;7053&apos; 4.2 在各个宿主机上创建启动文件 实验过程中，zookeeper原本以默认网络模式启动，即与peer一样用默认网络配置，结果zookeeper之间无法联通，因此采用“host”网络模式启动，即在启动文件中使用network_mode: “host”。本实验中除了peer用默认网络配置启动之外，其它角色均使用“host”模式启动。 如果仅仅是zookeeper和kafka使用“host”模式启动应该也是可以的。 cli容器启动应该与peer容器处于同一网络模式中 4.2.1 宿主机191.8.2.156创建ca0.yml，其中文件中的c54f5a53707de15a9530d1f5bd492e5b2a626b67acd400b61f24d22b9fd06e69_sk 应该随着新生成的证书密钥文件作对应修改 1234567891011121314151617181920212223242526272829vi ca0.ymlversion: &apos;2&apos;# networks:# behave:services: ca0: image: hyperledger/fabric-ca:$IMAGE_TAG environment: - FABRIC_CA_HOME=/etc/hyperledger/fabric-ca-server - FABRIC_CA_SERVER_CA_NAME=ca-org1 - FABRIC_CA_SERVER_TLS_ENABLED=false - FABRIC_CA_SERVER_TLS_CERTFILE=/etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem - FABRIC_CA_SERVER_TLS_KEYFILE=/etc/hyperledger/fabric-ca-server-config/c54f5a53707de15a9530d1f5bd492e5b2a626b67acd400b61f24d22b9fd06e69_sk #该文件名应该对应着新生成的密钥文件进行修改 ports: - &quot;7054:7054&quot; command: sh -c &apos;fabric-ca-server start --ca.certfile /etc/hyperledger/fabric-ca-server-config/ca.org1.example.com-cert.pem --ca.keyfile /etc/hyperledger/fabric-ca-server-config/c54f5a53707de15a9530d1f5bd492e5b2a626b67acd400b61f24d22b9fd06e69_sk -b admin:adminpw -d&apos; #该文件名应该对应着新生成的密钥文件进行修改 volumes: - ../crypto-config/peerOrganizations/org1.example.com/ca/:/etc/hyperledger/fabric-ca-server-config - ./hosts:/etc/hosts container_name: ca_peerOrg1 network_mode: &quot;host&quot; # networks: # behave: # aliases: # - $&#123;CORE_PEER_NETWORKID&#125; 创建zookeeper0.yml 12345678910111213141516171819202122vi zookeeper0.ymlversion: &apos;2&apos;# networks:# behave:services: zookeeper0: extends: file: docker-compose-base.yml service: zookeeper container_name: zookeeper0 environment: - ZOO_MY_ID=1 - ZOO_SERVERS=server.1=zookeeper0:2888:3888 server.2=zookeeper1:2888:3888 server.3=zookeeper2:2888:3888 network_mode: &quot;host&quot; # networks: # behave: # aliases: # - $&#123;CORE_PEER_NETWORKID&#125; 创建kafka0.yml 123456789101112131415161718192021222324252627vi kafka0.ymlversion: &apos;2&apos;# networks:# behave:services: kafka0: extends: file: docker-compose-base.yml service: kafka container_name: kafka0 environment: - KAFKA_BROKER_ID=0 - KAFKA_ZOOKEEPER_CONNECT=zookeeper0:2181,zookeeper1:2181,zookeeper2:2181 - KAFKA_MESSAGE_MAX_BYTES=$&#123;KAFKA_MESSAGE_MAX_BYTES&#125; - KAFKA_REPLICA_FETCH_MAX_BYTES=$&#123;KAFKA_REPLICA_FETCH_MAX_BYTES&#125; - KAFKA_REPLICA_FETCH_RESPONSE_MAX_BYTES=$&#123;KAFKA_REPLICA_FETCH_RESPONSE_MAX_BYTES&#125; ports: - &quot;9092:9092&quot; network_mode: &quot;host&quot; # networks: # behave: # aliases: # - $&#123;CORE_PEER_NETWORKID&#125; 创建orderer0.yml 1234567891011121314151617181920212223242526272829303132333435vi orderer0.ymlversion: &apos;2&apos;# networks:# behave:services: orderer0.example.com: extends: file: docker-compose-base.yml service: orderer container_name: orderer0.example.com environment: - ORDERER_HOST=orderer0.example.com - CONFIGTX_ORDERER_ORDERERTYPE=kafka - CONFIGTX_ORDERER_KAFKA_BROKERS=[kafka0:9092,kafka1:9092,kafka2:9092,kafka3:9092] - ORDERER_KAFKA_RETRY_SHORTINTERVAL=1s - ORDERER_KAFKA_RETRY_SHORTTOTAL=30s - ORDERER_KAFKA_VERBOSE=true - ORDERER_GENERAL_GENESISPROFILE=SampleInsecureKafka - ORDERER_ABSOLUTEMAXBYTES=$&#123;ORDERER_ABSOLUTEMAXBYTES&#125; - ORDERER_PREFERREDMAXBYTES=$&#123;ORDERER_PREFERREDMAXBYTES&#125; volumes: - ../crypto-config/ordererOrganizations/example.com/orderers/orderer0.example.com/msp:/var/hyperledger/msp - ../crypto-config/ordererOrganizations/example.com/orderers/orderer0.example.com/tls:/var/hyperledger/tls - ../config/:/var/hyperledger/configs network_mode: &quot;host&quot; ports: - 7050:7050 # networks: # behave: # aliases: # - $&#123;CORE_PEER_NETWORKID&#125; 创建peer01.yml 123456789101112131415161718192021222324252627282930313233343536373839404142vi peer01.ymlversion: &apos;2&apos;networks: behave:services: peer0.org1.example.com: extends: file: docker-compose-base.yml service: peer container_name: peer0.org1.example.com environment: - CORE_PEER_CHAINCODELISTENADDRESS=peer0.org1.example.com:7052 - CORE_PEER_ID=peer0.org1.example.com - CORE_PEER_ADDRESS=peer0.org1.example.com:7051 - CORE_PEER_GOSSIP_BOOTSTRAP=peer1.org1.example.com:7051 - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer0.org1.example.com:7051 - CORE_PEER_GOSSIP_ORGLEADER=$&#123;CORE_PEER_GOSSIP_ORGLEADER_PEER0_ORG1&#125; - CORE_PEER_GOSSIP_USELEADERELECTION=$&#123;CORE_PEER_GOSSIP_USELEADERELECTION_PEER0_ORG1&#125; - CORE_PEER_LOCALMSPID=Org1MSP - CORE_PEER_TLS_CLIENTROOTCAS_FILES=/var/hyperledger/users/Admin@org1.example.com/tls/ca.crt - CORE_PEER_TLS_CLIENTCERT_FILE=/var/hyperledger/users/Admin@org1.example.com/tls/client.crt - CORE_PEER_TLS_CLIENTKEY_FILE=/var/hyperledger/users/Admin@org1.example.com/tls/client.key volumes: - ../crypto-config/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/msp:/var/hyperledger/msp - ../crypto-config/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls:/var/hyperledger/tls - ../crypto-config/peerOrganizations/org1.example.com/users:/var/hyperledger/users - ../config/:/var/hyperledger/configs extra_hosts: - &quot;orderer0.example.com:191.8.2.156&quot; - &quot;orderer1.example.com:191.8.2.158&quot; - &quot;orderer2.example.com:191.8.2.159&quot; networks: behave: aliases: - $&#123;CORE_PEER_NETWORKID&#125; ports: - 7051:7051 - 7053:7053 创建docker-compose-cli-org1.yml123456789101112131415161718192021222324252627282930vi docker-compose-cli-org1.ymlversion: &apos;2&apos;networks: behave:services: cli: container_name: cli image: hyperledger/fabric-tools tty: true environment: - GOPATH=/opt/gopath - CORE_VM_ENDPOINT=unix:///host/var/run/docker.sock - CORE_LOGGING_LEVEL=DEBUG - CORE_PEER_ID=cli - CORE_PEER_ADDRESS=peer0.org1.example.com:7051 - CORE_PEER_LOCALMSPID=Org1MSP - CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp - CORE_CHAINCODE_KEEPALIVE=10 working_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer command: /bin/bash volumes: - /var/run/:/host/var/run/ - ../chaincode/:/opt/gopath/src/github.com/chaincode - $GOPATH/src/github.com/hyperledger/fabric/:/opt/gopath/src/github.com/hyperledger/fabric/ - ../crypto-config:/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ networks: - behave 4.2.2 宿主机191.8.2.158创建zookeeper1.yml 1234567891011121314151617181920212223242526vi zookeeper1.ymlversion: &apos;2&apos;# networks:# behave:services: zookeeper1: extends: file: docker-compose-base.yml service: zookeeper container_name: zookeeper1 environment: - ZOO_MY_ID=2 - ZOO_SERVERS=server.1=zookeeper0:2888:3888 server.2=zookeeper1:2888:3888 server.3=zookeeper2:2888:3888 ports: - &quot;2181:2181&quot; - &quot;2888:2888&quot; - &quot;3888:3888&quot; network_mode: &quot;host&quot; # networks: # behave: # aliases: # - $&#123;CORE_PEER_NETWORKID&#125; 创建kafka1.yml 12345678910111213141516171819202122232425262728vi kafka1.ymlversion: &apos;2&apos;# networks:# behave:services: kafka1: extends: file: docker-compose-base.yml service: kafka container_name: kafka1 environment: - KAFKA_ADVERTISED_HOST_NAME=kafka1 - KAFKA_BROKER_ID=1 - KAFKA_ZOOKEEPER_CONNECT=zookeeper0:2181,zookeeper1:2181,zookeeper2:2181 - KAFKA_MESSAGE_MAX_BYTES=$&#123;KAFKA_MESSAGE_MAX_BYTES&#125; - KAFKA_REPLICA_FETCH_MAX_BYTES=$&#123;KAFKA_REPLICA_FETCH_MAX_BYTES&#125; - KAFKA_REPLICA_FETCH_RESPONSE_MAX_BYTES=$&#123;KAFKA_REPLICA_FETCH_RESPONSE_MAX_BYTES&#125; ports: - &quot;9092:9092&quot; network_mode: &quot;host&quot; # networks: # behave: # aliases: # - $&#123;CORE_PEER_NETWORKID&#125; 创建orderer1.yml 12345678910111213141516171819202122232425262728293031323334353637vi orderer1.ymlversion: &apos;2&apos;# networks:# behave:services: orderer1.example.com: extends: file: docker-compose-base.yml service: orderer container_name: orderer1.example.com environment: - ORDERER_HOST=orderer1.example.com - CONFIGTX_ORDERER_ORDERERTYPE=kafka - CONFIGTX_ORDERER_KAFKA_BROKERS=[kafka0:9092,kafka1:9092,kafka2:9092,kafka3:9092] - ORDERER_KAFKA_RETRY_SHORTINTERVAL=1s - ORDERER_KAFKA_RETRY_SHORTTOTAL=30s - ORDERER_KAFKA_RETRY_LONGINTERVAL=30s - ORDERER_KAFKA_RETRY_LONGTOTAL=5m - ORDERER_KAFKA_VERBOSE=true - ORDERER_GENERAL_GENESISPROFILE=SampleInsecureKafka - ORDERER_ABSOLUTEMAXBYTES=$&#123;ORDERER_ABSOLUTEMAXBYTES&#125; - ORDERER_PREFERREDMAXBYTES=$&#123;ORDERER_PREFERREDMAXBYTES&#125; volumes: - ../crypto-config/ordererOrganizations/example.com/orderers/orderer1.example.com/msp:/var/hyperledger/msp - ../crypto-config/ordererOrganizations/example.com/orderers/orderer1.example.com/tls:/var/hyperledger/tls - ../config/:/var/hyperledger/configs network_mode: &quot;host&quot; ports: - 7050:7050 # networks: # behave: # aliases: # - $&#123;CORE_PEER_NETWORKID&#125; 4.2.3 宿主机191.8.2.159创建zookeeper2.yml 1234567891011121314151617181920212223242526vi zookeeper2.ymlversion: &apos;2&apos;# networks:# behave:services: zookeeper2: extends: file: docker-compose-base.yml service: zookeeper container_name: zookeeper2 environment: - ZOO_MY_ID=3 - ZOO_SERVERS=server.1=zookeeper0:2888:3888 server.2=zookeeper1:2888:3888 server.3=zookeeper2:2888:3888 ports: - &quot;2181:2181&quot; - &quot;2888:2888&quot; - &quot;3888:3888&quot; network_mode: &quot;host&quot; # networks: # behave: # aliases: # - $&#123;CORE_PEER_NETWORKID&#125; 创建kafka2.yml 12345678910111213141516171819202122232425262728vi kafka2.ymlversion: &apos;2&apos;# networks:# behave:services: kafka2: extends: file: docker-compose-base.yml service: kafka container_name: kafka2 environment: - KAFKA_ADVERTISED_HOST_NAME=kafka2 - KAFKA_BROKER_ID=2 - KAFKA_ZOOKEEPER_CONNECT=zookeeper0:2181,zookeeper1:2181,zookeeper2:2181 - KAFKA_MESSAGE_MAX_BYTES=$&#123;KAFKA_MESSAGE_MAX_BYTES&#125; - KAFKA_REPLICA_FETCH_MAX_BYTES=$&#123;KAFKA_REPLICA_FETCH_MAX_BYTES&#125; - KAFKA_REPLICA_FETCH_RESPONSE_MAX_BYTES=$&#123;KAFKA_REPLICA_FETCH_RESPONSE_MAX_BYTES&#125; ports: - &quot;9092:9092&quot; network_mode: &quot;host&quot; # networks: # behave: # aliases: # - $&#123;CORE_PEER_NETWORKID&#125; 创建orderer2.yml 1234567891011121314151617181920212223242526272829303132333435vi orderer2.ymlversion: &apos;2&apos;# networks:# behave:services: orderer2.example.com: extends: file: docker-compose-base.yml service: orderer container_name: orderer2.example.com environment: - ORDERER_HOST=orderer2.example.com - CONFIGTX_ORDERER_ORDERERTYPE=kafka - CONFIGTX_ORDERER_KAFKA_BROKERS=[kafka0:9092,kafka1:9092,kafka2:9092,kafka3:9092] - ORDERER_KAFKA_RETRY_SHORTINTERVAL=1s - ORDERER_KAFKA_RETRY_SHORTTOTAL=30s - ORDERER_KAFKA_VERBOSE=true - ORDERER_GENERAL_GENESISPROFILE=SampleInsecureKafka - ORDERER_ABSOLUTEMAXBYTES=$&#123;ORDERER_ABSOLUTEMAXBYTES&#125; - ORDERER_PREFERREDMAXBYTES=$&#123;ORDERER_PREFERREDMAXBYTES&#125; volumes: - ../crypto-config/ordererOrganizations/example.com/orderers/orderer2.example.com/msp:/var/hyperledger/msp - ../crypto-config/ordererOrganizations/example.com/orderers/orderer2.example.com/tls:/var/hyperledger/tls - ../config/:/var/hyperledger/configs network_mode: &quot;host&quot; ports: - 7050:7050 # networks: # behave: # aliases: # - $&#123;CORE_PEER_NETWORKID&#125; 创建peer02.yml 123456789101112131415161718192021222324252627282930313233343536373839404142vi peer02.ymlversion: &apos;2&apos;networks: behave:services: peer0.org2.example.com: extends: file: docker-compose-base.yml service: peer container_name: peer0.org2.example.com environment: - CORE_PEER_CHAINCODELISTENADDRESS=peer0.org2.example.com:7052 - CORE_PEER_ID=peer0.org2.example.com - CORE_PEER_ADDRESS=peer0.org2.example.com:7051 - CORE_PEER_GOSSIP_BOOTSTRAP=peer1.org2.example.com:7051 - CORE_PEER_GOSSIP_EXTERNALENDPOINT=peer0.org2.example.com:7051 - CORE_PEER_GOSSIP_ORGLEADER=$&#123;CORE_PEER_GOSSIP_ORGLEADER_PEER0_ORG2&#125; - CORE_PEER_GOSSIP_USELEADERELECTION=$&#123;CORE_PEER_GOSSIP_USELEADERELECTION_PEER0_ORG2&#125; - CORE_PEER_LOCALMSPID=Org2MSP - CORE_PEER_TLS_CLIENTROOTCAS_FILES=/var/hyperledger/users/Admin@org2.example.com/tls/ca.crt - CORE_PEER_TLS_CLIENTCERT_FILE=/var/hyperledger/users/Admin@org2.example.com/tls/client.crt - CORE_PEER_TLS_CLIENTKEY_FILE=/var/hyperledger/users/Admin@org2.example.com/tls/client.key volumes: - ../crypto-config/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/msp:/var/hyperledger/msp - ../crypto-config/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls:/var/hyperledger/tls - ../crypto-config/peerOrganizations/org2.example.com/users:/var/hyperledger/users - ../config/:/var/hyperledger/configs extra_hosts: - &quot;orderer0.example.com:191.8.2.156&quot; - &quot;orderer1.example.com:191.8.2.158&quot; - &quot;orderer2.example.com:191.8.2.159&quot; networks: behave: aliases: - $&#123;CORE_PEER_NETWORKID&#125; ports: - 7051:7051 - 7053:7053 4.2.4 宿主机191.8.2.147创建kafka3.yml 1234567891011121314151617181920212223242526272829vi kafka3.ymlversion: &apos;2&apos;# networks:# behave:services: kafka3: extends: file: docker-compose-base.yml service: kafka container_name: kafka3 environment: - KAFKA_ADVERTISED_HOST_NAME=kafka3 - KAFKA_BROKER_ID=3 - KAFKA_ZOOKEEPER_CONNECT=zookeeper0:2181,zookeeper1:2181,zookeeper2:2181 - KAFKA_MESSAGE_MAX_BYTES=$&#123;KAFKA_MESSAGE_MAX_BYTES&#125; - KAFKA_REPLICA_FETCH_MAX_BYTES=$&#123;KAFKA_REPLICA_FETCH_MAX_BYTES&#125; - KAFKA_REPLICA_FETCH_RESPONSE_MAX_BYTES=$&#123;KAFKA_REPLICA_FETCH_RESPONSE_MAX_BYTES&#125; ports: - &quot;9092:9092&quot; network_mode: &quot;host&quot; # networks: # behave: # aliases: # - $&#123;CORE_PEER_NETWORKID&#125; 创建peer12.yml 12345678910111213141516171819202122232425262728293031323334353637383940414243vi peer12.ymlversion: &apos;2&apos;networks: behave:services: peer1.org2.example.com: extends: file: docker-compose-base.yml service: peer container_name: peer1.org2.example.com environment: - CORE_PEER_CHAINCODELISTENADDRESS=peer1.org2.example.com:7052 - CORE_PEER_ID=peer1.org2.example.com - CORE_PEER_ADDRESS=peer1.org2.example.com:7051 - CORE_PEER_GOSSIP_BOOTSTRAP=peer0.org2.example.com:7051 - CORE_PEER_GOSSIP_ORGLEADER=$&#123;CORE_PEER_GOSSIP_ORGLEADER_PEER1_ORG2&#125; - CORE_PEER_GOSSIP_USELEADERELECTION=$&#123;CORE_PEER_GOSSIP_USELEADERELECTION_PEER1_ORG2&#125; - CORE_PEER_LOCALMSPID=Org2MSP - CORE_PEER_TLS_CLIENTROOTCAS_FILES=/var/hyperledger/users/Admin@org2.example.com/tls/ca.crt - CORE_PEER_TLS_CLIENTCERT_FILE=/var/hyperledger/users/Admin@org2.example.com/tls/client.crt - CORE_PEER_TLS_CLIENTKEY_FILE=/var/hyperledger/users/Admin@org2.example.com/tls/client.key volumes: - ../crypto-config/peerOrganizations/org2.example.com/peers/peer1.org2.example.com/msp:/var/hyperledger/msp - ../crypto-config/peerOrganizations/org2.example.com/peers/peer1.org2.example.com/tls:/var/hyperledger/tls - ../crypto-config/peerOrganizations/org2.example.com/users:/var/hyperledger/users - ../config/:/var/hyperledger/configs extra_hosts: - &quot;orderer0.example.com:191.8.2.156&quot; - &quot;orderer1.example.com:191.8.2.158&quot; - &quot;orderer2.example.com:191.8.2.159&quot; - &quot;peer0.org2.example.com:191.8.2.159&quot; networks: behave: aliases: - $&#123;CORE_PEER_NETWORKID&#125; ports: - 7051:7051 - 7053:7053 4.2.5 宿主机191.8.2.148创建ca1.yml，其中文件中的4eda5b173fa1151ce140d538ba5135f6459d383c989b37836e2b687cdf0f2b72_sk 应该随着新生成的证书密钥文件作对应修改 1234567891011121314151617181920212223242526272829vi ca1.ymlversion: &apos;2&apos;# networks:# behave:services: ca1: image: hyperledger/fabric-ca:$IMAGE_TAG environment: - FABRIC_CA_HOME=/etc/hyperledger/fabric-ca-server - FABRIC_CA_SERVER_CA_NAME=ca-org2 - FABRIC_CA_SERVER_TLS_ENABLED=false - FABRIC_CA_SERVER_TLS_CERTFILE=/etc/hyperledger/fabric-ca-server-config/ca.org2.example.com-cert.pem - FABRIC_CA_SERVER_TLS_KEYFILE=/etc/hyperledger/fabric-ca-server-config/4eda5b173fa1151ce140d538ba5135f6459d383c989b37836e2b687cdf0f2b72_sk #该文件名应该对应着新生成的密钥文件进行修改 ports: - &quot;7054:7054&quot; command: sh -c &apos;fabric-ca-server start --ca.certfile /etc/hyperledger/fabric-ca-server-config/ca.org2.example.com-cert.pem --ca.keyfile /etc/hyperledger/fabric-ca-server-config/4eda5b173fa1151ce140d538ba5135f6459d383c989b37836e2b687cdf0f2b72_sk -b admin:adminpw -d&apos; #该文件名应该对应着新生成的密钥文件进行修改 volumes: - ../crypto-config/peerOrganizations/org2.example.com/ca/:/etc/hyperledger/fabric-ca-server-config - ./hosts:/etc/hosts container_name: ca_peerOrg2 network_mode: &quot;host&quot; # networks: # behave: # aliases: # - $&#123;CORE_PEER_NETWORKID&#125; 创建peer11.yml 123456789101112131415161718192021222324252627282930313233343536373839404142vi peer11.ymlversion: &apos;2&apos;networks: behave:services: peer1.org1.example.com: extends: file: docker-compose-base.yml service: peer container_name: peer1.org1.example.com environment: - CORE_PEER_CHAINCODELISTENADDRESS=peer1.org1.example.com:7052 - CORE_PEER_ID=peer1.org1.example.com - CORE_PEER_ADDRESS=peer1.org1.example.com:7051 - CORE_PEER_GOSSIP_BOOTSTRAP=peer0.org1.example.com:7051 - CORE_PEER_GOSSIP_ORGLEADER=$&#123;CORE_PEER_GOSSIP_ORGLEADER_PEER1_ORG1&#125; - CORE_PEER_GOSSIP_USELEADERELECTION=$&#123;CORE_PEER_GOSSIP_USELEADERELECTION_PEER1_ORG1&#125; - CORE_PEER_LOCALMSPID=Org1MSP - CORE_PEER_TLS_CLIENTROOTCAS_FILES=/var/hyperledger/users/Admin@org1.example.com/tls/ca.crt - CORE_PEER_TLS_CLIENTCERT_FILE=/var/hyperledger/users/Admin@org1.example.com/tls/client.crt - CORE_PEER_TLS_CLIENTKEY_FILE=/var/hyperledger/users/Admin@org1.example.com/tls/client.key volumes: - ../crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/msp:/var/hyperledger/msp - ../crypto-config/peerOrganizations/org1.example.com/peers/peer1.org1.example.com/tls:/var/hyperledger/tls - ../crypto-config/peerOrganizations/org1.example.com/users:/var/hyperledger/users - ../config/:/var/hyperledger/configs extra_hosts: - &quot;orderer0.example.com:191.8.2.156&quot; - &quot;orderer1.example.com:191.8.2.158&quot; - &quot;orderer2.example.com:191.8.2.159&quot; - &quot;peer0.org1.example.com:191.8.2.156&quot; networks: behave: aliases: - $&#123;CORE_PEER_NETWORKID&#125; ports: - 7051:7051 - 7053:7053 5、启动容器按照以下顺序启动容器 123456graph LRCA--&gt;ZookeeperZookeeper--&gt;kafkakafka--&gt;ordererorderer--&gt;peerpeer--&gt;cli 5.1 启动CA191.8.2.1561docker-compose -f ca0.yml up -d 191.8.2.1481docker-compose -f ca1.yml up -d 5.2 启动Zookeeper191.8.2.1561docker-compose -f zookeeper0.yml up -d 191.8.2.1581docker-compose -f zookeeper1.yml up -d 191.8.2.1591docker-compose -f zookeeper2.yml up -d 5.3 启动kafka191.8.2.1561docker-compose -f kafka0.yml up -d 191.8.2.1581docker-compose -f kafka1.yml up -d 191.8.2.1591docker-compose -f kafka2.yml up -d 191.8.2.1471docker-compose -f kafka3.yml up -d 5.4 启动orderer191.8.2.1561docker-compose -f orderer0.yml up -d 191.8.2.1581docker-compose -f orderer1.yml up -d 191.8.2.1591docker-compose -f orderer2.yml up -d 5.5 启动peer191.8.2.1561docker-compose -f peer01.yml up -d 191.8.2.1481docker-compose -f peer11.yml up -d 191.8.2.1591docker-compose -f peer02.yml up -d 191.8.2.1471docker-compose -f peer12.yml up -d 5.6 启动cli191.8.2.156 1docker-compose -f docker-compose-cli-org1.yml up -d 6、部署链码12345678910111213141516171819202122232425262728293031docker exec -it cli /bin/bashexport CHANNEL_NAME=mychannelpeer channel create -o orderer0.example.com:7050 -c $CHANNEL_NAME -f ./channel-artifacts/channel.tx --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer0.example.com/msp/tlscacerts/tlsca.example.com-cert.pempeer channel join -b mychannel.blockCORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/users/Admin@org2.example.com/msp \\CORE_PEER_ADDRESS=peer0.org2.example.com:7051 CORE_PEER_LOCALMSPID=&quot;Org2MSP&quot; \\CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt \\peer channel join -b mychannel.blockpeer channel update -o orderer0.example.com:7050 -c $CHANNEL_NAME -f ./channel-artifacts/Org1MSPanchors.tx \\--cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer0.example.com/msp/tlscacerts/tlsca.example.com-cert.pemCORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/users/Admin@org2.example.com/msp \\CORE_PEER_ADDRESS=peer0.org2.example.com:7051 CORE_PEER_LOCALMSPID=&quot;Org2MSP&quot; \\CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt \\peer channel update -o orderer0.example.com:7050 -c $CHANNEL_NAME -f ./channel-artifacts/Org2MSPanchors.tx \\--cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer0.example.com/msp/tlscacerts/tlsca.example.com-cert.pempeer chaincode install -n sacc -v 1.0 -p github.com/chaincode/CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/users/Admin@org2.example.com/msp \\CORE_PEER_ADDRESS=peer0.org2.example.com:7051 CORE_PEER_LOCALMSPID=&quot;Org2MSP&quot; \\CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt \\peer chaincode install -n sacc -v 1.0 -p github.com/chaincode/peer chaincode instantiate -o orderer0.example.com:7050 -C mychannel -n emall_cc -v 1.2 -c &apos;&#123;&quot;Args&quot;:[&quot;init&quot;]&#125;&apos; --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer0.example.com/msp/tlscacerts/tlsca.example.com-cert.pem 7、部署效果191.8.2.156 191.8.2.158 191.8.2.159 191.8.2.148 191.8.2.147 参考配置文件地址：silence-lhl 有时候内网机器不能连接外网，也无法从外网直接拉取镜像，一般从跳板机将镜像拉取完成后保存并发送到内网机器，再在内网机器中进行加载，命令如下： docker save IMAGE_NAME IMAGE_NAME.tar docker load -i IMAGE_NAME.tar"},{"title":"docker +calico网络部署","date":"2019-03-16T14:31:12.000Z","path":"2019/03/16/calico/","text":"环境 IP 节点 环境 系统 192.168.15.33 node1 docker+etcd+calicoctl CentOS 7 192.168.15.34 node2 docker+etcd+calicoctl CentOS 7 步骤1）环境准备 修改主机名称 node112[root@localhost ~]# hostnamectl --static set-hostname node1[root@localhost ~]# echo &quot;node1&quot; &gt; /etc/hostname node212[root@localhost ~]# hostnamectl --static set-hostname node2[root@localhost ~]# echo &quot;node2&quot; &gt; /etc/hostname 关闭两台主机防火墙，若开启iptables防火墙，则打开2380端口 12345[root@localhost ~]# systemctl disable firewalld.service[root@localhost ~]# systemctl stop firewalld.service[root@localhost ~]# iptables -F[root@localhost ~]# firewall-cmd --statenot running 两台主机均设置hosts，都执行以下命令 1234[root@localhost ~]# vim /etc/hosts192.168.15.133 node1192.168.15.134 node2 将机器上的ip转发功能打开 12[root@localhost ~]# echo 1 &gt; /proc/sys/net/ipv4/ip_forward[root@localhost ~]# sysctl -p 2）安装docker【两台机器上均安装】123[root@localhost ~]# yum install -y docker[root@localhost ~]# systemctl start docker[root@localhost ~]# systemctl enable docker 3）安装etcd【两台机器上均安装】1[root@localhost ~]# yum install etcd -y 4）配置etcd集群node1 1234567891011121314[root@localhost ~]# cp /etc/etcd/etcd.conf /etc/etcd/etcd.conf.bak[root@localhost ~]#cat &gt; /etc/etcd/etcd.conf &lt;&lt;EOF#[Member]ETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot;ETCD_LISTEN_PEER_URLS=&quot;http://0.0.0.0:2380&quot;ETCD_LISTEN_CLIENT_URLS=&quot;http://0.0.0.0:2379&quot;ETCD_NAME=&quot;node1&quot;#[Clustering]ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;http://192.168.15.133:2380&quot;ETCD_ADVERTISE_CLIENT_URLS=&quot;http://192.168.15.133:2379&quot;ETCD_INITIAL_CLUSTER=&quot;node1=http://192.168.15.133:2380,node2=http://192.168.15.134:2380&quot;EOF node2 1234567891011121314[root@localhost ~]# cp /etc/etcd/etcd.conf /etc/etcd/etcd.conf.bak[root@localhost ~]# cat &gt; /etc/etcd/etcd.conf &lt;&lt;EOF#[Member]ETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot;ETCD_LISTEN_PEER_URLS=&quot;http://0.0.0.0:2380&quot;ETCD_LISTEN_CLIENT_URLS=&quot;http://0.0.0.0:2379&quot;ETCD_NAME=&quot;node2&quot;#[Clustering]ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;http://192.168.15.134:2380&quot;ETCD_ADVERTISE_CLIENT_URLS=&quot;http://192.168.15.134:2379&quot;ETCD_INITIAL_CLUSTER=&quot;node1=http://192.168.15.133:2380,node2=http://192.168.15.134:2380&quot;EOF 启动两个节点的etcd服务，以node1为例 12[root@localhost ~]# systemctl enable etcd[root@localhost ~]# systemctl start etcd 查看集群成员 1234567[root@localhost ~]# etcdctl member list8e92f64982d9786c: name=node2 peerURLs=http://192.168.15.134:2380 clientURLs=http://192.168.15.134:2379 isLeader=falsed3e45f62ae9d5a52: name=node1 peerURLs=http://192.168.15.133:2380 clientURLs=http://192.168.15.133:2379 isLeader=true[root@localhost ~]# etcdctl cluster-healthmember 8e92f64982d9786c is healthy: got healthy result from http://192.168.15.134:2379member d3e45f62ae9d5a52 is healthy: got healthy result from http://192.168.15.133:2379cluster is healthy 5）修改docker启动文件以支持etcdnode1 在ExecStart区域内添加 (在–seccomp-profile 这一行的下面一行添加–cluster-store=etcd://192.168.15.133:2379 \\ ) 12345678[root@localhost ~]# cp /usr/lib/systemd/system/docker.service /usr/lib/systemd/system/docker.service.bak[root@localhost ~]# vim /usr/lib/systemd/system/docker.service........--seccomp-profile=/etc/docker/seccomp.json \\--cluster-store=etcd://192.168.15.133:2379 \\[root@localhost ~]# systemctl daemon-reload[root@localhost ~]# systemctl restart docker node2 在ExecStart区域内添加 (在–seccomp-profile 这一行的下面一行添加–cluster-store=etcd://192.168.15.134:2379 \\ ) 12345678[root@localhost ~]# cp /usr/lib/systemd/system/docker.service /usr/lib/systemd/system/docker.service.bak[root@localhost ~]# vim /usr/lib/systemd/system/docker.service........--seccomp-profile=/etc/docker/seccomp.json \\--cluster-store=etcd://192.168.15.134:2379 \\[root@localhost ~]# systemctl daemon-reload[root@localhost ~]# systemctl restart docker 结果 发现当前docker支持了etcd，且由于etcd服务已经启动，所以可以看到etcd进程1234[root@localhost ~]# ps -ef|grep etcdetcd 10293 1 0 19:47 ? 00:00:33 /usr/bin/etcd --name=node1 --data-dir=/var/lib/etcd/default.etcd --listen-client-urls=http://0.0.0.0:2379root 10426 1 0 19:54 ? 00:00:07 /usr/bin/dockerd-current --add-runtime docker-runc=/usr/libexec/docker/docker-runc-current --default-runtime=docker-runc --exec-opt native.cgroupdriver=systemd --userland-proxy-path=/usr/libexec/docker/docker-proxy-current --init-path=/usr/libexec/docker/docker-init-current --seccomp-profile=/etc/docker/seccomp.json --cluster-store=etcd://192.168.15.133:2379 --selinux-enabled --log-driver=journald --signature-verification=false --storage-driver overlay2root 13333 1279 0 21:34 pts/0 00:00:00 grep --color=auto etcd 6）安装calico网络通信环境节点上先下载calico容器镜像 1[root@localhost ~]# docker pull quay.io/calico/node:v2.6.10 安装calicoctl【所有节点都需要安装】 12345[root@localhost ~]# wget https://github.com/projectcalico/calicoctl/releases/download/v1.1.0/calicoctl[root@localhost ~]# chmod 755 calicoctl[root@localhost ~]# mv calicoctl /usr/local/bin/[root@localhost ~]# calicoctl --versioncalicoctl version v1.1.0, build 882dd008 分别在两个节点上创建calico容器 node1 1[root@localhost ~]# docker run --net=host --privileged --name=calico-node -d --restart=always -e NODENAME=node1 -e CALICO_NETWORKING_BACKEND=bird -e CALICO_LIBNETWORK_ENABLED=true -e IP=192.168.15.133 -e ETCD_ENDPOINTS=http://127.0.0.1:2379 -v /var/log/calico:/var/log/calico -v /var/run/calico:/var/run/calico -v /lib/modules:/lib/modules -v /run:/run -v /run/docker/plugins:/run/docker/plugins -v /var/run/docker.sock:/var/run/docker.sock quay.io/calico/node:v2.6.10 node21[root@localhost ~]# -e CALICO_NETWORKING_BACKEND=bird -e CALICO_LIBNETWORK_ENABLED=true -e IP=192.168.15.134 -e ETCD_ENDPOINTS=http://127.0.0.1:2379 -v /var/log/calico:/var/log/calico -v /var/run/calico:/var/run/calico -v /lib/modules:/lib/modules -v /run:/run -v /run/docker/plugins:/run/docker/plugins -v /var/run/docker.sock:/var/run/docker.sock quay.io/calico/node:v2.6.10 查看calico容器创建情况（以node1为例） 123456789101112131415[root@localhost ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES2d9f4e006b37 quay.io/calico/node:v2.6.10 &quot;start_runit&quot; About an hour ago Up About an hour calico-node[root@localhost ~]# ps -ef|grep calicoroot 11112 11109 0 20:24 ? 00:00:00 svlogd -tt /var/log/calico/bird6root 11113 11109 0 20:24 ? 00:00:00 bird6 -R -s /var/run/calico/bird6.ctl -d -c /etc/calico/confd/config/bird6.cfgroot 11114 11110 0 20:24 ? 00:00:00 svlogd /var/log/calico/confdroot 11115 11110 0 20:24 ? 00:00:00 confd -confdir=/etc/calico/confd -interval=5 -watch --log-level=info -node=http://127.0.0.1:2379 -client-key= -client-cert= -client-ca-keys=root 11116 11111 0 20:24 ? 00:00:00 svlogd /var/log/calico/libnetworkroot 11118 11107 0 20:24 ? 00:00:00 svlogd /var/log/calico/felixroot 11120 11108 0 20:24 ? 00:00:00 svlogd -tt /var/log/calico/birdroot 11121 11108 0 20:24 ? 00:00:00 bird -R -s /var/run/calico/bird.ctl -d -c /etc/calico/confd/config/bird.cfgroot 11455 11107 0 20:34 ? 00:00:28 calico-felixroot 13771 1279 0 21:49 pts/0 00:00:00 grep --color=auto calico 查看calico状态 node1 123456789101112[root@localhost ~]# calicoctl node statusCalico process is running.IPv4 BGP status+----------------+-------------------+-------+----------+-------------+| PEER ADDRESS | PEER TYPE | STATE | SINCE | INFO |+----------------+-------------------+-------+----------+-------------+| 192.168.15.134 | node-to-node mesh | up | 12:24:19 | Established |+----------------+-------------------+-------+----------+-------------+IPv6 BGP statusNo IPv6 peers found. node2 123456789101112[root@localhost ~]# calicoctl node statusCalico process is running.IPv4 BGP status+----------------+-------------------+-------+----------+-------------+| PEER ADDRESS | PEER TYPE | STATE | SINCE | INFO |+----------------+-------------------+-------+----------+-------------+| 192.168.15.133 | node-to-node mesh | up | 12:24:21 | Established |+----------------+-------------------+-------+----------+-------------+IPv6 BGP statusNo IPv6 peers found. 7）添加calico网络注：只需要在一个节点配置添加即可 node1 创建ip pool123456789101112[root@localhost ~]# cat &gt;ipPool.yaml &lt;&lt;EOF- apiVersion: v1 kind: ipPool metadata: cidr: 10.20.0.0/24 spec: ipip: enabled: true nat-outgoing: trueEOF[root@localhost ~]# calicoctl create -f ipPool.yaml 在任意节点查看添加ip pool情况 12345[root@localhost ~]# calicoctl get ipPoolCIDR 10.20.0.0/24 192.168.0.0/16 fd80:24e2:f998:72d6::/64 在上面创建的ip pool(10.20.0.0/24)里创建子网络 12[root@localhost ~]# docker network create --driver calico --ipam-driver calico-ipam --subnet 10.20.0.0/24 net1[root@localhost ~]# docker network create --driver calico --ipam-driver calico-ipam --subnet 10.20.0.0/24 net2 查看网络创建情况，可以看到net1、net2的网络已经存在 1234567[root@localhost ~]# docker network lsNETWORK ID NAME DRIVER SCOPEdd3ae1400375 bridge bridge localb87973f6e3da host host localaaea1c24a3d6 net1 calico globalefebcca875b3 net2 calico global0fd941dfe66b none null local 在node1和node2上创建容器来测试下容器网络的连通性 下载busybox工具，方便测试使用 1[root@localhost ~]# docker pull busybox node1 12[root@localhost ~]# docker run --net net1 --name workload-A -tid busybox[root@localhost ~]# docker run --net net2 --name workload-B -tid busybox node2 1[root@localhost ~]# docker run --net net1 --name workload-E -tid busybox 同一网络内的容器（即使不在同一节点主机上）可以使用容器名来访问 node112345678910[root@localhost ~]# docker exec workload-A ping -c 4 workload-E.net1PING workload-E.net1 (10.20.0.1): 56 data bytes64 bytes from 10.20.0.1: seq=0 ttl=62 time=0.811 ms64 bytes from 10.20.0.1: seq=1 ttl=62 time=0.220 ms64 bytes from 10.20.0.1: seq=2 ttl=62 time=0.157 ms64 bytes from 10.20.0.1: seq=3 ttl=62 time=0.231 ms--- workload-E.net1 ping statistics ---4 packets transmitted, 4 packets received, 0% packet lossround-trip min/avg/max = 0.157/0.354/0.811 ms node2 12345678910[root@localhost ~]# docker exec workload-E ping -c 4 workload-A.net1PING workload-A.net1 (10.20.0.129): 56 data bytes64 bytes from 10.20.0.129: seq=0 ttl=62 time=1.964 ms64 bytes from 10.20.0.129: seq=1 ttl=62 time=1.152 ms64 bytes from 10.20.0.129: seq=2 ttl=62 time=0.521 ms64 bytes from 10.20.0.129: seq=3 ttl=62 time=0.503 ms--- workload-A.net1 ping statistics ---4 packets transmitted, 4 packets received, 0% packet lossround-trip min/avg/max = 0.503/1.035/1.964 ms 不同网络内的容器需要使用容器ip来访问 使用容器名会报：bad address 12[root@localhost ~]# docker exec workload-A ping -c 4 workload-B.net2ping: bad address &apos;workload-B.net2&apos; 使用容器ip（这个还没尝试成功） 1docker exec workload-A ping -c 2 `docker inspect --format &quot;&#123;&#123; .NetworkSettings.Networks.net2.IPAddress &#125;&#125;&quot; workload-B`"},{"title":"IPv6-router","date":"2018-11-10T03:40:02.000Z","path":"2018/11/10/IPv6-router/","text":"1、IPv6路由1.1 源和目的机在同一链路的数据转发（on-link) 通过地址前缀判断是否同一链路：on-link 发起地址解析（与v4的ARP不同） 独立于媒体层 利用三层安全机制 改广播为组播，降低骚扰范围 由ND协议完成 1.1.1 ND（Neighbor Discover,邻居发现）协议 地址解析 替代ARP 邻居不可达检测 无状态地址自动配置 路由器发现 接口ID自动生成 重复地址检测（DAD） 前缀重新编址 路由器重定向 ICMPv6类型 消息名称 ICMPv6类型 消息名称 Type=133 RS (路由器请求) Type=136 NA (邻居公告) Type=134 RA (路由器公告) Type=137 Redirect Type=135 NS (邻居请求) IPv6地址解析 查找邻居缓存表（ipv6 nc），没有则进行地址解析 源主机发送组播NS报文，该报文的目的地址为目标IPv6地址所对应的被请求节点组播地址(Solicted-node)，在其中也包括了自己的链路层地址； 目标主机收到NS报文之后，就会得到发送主机的IPv6地址和相应的链路层地址； 目标主机向源主机单播发一个邻接点公告报文(NA)，该报文中包含自己的链路层地址 实例： Attention: 邻居缓存表(neighbor cache) 存储最近通过信的邻居的信息 每条记录包括单播IPv6地址、MAC地址、标记、下次NUD时间 NUD：Neighbor Unreachability Detection,不可达检测，测试自己和邻居之间的通达性 邻居缓存表中记录的状态： 状态 含义 INCOMPLETE（未完成状态） 添加新记录，还未有MAC地址，可尝试多次组播NS REACHABLE（可达状态） 收到NA确认 STALE（失效状态） 已经过了reachable time时效 DELAY（延迟状态） 等待NA确认，默认5s PROBE（探测状态） delay时效过， 可发3次（间隔1s） NS 1.2 源和目的机不在同一链路的数据转发（off-link）1.2.1 主机——路由器(主机发给哪个路由器)DestinationCache（目的缓存表） 初始时为空 某个地址在该表中查不到时， 改查路由表， 做on-link判断： 是on-link的，将目的地址本身加入DC表的nexthop域； 是off-link的，将路由表中的下一跳加入DC的nexthop域。 重定向问题 优化主机-路由器之间的路由若路由器发现报文的出口和入口相同或者源地址与报文下一跳同属一个网段，则发出重定向报文。 1.2.2 路由器——路由器(路由器发给哪个路由器)核心：路由表 直连路由 静态路由 IPv4：ip route IPv6：ipv6 route 动态路由 内部网关协议 距离矢量路由选择协议：RIPng 链路状态路由选择协议：OSPFv3 边界网关协议 BGP4+ 2、IPv6过渡技术2.1 三种主要地方共存技术2.1.1 双栈 网络设备上运行IPv6/IPv4双协议栈 适用于混合环境。基础设施设备，如路由器、交换机、公用服务器等需要运行和支持双栈； 到底使用哪个地址：选择高优先级地址，根据地址选择策略表：优先级、范围 Happy eyeballs dual stack 先尝试IPv6，不成功则转向IPv4 要求，DNS服务器有双栈记录，“A”，“AAAA” 2.1.2 隧道 IPv6网络上承载IPv4分组，或相反 大致分为两类 手动隧道：事前配置 自动隧道：创建和拆除都依赖当前网络条件 IPv6分组通过IPv4网络 适用于IPv6孤岛情形 IPv6分组作为载荷搭载到IPv4分组中，在这种情形下，IPv4分组头部的protocol=41 IPv4分组通过IPv6网络 类似IPv6通过IPv4 DSTM(Dual Stack Transition Mechanism) 2.1.3 翻译/转换 [x] 地址、分组、端口的转换 从IPv4转换到IPv6， 或反过来，不仅发生在网络层还有传输层和应用层 当双栈和隧道都无法使用的时候，才使用；适用纯IPv4节点和IPv6节点的通信。"},{"title":"IPv6-packet","date":"2018-11-09T07:29:09.000Z","path":"2018/11/09/IPv6-packet/","text":"1、IPv6报文一般格式 1.1 IPv6与IPv4报文比较 报头变化： IPv4最小报头：20字节 IPv6固定报头：40字节 修改项 地址：32位——&gt; 128位 TTL ——&gt; 跳数限制 协议 ——&gt; 下一报头 服务质量 ——&gt; 流量类型 删除的项 分片域 IP选项 校验和 HL 数据报长度 增加的项 流标签 1.2 IPv6扩展报头主要的扩展报头： 逐跳选项路由报头分段报头认证报头封装安全有效载荷报头目标选项 扩展报头 next header value 逐跳扩展头 0 ICMPv4 1 TCP 6 UDP 17 路由扩展头 43 ICMPv6 58 OSPF 89 没有下一个报头 59 扩展头顺序 逐跳选项报头 目标选项报头1（当存在路由报头时，用于中间目标） 路由报头 分片段报头 身份验证报头 封装安全有效载荷报头 目标选项报头2（用于最终目标） 1.2.1 逐跳选项报头 存放沿途所有路由器必须检查的信息！ 定义一些选项：eg：巨形数据报 选项按照类型、长度、值出现 选项字段最高两位含义如下： 00 ：跳过该选项 01 ：丢弃数据包，不通知发送方 10 ：丢弃数据包，无论数据包目标地址是否为一个组播地址，都向发送方发出ICMPv6参数问题的报文 11 ：丢弃数据包，如果数据包的目标地址不是一个组播地址，就向发送方发出一个ICMPv6参数问题的报文 选项字段最高第三位表示在通向目标的路径中，选项数据是否可以改变 0 ：选项数据不能改变 1 ：选项数据可以改变 当路由器识别不出对应类型的时候，执行相应动作。 1.2.2 路由报头使数据分组经过指定的中间节点到达目的地。 剩余分段：表示地址表中还有多少个地址未被访问！每过一个列表中的地址 -1 当数据到达每个中间目标地址的时候，执行动作如下： 当前目标地址与第（n-段剩余值+1）个地址交换；（n是地址总数） 段剩余值减1 转发 2.ICMPv6协议ICMPv6报文类型 差错报文：通告IPv6分组传输中出现的错误 目标不可达 数据包超长 超时 参数问题 信息报文：提供诊断和附加的主机功能 MLD ND(ARP,redirect) 回声请求和应答 2.1 ICMPv6报文的一般格式 差错报文：类型=0 xxxxxxx =0 ~ 127 信息报文：类型=1 xxxxxxx =128 ~255 128: 回声请求 129：回声应答 2.2 ICMPv6的三个应用 ping tracert 第一个请求：HopLim=1(TTL=1) 第一跳路由器收到，发送超时消息 得到第一跳路由器信息 第二个请求：HopLim=2(TTL=2) 第二跳路由器收到，发送超时消息 得到第二跳路由器信息 …… 指导目的地，目的机通常发送端口不可达报文 PMTU发现 MTU：最大传输单元，在IPv4网络中可能由路由器承担分段，容易遭受分片型攻击，在IPv6中规定分段不能由路由器承担，只能由发送方分段（切割数据来适应载重能力），因此在IPv6中，要求源节点（发送方）必须在发送数据之前知道整个传输路径的最小MTU PMTU发现原理（试探） 源机向目的机发送MTU=1500字节的IPv6数据包 路由器B向源发送超长信息，指定MTU=1400字节 源机向目的机发送MTU=1400字节的IPv6数据包 路由器C向源发送超长消息，指定MTU=1300字节 源机向目的机发送MTU=1300字节的IPv6数据包 此后，该路径的MTU都使用1300字节"},{"title":"IPv6(2)","date":"2018-10-25T06:35:12.000Z","path":"2018/10/25/IPv6-2/","text":"5.2 组播地址（Multicast Address) 其中 Flags： 0001 （表示permanent)或 0000(表示临时组播组) Scope： 表示组播组范围 范围值 范围 范围值 范围 0 保留 8 组织-本地范围 1 节点-本地范围 9 未分配 2 链路-本地范围 A 未分配 3 未分配 B 未分配 4 未分配 C 未分配 5 站点-本地范围 D 未分配 6 未分配 E 全局范围 7 未分配 F 保留 Group ID： 组播组ID 5.2.1 一些熟知的组播地址节点-本地范围 FF01：:1 所有-节点地址 FF01：:2 所有-路由器地址 链路-本地范围 FF02：:1 所有-节点地址 FF02：:2 所有-路由器地址 5.2.2 特殊的组播地址 Solicited-node节点地址：被请求节点组播地址，主要用于重复地址检测和获取邻居节点的链路层地址 地址构成： 前104位：FF02：:1:FF/104(64个0) 后24位：单播地址的后24位 [x] 工作范围：在本地链路上有效 凡是单播地址后24位相同的接口自动加入相应的请求节点组播组！ 作用： 1、在IPV6中，没有ARP。ICMP代替了ARP的功能，被请求节点的组播地址被节点用来获得相同本地链路上邻居节点的链路层地址 2、用于重复地址检测DAD，在使用无状态自动配置将某个地址配置为自已的IPV6地址之前，节点利用DAD验证在其本地链路上该地址是否已经被使用。 5.3 任播地址（Anycast Address)IPv6地址新类型： IPv6中一个任播地址是分配给不同节点的多个接口的，就是说有若干个网络接口可分配同一个任播地址。当有一个数据包传送给这个地址时，路由器只将此数据包转发到其中一个“最近距离”的接口上就结束了，并不是每个接口都收到此数据包。（这一点上也与IPv6多播不同。） 另外，单从IPv6的地址形式上是无法区分单播与任播地址的 目标地址为任播地址的数据报将发送给最近的一个接口 适合与One-to-One of Many（一对多之一）的通讯场合 仅能做目标地址，且仅分配给路由器 6.一台IPv6主机，一个接口上可以具有的IPv6地址 名称 地址 链路本地地址 FE80::/10 环回地址 ::1/128 所有节点组播地址 FF01：:1(本地接口范围)，FF02::1(本地链路范围) 分配的可聚合全球单播地址 2000::/3 被请求节点组播地址 FF02::1:FF00:/104 主机所属组的组播地址 FF00::/8 7.IPv6地址配置 手工配置 无状态地址自动配置（ND协议） 有状态地址自动配置（DHCPv6） 默认情况下，IPv6主机可以为每个接口配置一个链路本地地址 7.1 无状态地址自动配置（SLAAC）无需任何配置即可与外界通信 无状态地址自动配置基于对主机使用的IPv6地址的如下结构：由前缀 和 接口ID 组成 接口ID：EUI-64 前缀一般是路由器前缀，运行一个无需主机配置的协议即可。 无状态地址自动配置用到的消息Router Solicitation (RS):促使路由器发送RA消息 Router Advertisement (RA)：向主机通告前缀等信息 两种消息都是以ICMP报文形式出现，也是5种ND协议消息中的两种 无状态地址自动配置中的3个机制(1)路由发现 主机选择默认网关 主机发现前缀，生成前缀列表 参数发现：发现相关参数的过程，如MTU，跳数限制、地址配置方式等 路由发现实例 主机请求——触发路由器 注意要点： 节点启动最多只能发送3个RS，避免RS泛滥 主机收到路由器RA之后，自动设置默认路由器，建立默认路由器列表、前缀列表及其它参数 路由器会主动周期性发送RA（默认值200秒） 关于地址的生存期：自动配置的IPv6地址在系统中you一个生存周期，跟++优先时间++和++有效时间++有关，对应4种状态 RA消息种prefix选项 在Preferred Lifetime周期内的前缀生成的地址，任何上层应用都可不受限制地使用 在超过Preferred Lifetime 但未超过ValidLifetime周期内的前缀生成的地址， 正在使用该地址的上层应用可继续使用， 但任何新的上层应用不能使用这个地址 在超过Valid Lifetime周期内的前缀构造的地址，任何上层应用都不能使用该地址 Attention:一个链路本地地址的优先时间和有效时间是无限的，即永不超时 RA消息中的M和O选项 (2)重复地址检测（Duplicate Address Detection：DAD） 节点确定即将使用的地址是否在链路上唯一的过程，对于所有的IPv6地址，不管是自动配置还是手动配置，都必须要通过DAD，DAD机制通过ND中的NS/NA两种消息实现 基本思想 一个地址在分配给一个接口之后且通过重复地址检测之前称为tentative地址，即试验地址 节点组播发送Neighbor Solicitation 若接收到Neighbor Advertisment，就证明地址重复 若尝试若干次请求，没有收到邻居通告，即可启用该地址 实例 若NS接受者发现目标域中地址对它而言是临时的，则主动放弃使用该地址 若NS接收者发现目标域中地址是一个它正在使用的地址，则发送NA消息，请求发起者将放弃使用该临时地址 (3)前缀重新编址 允许从旧前缀平稳过渡到新前缀，提供对用户透明的网络重新编址能力 当前缀重新编址的时候，路由器会继续通告当前前缀，只是优先时间和有效时间被减到接近0，同时路由器开始通告新的前缀，此时链路中至少有两个前缀共存 当节点收到这样的RA的时候，会发现当前前缀的生命周期较短，停止使用；同时开始使用新的前缀配置接口，并进行DAD，通过后，获得新的地址使用。 Attention:在转换期间，节点有两个单播地址使用。旧的地址是基于旧的前缀，用以维持以前已经建立的连接。新的地址是基于新的前缀，用来建立新的连接。当旧的前缀的有效时间递减为0时，旧的前缀完全废止，此时，RA中只包含新的前缀 小结：4中ND协议消息交互 7.2 有状态地址自动配置（DHCPv6）DHCPv6：Dynamic Host Configuration Protocol for ipv6 在有无状态地址自动配置的情况下，仍然需要DHCPv6的原因： 需要动态指定DNS服务 不想MAC地址成为IPv6地址的一部分 需要良好扩展性 特点 使用UDP来交换报文，端口546/547(v4：67/68),使用本地链路地址或其它机制获得的地址来发送和接收DHCPv6报文。没有了广播， 客户机只需发送给保留的链路范围组播地址，取消了DHCPv4中的Discover和Offer消息 DHCPv6获取地址和参数的典型过程 4步交互地址分配 快速地址配置 只需要两个信息交互 当客户端已经记录了地址和其他配置信息 只需要DNS server、NTP Server等信息 DHCPv6重配置机制 8.IPv6地址子网规划IPv4地址进行子网划分是为了管理地址稀缺性 IPv6子网划分是根据路由器数量以及支持的网络来构建寻址分层结构"},{"title":"IPv6(1)","date":"2018-10-24T12:43:33.000Z","path":"2018/10/24/IPv6-1/","text":"1.四层TCP/IPv6参考模型Application Layer ——HTTP,FTP,SMTP,SIP,RTP,DNS,DHCPv6，etc. Transport Layer ——TCPv6，UDPv6，SCTP Internet Layer —— IPv6，ICMPv6，IPsec Link Layer —— ND,OSPFv3,L2TP,PPP,Ethernet,DSL,MPLS,etc. 2.IPv6基本术语 局域网段：位于内部交换机下的网段 链路：内部子网路由器下 子网：多个链路可以组成子网 网络：不同子网可构成网络 3.IPv6地址为128位地址空间非常大，可以夸张地说，世界上每一粒沙子都可以有对应的IPv6地址。 4.IPv6地址表示格式：冒分十六进制128位IPv6地址如下：1200100000000000010000010000010000000000000000000000000000000000010000000000000000000000000000000000000000000000000100010111111111 每16位一组，分为8组如下：120010000000000001 0000010000010000 0000000000000000 00000000000000010000000000000000 0000000000000000 0000000000000000 0100010111111111 每一组中，每4为单位以16进制表示如下： 123456780010 0000 0000 0001 20010000 0100 0001 0000 04100000 0000 0000 0000 00000000 0000 0000 0001 00010000 0000 0000 0000 00000000 0000 0000 0000 00000000 0000 0000 0000 00000100 0101 1111 1111 45ff 将8组16进制数用冒号连接如下： 12001:0410:0000:0001:0000:0000:0000:45ff 为了简洁表示，IPv6冒分十六进制有以下规则 规则1： 省略前导0，如果每组16进制数中存在前导0，则省略 2001:0410:0000:0001:0000:0000:0000:45ff 省略前导0，结果如下： 12001:410:0:1:0:0:0:45ff 规则2： 忽略全0 2001:410:0:1:0:0:0:45ff 结果如下 12001:410:0:1::45ff 注意：如果有多个部分有全0部分只能忽略一个部分的全0，如： 12001:0:0:1:0:0:0:45ff 只能写成 123452001::1:0:0:0:45ff或者2001:0:0:1::45ff 以下写法为错误写法： 12001::1::45ff 因为这样写无法确定省略了0的个数 5.IPv6地址分类与IPv4地址相比少了广播地址 5.1 单播地址（Unicast Address)IPv6单播地址用于唯一标识支持IPv6的设备上的接口，源IPv6地址必须为单播地址 本地链路地址 全局单播地址 环回地址 唯一本地地址 嵌入式IPv4地址 未指定地址 5.1.1本地链路地址目的：用于与统一链路中的其他设备通信 注意：路由器不会转发具有本地链路源地址或目的地址的数据包，每个支持IPv6的网络接口一定有本地链路地址。 支持IPv6的主机会创建IPv6本地链路地址，而IPv4的本地链路地址不会自动生成。 1. 链路本地地址的构成 应用范围：只能在同一本地链路节点之间使用，FE80::/64 节点启动时会自动配置一个本地链路地址。 2.链路本地地址的一种生成方法 前64位：FE80：0：0：0 后64位：EUI-64地址 EUI-64地址生成 MAC地址为48位，从中间切分为两部分各24位； 在这两部分之间插入16位数：11111111 11111110 组成64位地址； 将从头开始数的第7位取反，得到最终EUI-64地址 例：一台主机的MAC地址是： 0012:3400:ABCD， 试求其生成的链路本地地址 MAC地址写成二进制 100000000 00010010 00110100 00000000 10101011 11001101 中间插入 11111111 11111110 100000000 00010010 00110100 11111111 11111110 00000000 10101011 11001101 第7位取反 100000010 00010010 00110100 11111111 11111110 00000000 10101011 11001101 得到EUI-64地址 10212:34FF:FE00:ABCD 与前64位组合生成本地链路地址 1FE80::0212:34FF:FE00:ABCD 3.本地链路地址用途 主机使用本地路由器的本地链路地址作为默认网关IPv6地址 路由器使用本地链路地址交换动态路由协议消息 转发 IPv6 数据包时， 路由器的路由表使用本地链路地址确定下一跳路由器 5.1.2 环回地址 环回地址除最后一位外全为0，压缩格式表示为::1/128 主机使用环回地址发送数据包到其自身，环回地址不能分配给物理接口 5.1.3 未指定地址 未指定地址为全0地址，压缩格式表示为::/128或:: 不能分配给接口。仅作为IPv6数据包源地址，在设备尚无永久IPv6地址时，未指定地址可作为源地址，不能作为目的地址。 5.1.4 唯一本地地址 类似于IPv4的私有地址，但也有重大差异，范围从FC00::/7到FDFF::/7 唯一本地地址在一个站点内或有限站点数之间用作本地地址，在全局IPv6中不具有可路由性 5.1.5 可聚合全球单播地址 由格式前缀001标识，ISP商分配的前缀：/48，全球路由前缀 Site拓扑：由组织机构划分子网，子网ID 接口ID：64 接口ID生成方法： EUI-64（MAC地址生成） 随机生成（RFC3041） 手工设置 5.1.5 特殊单播地址 IPv6兼容地址：0：0：0：0：0：0：w:x:y:z 或 ::w.x.y.z IPv4映射地址：0：0：0：0：0：FFFF:w.x.y.z或::FFFF:w.x.y.z 6to4地址"},{"title":"CentOS以太坊私链搭建","date":"2018-10-02T02:47:59.000Z","path":"2018/10/02/centos-ethereum-establish/","text":"一、安装golang语言1yum install golang 也可以直接下载对应版本安装： 12wget https://studygolang.com/dl/golang/go1.10.1.linux-amd64.tar.gztar -xvf go1.10.1.linux-amd64.tar.gz 二、安装以太坊下载 1wget https://github.com/ethereum/go-ethereum/archive/v1.8.3.tar.gz 解压并编译 123tar -zxvf v1.8.3.tar.gzcd go-ethereum-1.8.3make 三、运行以太坊 进入对应目录 1cd build/bin/ 配置创世块 1234567891011121314151617181920vim genesis.json&#123; &quot;config&quot;:&#123; &quot;chainId&quot;:15, &quot;homesteadBlock&quot;:0, &quot;eip155Block&quot;:0, &quot;eip158Block&quot;:0 &#125;, &quot;nonce&quot;:&quot;0x0000000000000056&quot;, &quot;mixhash&quot;:&quot;0x0000000000000000000000000000000000000000000000000000000000000000&quot;, &quot;difficulty&quot;: &quot;0x400&quot;, &quot;alloc&quot;: &#123;&#125;, &quot;coinbase&quot;:&quot;0x0000000000000000000000000000000000000000&quot;, &quot;timestamp&quot;: &quot;0x00&quot;, &quot;parentHash&quot;:&quot;0x0000000000000000000000000000000000000000000000000000000000000000&quot;, &quot;extraData&quot;: &quot;&quot;, &quot;gasLimit&quot;:&quot;0xffffffff&quot;&#125; 初始化私链 1./geth --datadir data --networkid 20180929 --rpc --rpccorsdomain &quot;*&quot; init genesis.json 运行私链 1./geth --datadir data --networkid 20180929 --rpc --rpcaddr &quot;192.168.10.18&quot; --rpccorsdomain &quot;*&quot; --nodiscover --port 30303 --rpcport 8545 console 其中 –rpcaddr “192.168.10.18”为可选参数，当需要外部访问私链时需要绑定本机ip 四、使用screen管理会话为了防止远程连接中断导致私链停止运行，使用screen来管理会话 当需要运行私链前 1screen -S yourname -&gt; 新建一个叫yourname的session 切出当前会话 ctrl+A+D 1C-a d -&gt; detach，暂时离开当前session，将目前的 screen session (可能含有多个 windows) 丢到后台执行，并会回到还没进 screen 时的状态，此时在 screen session 里，每个 window 内运行的 process (无论是前台/后台)都在继续执行，即使 logout 也不影响。 重新连接后台会话 1screen -r yourname -&gt; 回到yourname这个session"},{"title":"Ubuntu以太坊私链搭建","date":"2018-10-01T13:19:47.000Z","path":"2018/10/01/ubuntu-ethereum-establish/","text":"一、安装以太坊（Ethereum）客户端执行以下命令，安装以太坊客户端 123456apt-get updateapt-get install software-properties-commonadd-apt-repository -y ppa:ethereum/ethereumadd-apt-repository -y ppa:ethereum/ethereum-devapt-get updateapt-get install ethereum 安装完成后，命令行输入 1geth -h 出现上图信息说明安装成功！ 二、创建私链2.1 创建创世块创建一个genesis.json文件，并将以下内容写到该文件中并保存 1234567891011121314151617&#123;&quot;config&quot;:&#123;&quot;chainId&quot;:15,&quot;homesteadBlock&quot;:0,&quot;eip155Block&quot;:0,&quot;eip158Block&quot;:0&#125;,&quot;nonce&quot;:&quot;0x0000000000000056&quot;,&quot;mixhash&quot;:&quot;0x0000000000000000000000000000000000000000000000000000000000000000&quot;,&quot;difficulty&quot;: &quot;0x40000&quot;,&quot;alloc&quot;: &#123;&#125;,&quot;coinbase&quot;:&quot;0x0000000000000000000000000000000000000000&quot;,&quot;timestamp&quot;: &quot;0x00&quot;,&quot;parentHash&quot;:&quot;0x0000000000000000000000000000000000000000000000000000000000000000&quot;,&quot;extraData&quot;: &quot;&quot;,&quot;gasLimit&quot;:&quot;0xffffffff&quot;&#125; 2.2 初始化私链1geth --datadir data --networkid 20140628 --rpc --rpccorsdomain &quot;*&quot; init ./genesis.json 其中 ==init==后面所带的为上面所创建genesis.json文件路径 2.3 启动私链1geth --datadir data --networkid 20140628 --rpc [--rpcaddr &quot;192.168.10.150&quot;] --rpccorsdomain &quot;*&quot; --nodiscover --port 30303 --rpcport 8545 console 其中==–rpcaddr==为可选部分，如果需要外部访问私链，需要将运行节点本机ip绑定 –rpcaddr “192.168.10.150” 2.4 创建账号并开始挖矿 创建账号 personal.newAccount(“123456”); 括号中参数为账号私钥密码 2.开启/停止挖矿 miner.start(‘1’) 括号中参数代表参与挖矿线程，若不加此参数则会使用机器所有线程进行挖矿 miner.stop() 2.5 其它相关命令查询第一个账户余额1web3.fromWei(web3.eth.getBalance(web3.eth.accounts[0]),&quot;ether&quot;) 查询第二个账户余额1web3.fromWei(web3.eth.getBalance(web3.eth.accounts[1]),&quot;ether&quot;) 第一个账户向第二个账户转入50 ether1web3.eth.sendTransaction(&#123;from:web3.eth.accounts[0] , to: web3.eth.accounts[1],value: web3.toWei(50, &quot;ether&quot;)&#125;) 为第一个账户解锁，一般在发起交易时需要使用1personal.unlockAccount(web3.eth.accounts[0]) 连接geth控制台 1./geth attach http://127.0.0.1:8545"},{"title":"终于有一个自己的博客了！！","date":"2018-09-30T16:00:00.000Z","path":"2018/10/01/hello-world/","text":"喜大普奔啊！利用hexo快速地搭建了自己的博客 Harlan! 以后这个博客会作为我学习内容记录的一部分，我将会把自己学习的一些内容在这个博客中记录。作为菜鸟的我，还是不敢说做技术分享的！！该博客仅为本人的笔记。将会记录内容包括：课程学习内容、 技术学习内容 ，甚至还有吐槽，hhh！ 个人博客为什么要搭建博客？作为一个程序猿大学毕业还没有自己的博客，实在是太不像话了，还不赶紧neng一个！！（其实就是想找个属于自己的地方） 博客会用来干嘛？废话，当然用来写写写的呀！难道用来唠嗑吗？（不好意思，用来唠嗑也是挺好的感觉）当然，博客中会记录自己在每段时间的学习内容，任何学习内容都有可能出现，只要不违法！游戏内容应该就不会出现了，毕竟本人是个不玩游戏的假程序猿 真的会写下去吗？不知道诶，也许是一时兴起呢！ 记录一下发文章的步骤 步骤一：创建新文章 hexo new title 步骤二：编写新文章 步骤三：生成并部署 hexo g -d / hexo d -g"}]